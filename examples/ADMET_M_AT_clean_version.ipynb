{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVtD1GmeggwIrKTP6enQk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/examples/ADMET_M_AT_clean_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0o8KT5Qy9n",
        "outputId": "c332a4b2-2a2a-4b3b-ef76-59ef902af479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet"
      ],
      "metadata": {
        "id": "0z7g7bjEQ_Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfJSHvatRAuS",
        "outputId": "a94d6c70-8982-4b8f-fbc6-7a045224900d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "import torch.nn as nn\n",
        "from scripts.preprocess_mols import collect_data\n",
        "from models.dataloader_AT import *\n",
        "\n",
        "# train_datasets = get_graph_dataset(trains, met_cls)\n",
        "# train_loader = get_graph_dataloader(train_datasets, loader_params)\n",
        "\n",
        "batch_size = 64\n",
        "loader_params ={'batch_size': batch_size, 'shuffle': True}\n",
        "params_test = {'batch_size': batch_size, 'shuffle': False}\n",
        "\n",
        "def get_loader(df, name, loader_params=loader_params):\n",
        "    dataset = get_graph_dataset(df, name)\n",
        "    loader = get_graph_dataloader(dataset, loader_params)\n",
        "    return loader\n",
        "\n",
        "def get_multi_loader(trains, valids, tests, name, loader_params=loader_params):\n",
        "    train_loader = get_loader(trains, name, loader_params)\n",
        "    valid_loader = get_loader(valids, name, loader_params)\n",
        "    test_loader  = get_loader(tests,  name, params_test) # should not shuffle\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "import torch.nn.functional as F\n",
        "def evaluate_(preds_, labels_, masks_, names, IS_R):\n",
        "    if IS_R == False:\n",
        "        for i, name in enumerate(names):\n",
        "            # try: name = name.split('_')[0]\n",
        "            # except: pass\n",
        "            print('*'*15, name, '*'*15)\n",
        "            probs = F.sigmoid(preds_[:, i][~masks_[:, i]])\n",
        "            label = labels_[:, i][~masks_[:, i]]\n",
        "            probs = probs.cpu().detach().numpy()\n",
        "            label = label.cpu().detach().numpy()\n",
        "            assert len(probs) == len(label)\n",
        "            preds = get_preds(0.5, probs)\n",
        "            evaluate(label, preds, probs)\n",
        "            print()"
      ],
      "metadata": {
        "id": "Ke7HJpTRRA98"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "met_cls = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "            'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "\n",
        "IS_R = False # is regression task\n",
        "SCALE = False\n",
        "\n",
        "if IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification\n",
        "\n",
        "trains, valids, tests = collect_data(met_cls, IS_R=False)\n",
        "train_loader, valid_loader, test_loader = get_multi_loader(\n",
        "                                trains, valids, tests, met_cls, loader_params)"
      ],
      "metadata": {
        "id": "GAERZyuuRCID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import EarlyStopping, Meter\n",
        "import torch\n",
        "import numpy as np\n",
        "from models.train_AT import train_epoch\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda: device = 'cuda'\n",
        "else: device = 'cpu'\n",
        "\n",
        "from models.dataloader_AT import get_model_AT\n",
        "model = get_model_AT(met_cls, n_layers=5, graph_feat_size=300,\n",
        "                     dropout=0.3, device=device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
        "stopper = EarlyStopping(mode='lower', patience=30)\n",
        "n_epochs = 500\n",
        "best_epoch = 0\n",
        "min_loss = 100000\n",
        "\n",
        "IS_R = False # is regression task\n",
        "\n",
        "if IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification"
      ],
      "metadata": {
        "id": "9MhOH8_tRMbB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if best_epoch != 0:\n",
        "    model.load_state_dict(torch.load('ckpt_M.pt', map_location=device))\n",
        "\n",
        "for epoch in range(best_epoch, best_epoch + n_epochs):\n",
        "    score = train_epoch(epoch, model, train_loader, loss_fn, optimizer)\n",
        "    val_score = train_epoch(epoch, model, valid_loader, loss_fn)\n",
        "    early_stop = stopper.step(val_score[1], model)\n",
        "    if val_score[1] < min_loss and epoch > 3:\n",
        "        print(f'prev min loss {min_loss:.3f}, now loss {val_score[1]:.3f} |',\n",
        "              f'save model at epoch: {epoch}')\n",
        "        min_loss = val_score[1]\n",
        "        torch.save(model.state_dict(), 'ckpt_M.pt')\n",
        "        best_epoch = epoch\n",
        "\n",
        "    if early_stop: print('early stop'); break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMacWdaARMzs",
        "outputId": "4b35228f-330d-4223-e7d9-bd720c253bf2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:144, [Train] R2: 0.564, Loss: 0.527\n",
            "Epoch:144, [Valid] R2: 0.458, Loss: 0.427\n",
            "EarlyStopping counter: 30 out of 30\n",
            "early stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.train_AT import eval_AP\n",
        "\n",
        "model.load_state_dict(torch.load('ckpt_M.pt', map_location=device))\n",
        "preds_, labels_, masks_ = eval_AP(model, False, test_loader)\n",
        "evaluate_(preds_, labels_, masks_, met_cls, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0bmDiasRmil",
        "outputId": "25ca298d-e2bc-4e5f-9f5a-f35db1e73baa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test sets\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 145/145 [00:18<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.476\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.841  &  0.841  &          0.812  &     0.850  &0.833  &0.830 &0.913 &   0.681 &   0.896\n",
            "ROC-AUC: 0.841\n",
            "PR-AUC: 0.759\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.882  &  0.756  &          0.741  &     0.557  &0.956  &0.636 &0.886 &   0.575 &   0.720\n",
            "ROC-AUC: 0.756\n",
            "PR-AUC: 0.495\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.819  &  0.812  &          0.788  &     0.769  &0.854  &0.778 &0.910 &   0.626 &   0.873\n",
            "ROC-AUC: 0.812\n",
            "PR-AUC: 0.701\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.879  &  0.879  &          0.866  &     0.879  &0.879  &0.873 &0.945 &   0.757 &   0.942\n",
            "ROC-AUC: 0.879\n",
            "PR-AUC: 0.819\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.858  &  0.842  &          0.787  &     0.795  &0.890  &0.791 &0.926 &   0.683 &   0.848\n",
            "ROC-AUC: 0.842\n",
            "PR-AUC: 0.695\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tdc.benchmark_group import admet_group\n",
        "# group = admet_group(path = 'data/')\n",
        "# pred_list = []\n",
        "# for seed in [0, 1, 2, 3, 4, 5]:\n",
        "#     pred_dict = {}\n",
        "#     for i, name in enumerate(met_cls):\n",
        "#         benchmark = group.get(name)\n",
        "#         name_spec = benchmark['name']\n",
        "#         if name.lower() == name_spec:\n",
        "#             test = benchmark['test']\n",
        "#             test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "#             test_loader = get_loader(test, [name], params_test)\n",
        "#             for idx, batch_data in enumerate(test_loader):\n",
        "#                 smiles, bg, labels, masks = batch_data\n",
        "#                 n_feats = bg.ndata.pop('hv')\n",
        "#                 e_feats = bg.edata.pop('he')\n",
        "#                 pred = model(bg, n_feats, e_feats)\n",
        "#                 if idx == 0: preds_ = pred.cpu()\n",
        "#                 else: preds_ = torch.cat([preds_, pred.cpu()], dim=0)\n",
        "#             pred_dict[name_spec] = get_preds(0.5,\n",
        "#                 F.sigmoid(preds_[:, i]).cpu().detach().numpy())\n",
        "#             pred_list.append(pred_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpNVHePnZfeM",
        "outputId": "9126cfbb-bfb5-4c43-c743-4132a3f3a16f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 1660 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=2)]: Done 2467 out of 2467 | elapsed:    3.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dgl graphs from scratch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done 1660 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=2)]: Done 2419 out of 2419 | elapsed:    3.9s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results = group.evaluate_many(pred_list)\n",
        "# results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIUwqWpzaQB-",
        "outputId": "0ddb76cf-0218-4ea7-cee6-831059ee3b09"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cyp2d6_veith': [0.651, 0.0],\n",
              " 'cyp3a4_veith': [0.8, 0.0],\n",
              " 'cyp2c9_veith': [0.763, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTR_tCdAbcus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}