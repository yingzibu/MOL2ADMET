{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVSdv0Qvk47bGKmkvU8TWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/examples/Graph/ADMET_GIN_MO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-bdNWG8iOx0",
        "outputId": "1abe1ad9-76dd-4dcc-a58f-3d3faf55173b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet"
      ],
      "metadata": {
        "id": "R8dRwvfliWV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet"
      ],
      "metadata": {
        "id": "IzXXU3t4icXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c00e37c-9107-488f-97d3-95e725cb73f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for descriptastorus (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paVNvIN-iXcT",
        "outputId": "b9544ee1-b23b-4279-a1a5-876786750699"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import walk\n",
        "import os\n",
        "files = next(walk('/content/drive/MyDrive/ADMET/'), (None, None, []))[2]\n",
        "for file in files:\n",
        "    if isinstance(file, str):\n",
        "        file_type = file.split('.')[-1]\n",
        "        # print(file_type)\n",
        "        if file_type == 'bin' or file_type == 'pth':\n",
        "            os.remove(file)"
      ],
      "metadata": {
        "id": "Apqv_McBiaio"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.model import load_pretrained\n",
        "from dgl.nn.pytorch.glob import AvgPooling\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "import torch\n",
        "from dgllife.utils import smiles_to_bigraph, PretrainAtomFeaturizer, PretrainBondFeaturizer\n",
        "\n",
        "MASK = -100\n",
        "\n",
        "class GIN_dataset(Dataset):\n",
        "    def __init__(self, df, names, mask=MASK):\n",
        "        df = df.fillna(mask)\n",
        "        self.names = names\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.props = self.df[names]\n",
        "        self.node_featurizer = PretrainAtomFeaturizer()\n",
        "        self.edge_featurizer = PretrainBondFeaturizer()\n",
        "        self.fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
        "    def __len__(self): return self.len\n",
        "    def __getitem__(self, idx):\n",
        "        v_d = self.df.iloc[idx]['Drug']\n",
        "        v_d = self.fc(smiles=v_d, node_featurizer = self.node_featurizer,\n",
        "                      edge_featurizer = self.edge_featurizer)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return v_d, label\n",
        "\n"
      ],
      "metadata": {
        "id": "125Wbwz4itai"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "def get_GIN_dataloader(datasets, loader_params):\n",
        "    def dgl_collate_func(data):\n",
        "        x, labels = map(list, zip(*data))\n",
        "        bg = dgl.batch(x)\n",
        "        labels = torch.stack(labels, dim=0)\n",
        "        bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "        bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "        return bg, labels\n",
        "    loader_params['collate_fn'] = dgl_collate_func\n",
        "    return DataLoader(datasets, **loader_params)"
      ],
      "metadata": {
        "id": "hsovfj4QiwEQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(epoch, model, loader, loss_func, device,\n",
        "                optimizer=None, names=None, MASK=-100):\n",
        "    if optimizer==None: model.eval(); train_type='Valid'\n",
        "    else: model.train(); train_type='Train'\n",
        "    losses = 0\n",
        "    y_probs = {}\n",
        "    y_label = {}\n",
        "    for idx, batch in tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch}'):\n",
        "        bg, labels = batch\n",
        "        bg, labels = bg.to(device), labels.to(device)\n",
        "        mask = labels == MASK\n",
        "        pred = model(bg)\n",
        "        loss = loss_func(pred[~mask], labels[~mask])\n",
        "        # del mask\n",
        "        losses += loss.item()\n",
        "        if optimizer != None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if names != None:\n",
        "            for j, name in enumerate(names):\n",
        "                probs = F.sigmoid(pred[:, j][~mask[:, j]])\n",
        "                label = labels[:, j][~mask[:, j]]\n",
        "                probs = probs.cpu().detach().numpy().tolist()\n",
        "                label = label.cpu().detach().numpy().tolist()\n",
        "                if idx ==0: y_probs[name], y_label[name] = probs, label\n",
        "                else:\n",
        "                    y_probs[name] += probs\n",
        "                    y_label[name] += label\n",
        "\n",
        "        # if idx % 10 == 0: print(losses)\n",
        "    total_loss = losses / len(loader.dataset)\n",
        "    print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
        "    if names == None or train_type == 'train': return total_loss\n",
        "    else: return total_loss, y_probs, y_label\n"
      ],
      "metadata": {
        "id": "1oWvT4U2jc55"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "def eval_dict(y_probs:dict, y_label:dict, names:list, IS_R=False):\n",
        "    if IS_R == False: # classification task\n",
        "        for i, name in enumerate(names):\n",
        "            print('*'*15, name, '*'*15)\n",
        "            probs = y_probs[name]\n",
        "            label = y_label[name]\n",
        "            assert len(probs) == len(label)\n",
        "            preds = get_preds(0.5, probs)\n",
        "            # evaluate(label, preds, probs)\n",
        "            print(f'AUROC: {roc_auc_score(label, probs):.4f}',\n",
        "                  f'AUPRC: {average_precision_score(label, probs):.4f}',\n",
        "                  f'F1: {f1_score(label, preds):.4f}')\n",
        "            evaluate(label, preds, probs)\n",
        "            print()\n",
        "\n",
        "\n",
        "def eval_AP(model, IS_R, test_loader, names, device=device):\n",
        "    # print('Evaluate on test sets')\n",
        "    # model = model.cpu()\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    y_probs = {}\n",
        "    y_label = {}\n",
        "    if IS_R: print('using MSELoss')\n",
        "    else: print('using BCELOSSwithdigits')\n",
        "    if IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "    else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification\n",
        "    for i, batch_data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "        bg, labels = batch_data\n",
        "        bg, labels = bg.to(device), labels.to(device)\n",
        "        pred = model(bg)\n",
        "        mask = labels == MASK\n",
        "        loss = loss_fn(pred[~mask], labels[~mask])\n",
        "        total_loss += loss.item()\n",
        "        for j, name in enumerate(names):\n",
        "            probs = F.sigmoid(pred[:, j][~mask[:, j]])\n",
        "            label = labels[:, j][~mask[:, j]]\n",
        "            probs = probs.cpu().detach().numpy().tolist()\n",
        "            label = label.cpu().detach().numpy().tolist()\n",
        "            if i ==0: y_probs[name], y_label[name] = probs, label\n",
        "            else:\n",
        "                y_probs[name] += probs\n",
        "                y_label[name] += label\n",
        "\n",
        "    total_loss /= len(test_loader.dataset)\n",
        "    print(f'total_loss: {total_loss:.3f}')\n",
        "\n",
        "    eval_dict(y_probs, y_label, names, IS_R)\n",
        "\n",
        "    return y_probs, y_label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbH28Nfclm0A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GIN_MOD(nn.Module):\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/encoders.py#L392\n",
        "    \"\"\"\n",
        "\t## adapted from https://github.com/awslabs/dgl-lifesci/blob/2fbf5fd6aca92675b709b6f1c3bc3c6ad5434e96/examples/property_prediction/moleculenet/utils.py#L76\n",
        "    def __init__(self, **config):\n",
        "        super(GIN_MOD, self).__init__()\n",
        "        self.gnn = load_pretrained('gin_supervised_contextpred')\n",
        "        self.readout = AvgPooling()\n",
        "        self.transform = nn.Linear(300, config['GIN_out_dim'])\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "        self.hidden_dims = config['hid_dims']\n",
        "        self.out_dim = config['out_dim']\n",
        "        layer_size = len(self.hidden_dims)\n",
        "        neurons = [config['GIN_out_dim'], *self.hidden_dims]\n",
        "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                         for i in range(1, len(neurons))]\n",
        "        self.hidden = nn.ModuleList(linear_layers)\n",
        "        self.final = nn.Linear(self.hidden_dims[-1], self.out_dim)\n",
        "\n",
        "    def forward(self, bg):\n",
        "        # bg = bg.to(device)\n",
        "        node_feats = [\n",
        "            bg.ndata.pop('atomic_number'),\n",
        "            bg.ndata.pop('chirality_type')\n",
        "        ]\n",
        "        edge_feats = [\n",
        "            bg.edata.pop('bond_type'),\n",
        "            bg.edata.pop('bond_direction_type')\n",
        "        ]\n",
        "\n",
        "        node_feats = self.gnn(bg, node_feats, edge_feats)\n",
        "        x = self.readout(bg, node_feats)\n",
        "        x = self.transform(x)\n",
        "        for layer in self.hidden: x = F.leaky_relu(layer(x))\n",
        "        x = self.final(x)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "ulEFHLX3_AJw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class PRED:\n",
        "    def __init__(self, **config):\n",
        "        cuda = torch.cuda.is_available()\n",
        "        if cuda: self.device = 'cuda'\n",
        "        else:    self.device = 'cpu'\n",
        "        self.prop_names = config['prop_names']\n",
        "        self.model = GIN_MOD(**config).to(self.device)\n",
        "        self.config = config\n",
        "        self.IS_R = config['IS_R']\n",
        "        if self.IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "        else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
        "                    lr=config['lr'], weight_decay=config['wd'])\n",
        "        self.stopper = EarlyStopping(mode='lower', patience=config['patience'])\n",
        "        self.min_loss = 10000\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def load_model(self, path):\n",
        "        con = self.config.copy()\n",
        "        # con['dropout'] = 0\n",
        "        self.model = GIN_MOD(**con).to(self.device)\n",
        "        print('load pretrained model from ', path)\n",
        "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
        "\n",
        "    def eval(self, loader, path=None):\n",
        "        # self.load_model(path)\n",
        "        if path != None: self.load_model(path)\n",
        "        eval_AP(self.model, self.IS_R, loader, self.prop_names)\n",
        "\n",
        "    def train(self, data_loader, val_loader, test_loader=None,\n",
        "              train_epoch=train_epoch):\n",
        "        if self.best_epoch != 0: self.load_model(self.config['model_path'])\n",
        "\n",
        "        for epoch in range(500):\n",
        "            score = train_epoch(epoch, self.model, data_loader, self.loss_fn,\n",
        "                                self.device, self.optimizer)\n",
        "            val_score, probs, labels = \\\n",
        "                    train_epoch(epoch, self.model, val_loader, self.loss_fn,\n",
        "                                self.device, names=self.prop_names)\n",
        "\n",
        "            early_stop = self.stopper.step(val_score, self.model)\n",
        "            if val_score < self.min_loss:\n",
        "                eval_dict(probs, labels, self.prop_names, IS_R=self.IS_R)\n",
        "                if epoch > 3:\n",
        "                    print(f'prev min loss {self.min_loss:.3f}, '\n",
        "                        f'now loss {val_score:.3f} |',\n",
        "                        f'save model at epoch: {epoch}')\n",
        "                    torch.save(self.model.state_dict(), self.config['model_path'])\n",
        "                    self.best_epoch = epoch\n",
        "                self.min_loss = val_score\n",
        "            if early_stop: print('early stop'); break\n",
        "\n",
        "        print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
        "        print()\n",
        "        if test_loader != None: self.eval(test_loader, self.config['model_path'])\n",
        "\n"
      ],
      "metadata": {
        "id": "Ol0ea-1aizOn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.preprocess_mols import collect_data\n",
        "met_cls = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "            'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "IS_R = False # is regression task\n",
        "\n",
        "\n",
        "\n",
        "trains, valids, tests = collect_data(met_cls, IS_R=False)\n",
        "batch_size = 128\n",
        "loader_params ={'batch_size': batch_size, 'shuffle': True}\n",
        "\n",
        "train_loader = get_GIN_dataloader(GIN_dataset(trains, met_cls), loader_params)\n",
        "valid_loader = get_GIN_dataloader(GIN_dataset(valids, met_cls), loader_params)\n",
        "p = {'batch_size': batch_size, 'shuffle': False}\n",
        "test_loader = get_GIN_dataloader(GIN_dataset(tests, met_cls), p)\n"
      ],
      "metadata": {
        "id": "yiyogD_didjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_R = False\n",
        "config = {'GIN_out_dim': 256,\n",
        "          'hid_dims': [512],\n",
        "          'out_dim': len(met_cls),\n",
        "          'prop_names': met_cls,\n",
        "          'dropout': 0.1,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': 5e-5,\n",
        "          'wd':1e-5,\n",
        "          'patience': 30,\n",
        "          'model_path': f'ckpt_GIN_MO.pt'}\n",
        "\n",
        "models = PRED(**config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1gBBMCeOf1g",
        "outputId": "607de55e-88fc-4ce9-8a95-cebe7f7aac01"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models.train(train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "AIDqBnhAD1SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuned model\n",
        "config = {'GIN_out_dim': 256,\n",
        "          'hid_dims': [512],\n",
        "          'out_dim': len(met_cls),\n",
        "          'prop_names': met_cls,\n",
        "          'dropout': 0.1,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': 5e-5,\n",
        "          'wd':1e-5,\n",
        "          'patience': 30,\n",
        "          'model_path': f'ckpt_GIN_MO.pt'}\n",
        "\n",
        "models = PRED(**config)\n",
        "print(f\"best epoch: {models.best_epoch}, min loss: {models.min_loss:.4f}\")\n",
        "print()\n",
        "models.eval(test_loader, 'ckpt_GIN_MO.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reCtV00M8xaM",
        "outputId": "046fc0d0-8fd0-485e-cd82-c7aaa25f5cfc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best epoch: 269, min loss: 0.3535\n",
            "\n",
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n",
            "load pretrained model from  ckpt_GIN_MO.pt\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [00:21<00:00,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.420\n",
            "*************** CYP2C19_Veith ***************\n",
            "AUROC: 0.9303 AUPRC: 0.9159 F1: 0.8522\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.863  &  0.863  &          0.845  &     0.860  &0.866  &0.852 &0.930 &   0.725 &   0.916\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "AUROC: 0.9078 AUPRC: 0.7711 F1: 0.6833\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.894  &  0.787  &          0.766  &     0.617  &0.957  &0.683 &0.908 &   0.626 &   0.771\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "AUROC: 0.9211 AUPRC: 0.8868 F1: 0.8063\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.845  &  0.836  &          0.832  &     0.782  &0.890  &0.806 &0.921 &   0.678 &   0.887\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "AUROC: 0.9516 AUPRC: 0.9477 F1: 0.8777\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.884  &  0.884  &          0.873  &     0.882  &0.886  &0.878 &0.952 &   0.767 &   0.948\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "AUROC: 0.9398 AUPRC: 0.8746 F1: 0.8121\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.876  &  0.855  &          0.837  &     0.789  &0.921  &0.812 &0.940 &   0.721 &   0.875\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prev trained model\n",
        "print(f\"best epoch: {models.best_epoch}, min loss: {models.min_loss:.4f}\")\n",
        "print()\n",
        "models.eval(test_loader, 'ckpt_.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HcUw2A3jxZm",
        "outputId": "ce0c780b-09c6-458e-baaf-4787a515cd68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best epoch: 0, min loss: 0.4084\n",
            "\n",
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n",
            "load pretrained model from  ckpt_.pt\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [00:20<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.476\n",
            "*************** CYP2C19_Veith ***************\n",
            "AUROC: 0.9263 AUPRC: 0.9109 F1: 0.8482\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.855  &  0.857  &          0.817  &     0.881  &0.833  &0.848 &0.926 &   0.712 &   0.911\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "AUROC: 0.9005 AUPRC: 0.7450 F1: 0.6331\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.883  &  0.751  &          0.763  &     0.541  &0.962  &0.633 &0.900 &   0.578 &   0.745\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "AUROC: 0.9191 AUPRC: 0.8819 F1: 0.8093\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.841  &  0.838  &          0.799  &     0.820  &0.855  &0.809 &0.919 &   0.673 &   0.882\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "AUROC: 0.9482 AUPRC: 0.9444 F1: 0.8755\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.883  &  0.882  &          0.878  &     0.873  &0.892  &0.875 &0.948 &   0.765 &   0.944\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "AUROC: 0.9312 AUPRC: 0.8585 F1: 0.7914\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.859  &  0.842  &          0.795  &     0.788  &0.896  &0.791 &0.931 &   0.685 &   0.858\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOkelA0QzzRF",
        "outputId": "c561d6db-4892-473d-f852-ae639c1ead90"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n",
            "load pretrained model from  ckpt_.pt\n",
            "Evaluate on test sets\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:05<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.302\n",
            "*************** CYP2D6_Veith ***************\n",
            "AUROC: 0.9052 AUPRC: 0.7518 F1: 0.6485\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.887  &  0.761  &          0.768  &     0.561  &0.961  &0.649 &0.905 &   0.593 &   0.752\n",
            "ROC-AUC: 0.761\n",
            "PR-AUC: 0.512\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_e = {'GIN_out_dim': 256,\n",
        "          'hid_dims': [512],\n",
        "          'out_dim': len(met_cls),\n",
        "          'dropout': 0.,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': 1e-4,\n",
        "          'wd':1e-5}\n",
        "models = PRED(**conf_e)\n",
        "\n",
        "models.model.load_state_dict(torch.load('ckpt_.pt', map_location='cuda'))\n",
        "eval_AP(models.model, False, test_loader, met_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwbcdzKnWGD",
        "outputId": "1595f133-c644-4510-d353-da2605be19dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test sets\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [00:20<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.432\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.858  &  0.860  &          0.826  &     0.875  &0.844  &0.850 &0.927 &   0.717 &   0.910\n",
            "ROC-AUC: 0.860\n",
            "PR-AUC: 0.781\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.883  &  0.760  &          0.747  &     0.564  &0.957  &0.643 &0.902 &   0.583 &   0.741\n",
            "ROC-AUC: 0.760\n",
            "PR-AUC: 0.502\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.837  &  0.833  &          0.798  &     0.811  &0.856  &0.804 &0.919 &   0.665 &   0.883\n",
            "ROC-AUC: 0.833\n",
            "PR-AUC: 0.725\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.885  &  0.884  &          0.887  &     0.866  &0.901  &0.876 &0.950 &   0.769 &   0.946\n",
            "ROC-AUC: 0.884\n",
            "PR-AUC: 0.832\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.870  &  0.850  &          0.821  &     0.788  &0.912  &0.804 &0.937 &   0.707 &   0.869\n",
            "ROC-AUC: 0.850\n",
            "PR-AUC: 0.718\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def cal_prob(model, IS_R, test_loader, certain_name:str, names):\n",
        "#     y_probs = {}\n",
        "#     for j, name in enumerate(names):\n",
        "#         if certain_name == name: break\n",
        "#     for i, batch_data in enumerate(test_loader):\n",
        "#         bg, labels = batch_data\n",
        "#         bg, labels = bg.to(device), labels.to(device)\n",
        "#         pred = model(bg)\n",
        "#         mask = labels == MASK\n",
        "#         pred = pred[:, j].reshape(len(pred), 1)\n",
        "#         probs = F.sigmoid(pred[~mask])\n",
        "#         probs = probs.cpu().detach().numpy().tolist()\n",
        "#         if i ==0: y_probs[name] = probs\n",
        "#         else: y_probs[name] += probs\n",
        "#     return y_probs\n",
        "\n",
        "# from tdc.benchmark_group import admet_group\n",
        "# group = admet_group(path = 'data/')\n",
        "# pred_list = []\n",
        "# for seed in [0, 1, 2, 3, 4, 5]:\n",
        "#     print(f'seed : {seed}')\n",
        "#     pred_dict = {}\n",
        "#     for i, name in tqdm(enumerate(met_cls), total=len(met_cls)):\n",
        "#         benchmark = group.get(name)\n",
        "#         name_spec = benchmark['name']\n",
        "#         if name.lower() == name_spec:\n",
        "#             test = benchmark['test']\n",
        "#             test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "#             test_loader = get_GIN_dataloader(GIN_dataset(test, [name]), p)\n",
        "\n",
        "#             probs = cal_prob(models.model, False, test_loader, name, met_cls)\n",
        "#             preds = get_preds(0.5, probs[name])\n",
        "#             pred_dict[name_spec] = preds\n",
        "#             pred_list.append(pred_dict)"
      ],
      "metadata": {
        "id": "RH6-zrHKns3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}