{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4od1ZccpUIR+hVQCOp+ZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/examples/ADMET_GIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-bdNWG8iOx0",
        "outputId": "59ec65f4-0160-416a-dd27-e46e5bba23a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet"
      ],
      "metadata": {
        "id": "R8dRwvfliWV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paVNvIN-iXcT",
        "outputId": "d01fca99-3cbb-4487-aa64-c3620120d041"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import walk\n",
        "import os\n",
        "files = next(walk('/content/drive/MyDrive/ADMET/'), (None, None, []))[2]\n",
        "for file in files:\n",
        "    if isinstance(file, str):\n",
        "        file_type = file.split('.')[-1]\n",
        "        # print(file_type)\n",
        "        if file_type == 'bin' or file_type == 'pth':\n",
        "            os.remove(file)"
      ],
      "metadata": {
        "id": "Apqv_McBiaio"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet"
      ],
      "metadata": {
        "id": "IzXXU3t4icXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.preprocess_mols import collect_data\n",
        "met_cls = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "            'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "IS_R = False # is regression task\n",
        "trains, valids, tests = collect_data(met_cls, IS_R=False)"
      ],
      "metadata": {
        "id": "yiyogD_didjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.model import load_pretrained\n",
        "from dgl.nn.pytorch.glob import AvgPooling\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda'\n",
        "class GIN(nn.Module):\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/encoders.py#L392\n",
        "    \"\"\"\n",
        "\t## adapted from https://github.com/awslabs/dgl-lifesci/blob/2fbf5fd6aca92675b709b6f1c3bc3c6ad5434e96/examples/property_prediction/moleculenet/utils.py#L76\n",
        "    def __init__(self, predictor_dim):\n",
        "        super(GIN, self).__init__()\n",
        "        self.gnn = load_pretrained('gin_supervised_contextpred')\n",
        "        self.readout = AvgPooling()\n",
        "        self.transform = nn.Linear(300, 200)\n",
        "        self.final = nn.Linear(200, predictor_dim)\n",
        "        self.out_dim = predictor_dim\n",
        "    def forward(self, bg):\n",
        "        # bg = bg.to(device)\n",
        "        node_feats = [\n",
        "            bg.ndata.pop('atomic_number'),\n",
        "            bg.ndata.pop('chirality_type')\n",
        "        ]\n",
        "        edge_feats = [\n",
        "            bg.edata.pop('bond_type'),\n",
        "            bg.edata.pop('bond_direction_type')\n",
        "        ]\n",
        "\n",
        "        node_feats = self.gnn(bg, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(bg, node_feats)\n",
        "        graph_feats = self.transform(graph_feats)\n",
        "        return self.final(graph_feats)"
      ],
      "metadata": {
        "id": "Hndkql-rifp7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "import torch\n",
        "\n",
        "from dgllife.utils import smiles_to_bigraph, PretrainAtomFeaturizer, PretrainBondFeaturizer\n",
        "MASK = -100\n",
        "\n",
        "class GIN_dataset(Dataset):\n",
        "    def __init__(self, df, names, mask=MASK):\n",
        "        df = df.fillna(mask)\n",
        "        self.names = names\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.props = self.df[names]\n",
        "        self.node_featurizer = PretrainAtomFeaturizer()\n",
        "        self.edge_featurizer = PretrainBondFeaturizer()\n",
        "        self.fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
        "    def __len__(self): return self.len\n",
        "    def __getitem__(self, idx):\n",
        "        v_d = self.df.iloc[idx]['Drug']\n",
        "        v_d = self.fc(smiles=v_d, node_featurizer = self.node_featurizer,\n",
        "                      edge_featurizer = self.edge_featurizer)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return v_d, label"
      ],
      "metadata": {
        "id": "125Wbwz4itai"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "def get_GIN_dataloader(datasets, loader_params):\n",
        "    def dgl_collate_func(data):\n",
        "        x, labels = map(list, zip(*data))\n",
        "        bg = dgl.batch(x)\n",
        "        labels = torch.stack(labels, dim=0)\n",
        "        bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "        bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "        return bg, labels\n",
        "    loader_params['collate_fn'] = dgl_collate_func\n",
        "    return DataLoader(datasets, **loader_params)"
      ],
      "metadata": {
        "id": "hsovfj4QiwEQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "loader_params ={'batch_size': batch_size, 'shuffle': True}\n",
        "\n",
        "train_loader = get_GIN_dataloader(GIN_dataset(trains, met_cls), loader_params)\n",
        "valid_loader = get_GIN_dataloader(GIN_dataset(valids, met_cls), loader_params)\n",
        "p = {'batch_size': batch_size, 'shuffle': False}\n",
        "test_loader = get_GIN_dataloader(GIN_dataset(tests, met_cls), p)"
      ],
      "metadata": {
        "id": "fLGpBR21ixWx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from tqdm import tqdm\n",
        "def train_epoch(epoch, model, loader, loss_func, device,\n",
        "                optimizer=None, MASK=-100):\n",
        "    if optimizer==None: model.eval(); train_type='Valid'\n",
        "    else: model.train(); train_type='Train'\n",
        "    losses = 0\n",
        "    # train_meter = Meter()\n",
        "    for batch in tqdm(loader, total=len(loader), desc=f'Epoch {epoch}'):\n",
        "        bg, labels = batch\n",
        "        bg, labels = bg.to(device), labels.to(device)\n",
        "        mask = labels == MASK\n",
        "        pred = model(bg)\n",
        "        loss = loss_func(pred[~mask], labels[~mask])\n",
        "        del mask\n",
        "        if optimizer != None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        losses += loss.item()\n",
        "    total_loss = losses / len(loader.dataset)\n",
        "    print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "1oWvT4U2jc55"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_R = False\n",
        "config = {'GIN_out_dim': len(met_cls),\n",
        "          'hid_dims': [32],\n",
        "          'out_dim': len(met_cls),\n",
        "          'dropout': 0.3,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': 1e-4,\n",
        "          'wd':1e-5}\n",
        "class PRED:\n",
        "    def __init__(self, **config):\n",
        "        cuda = torch.cuda.is_available()\n",
        "        if cuda: self.device = 'cuda'\n",
        "        else:    self.device = 'cpu'\n",
        "        # self.model_drug = GIN(config['GIN_out_dim']).to(self.device)\n",
        "        # model = TL(self.model_drug, config['hid_dims'],\n",
        "        #            config['out_dim'], config['dropout'])\n",
        "        # self.model = model.to(self.device)\n",
        "\n",
        "        self.model = GIN(config['GIN_out_dim']).to(self.device)\n",
        "\n",
        "        self.IS_R = config['IS_R']\n",
        "        if self.IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "        else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
        "                    lr=config['lr'], weight_decay=config['wd'])\n",
        "        self.stopper = EarlyStopping(mode='lower', patience=30)\n",
        "        self.min_loss = 10000\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
        "\n",
        "    def train(self, data_loader, val_data_loader, train_epoch=train_epoch):\n",
        "        if self.best_epoch != 0:\n",
        "            self.load_model('ckpt_.pt')\n",
        "        for epoch in range(500):\n",
        "            score = train_epoch(epoch, self.model, data_loader, self.loss_fn,\n",
        "                                self.device, self.optimizer)\n",
        "            val_score = train_epoch(epoch, self.model, val_data_loader,\n",
        "                                    self.loss_fn, self.device)\n",
        "            early_stop = self.stopper.step(val_score, self.model)\n",
        "            if val_score < self.min_loss and epoch > 3:\n",
        "                print(f'prev min loss {self.min_loss:.3f}, '\n",
        "                      f'now loss {val_score:.3f} |',\n",
        "                      f'save model at epoch: {epoch}')\n",
        "                self.min_loss = val_score\n",
        "                torch.save(self.model.state_dict(), 'ckpt_.pt')\n",
        "                self.best_epoch = epoch\n",
        "            if early_stop: print('early stop'); break\n"
      ],
      "metadata": {
        "id": "Ol0ea-1aizOn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = PRED(**config)\n",
        "# models.load_model('ckpt_tr.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXptP2BTjodZ",
        "outputId": "a4c1d401-2a0b-428e-aab8-ccdebf6220a7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models.train(train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "Stpy6X5VjqZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"best epoch: {models.best_epoch}, min loss: {models.min_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HcUw2A3jxZm",
        "outputId": "117f55af-110f-42c7-8b9e-6141b0f1c16f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best epoch: 42, min loss: 0.3673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "\n",
        "\n",
        "\n",
        "def eval_AP(model, IS_R, test_loader, names):\n",
        "    print('Evaluate on test sets')\n",
        "    # model = model.cpu()\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    y_probs = {}\n",
        "    y_label = {}\n",
        "    if IS_R: print('using MSELoss')\n",
        "    else: print('using BCELOSSwithdigits')\n",
        "    if IS_R: loss_fn = nn.MSELoss(reduction='sum') # if regression\n",
        "    else: loss_fn = nn.BCEWithLogitsLoss(reduction='sum') # if classification\n",
        "    for i, batch_data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "        bg, labels = batch_data\n",
        "        # bg, labels = bg.to('cpu'), labels.to('cpu')\n",
        "        bg, labels = bg.to(device), labels.to(device)\n",
        "        # print(bg.device)\n",
        "        pred = model(bg)\n",
        "        # mask = masks < 1\n",
        "        mask = labels == MASK\n",
        "        loss = loss_fn(pred[~mask], labels[~mask])\n",
        "        # test_meter.update(pred, labels, masks)\n",
        "        total_loss += loss.item()\n",
        "        for j, name in enumerate(names):\n",
        "            probs = F.sigmoid(pred[:, j][~mask[:, j]])\n",
        "            label = labels[:, j][~mask[:, j]]\n",
        "            probs = probs.cpu().detach().numpy().tolist()\n",
        "            label = label.cpu().detach().numpy().tolist()\n",
        "            if i ==0: y_probs[name], y_label[name] = probs, label\n",
        "            else:\n",
        "                y_probs[name] += probs\n",
        "                y_label[name] += label\n",
        "\n",
        "    total_loss /= len(test_loader.dataset)\n",
        "    print(f'total_loss: {total_loss:.3f}')\n",
        "\n",
        "\n",
        "    if IS_R == False: # classification task\n",
        "        for i, name in enumerate(names):\n",
        "            print('*'*15, name, '*'*15)\n",
        "            probs = y_probs[name]\n",
        "            label = y_label[name]\n",
        "            assert len(probs) == len(label)\n",
        "            preds = get_preds(0.5, probs)\n",
        "            evaluate(label, preds, probs)\n",
        "\n",
        "            print()\n",
        "    return y_probs"
      ],
      "metadata": {
        "id": "xbH28Nfclm0A"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models.model.load_state_dict(torch.load('ckpt_.pt', map_location='cuda'))\n",
        "eval_AP(models.model, False, test_loader, met_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwbcdzKnWGD",
        "outputId": "1595f133-c644-4510-d353-da2605be19dc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test sets\n",
            "using BCELOSSwithdigits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [00:20<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss: 0.432\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.858  &  0.860  &          0.826  &     0.875  &0.844  &0.850 &0.927 &   0.717 &   0.910\n",
            "ROC-AUC: 0.860\n",
            "PR-AUC: 0.781\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.883  &  0.760  &          0.747  &     0.564  &0.957  &0.643 &0.902 &   0.583 &   0.741\n",
            "ROC-AUC: 0.760\n",
            "PR-AUC: 0.502\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.837  &  0.833  &          0.798  &     0.811  &0.856  &0.804 &0.919 &   0.665 &   0.883\n",
            "ROC-AUC: 0.833\n",
            "PR-AUC: 0.725\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.885  &  0.884  &          0.887  &     0.866  &0.901  &0.876 &0.950 &   0.769 &   0.946\n",
            "ROC-AUC: 0.884\n",
            "PR-AUC: 0.832\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.870  &  0.850  &          0.821  &     0.788  &0.912  &0.804 &0.937 &   0.707 &   0.869\n",
            "ROC-AUC: 0.850\n",
            "PR-AUC: 0.718\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_prob(model, IS_R, test_loader, certain_name:str, names):\n",
        "    y_probs = {}\n",
        "    for j, name in enumerate(names):\n",
        "        if certain_name == name: break\n",
        "    for i, batch_data in enumerate(test_loader):\n",
        "        bg, labels = batch_data\n",
        "        bg, labels = bg.to(device), labels.to(device)\n",
        "        pred = model(bg)\n",
        "        mask = labels == MASK\n",
        "        pred = pred[:, j].reshape(len(pred), 1)\n",
        "        probs = F.sigmoid(pred[~mask])\n",
        "        probs = probs.cpu().detach().numpy().tolist()\n",
        "        if i ==0: y_probs[name] = probs\n",
        "        else: y_probs[name] += probs\n",
        "    return y_probs\n",
        "\n",
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "pred_list = []\n",
        "for seed in [0, 1, 2, 3, 4, 5]:\n",
        "    print(f'seed : {seed}')\n",
        "    pred_dict = {}\n",
        "    for i, name in tqdm(enumerate(met_cls), total=len(met_cls)):\n",
        "        benchmark = group.get(name)\n",
        "        name_spec = benchmark['name']\n",
        "        if name.lower() == name_spec:\n",
        "            test = benchmark['test']\n",
        "            test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "            test_loader = get_GIN_dataloader(GIN_dataset(test, [name]), p)\n",
        "\n",
        "            probs = cal_prob(models.model, False, test_loader, name, met_cls)\n",
        "            preds = get_preds(0.5, probs[name])\n",
        "            pred_dict[name_spec] = preds\n",
        "            pred_list.append(pred_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH6-zrHKns3H",
        "outputId": "0f248cd4-c5f7-46e3-d2eb-62e4a30d8d48"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed : 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.16s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = group.evaluate_many(pred_list)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTPmY4oiv3ru",
        "outputId": "1b5d3cf9-29e0-4c58-fcd8-8d8697be5397"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cyp2d6_veith': [0.551, 0.0],\n",
              " 'cyp3a4_veith': [0.759, 0.0],\n",
              " 'cyp2c9_veith': [0.692, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}