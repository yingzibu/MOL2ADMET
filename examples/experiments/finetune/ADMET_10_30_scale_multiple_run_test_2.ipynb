{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yBVKQx4XPA6F"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4hPaTqyoOAaK6jzd0iBA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/examples/experiments/finetune/ADMET_10_30_scale_multiple_run_test_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5PqpU0dOt2C",
        "outputId": "f06d3207-3838-47dc-defd-bd3aac53822e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print('cuda: ', torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJtA2o5BO7lI",
        "outputId": "1a411e9f-cfa9-4194-b80c-aecdd82c2520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "cuda:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "! pip install selfies  --quiet\n",
        "! pip install pubchempy --quiet\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet\n",
        "\n",
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet"
      ],
      "metadata": {
        "id": "NppdDFqCO-1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "yBVKQx4XPA6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import walk\n",
        "import os\n",
        "file_types = ['bin', 'pth']\n",
        "\n",
        "# clean certain type of file in path\n",
        "def clean_files(path='/content/drive/MyDrive/ADMET/', file_types = ['pth']):\n",
        "    files = next(walk(path), (None, None, []))[2]\n",
        "    for file in files:\n",
        "        if isinstance(file, str):\n",
        "            file_type = file.split('.')[-1]\n",
        "            if file_type in file_types:\n",
        "                os.remove(file); print(f'{file} removed from {path}')\n",
        "# clean_files()"
      ],
      "metadata": {
        "id": "0nr5J_vuPAzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G7PYVRJPFeJ",
        "outputId": "9bd5dee4-2bca-4725-eed6-27a405409562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test scripts.func_utils.py\n",
        "\n",
        "from scripts.func_utils import make_path, convert_with_qed_sa, get_min, \\\n",
        "                                plot_loss, plot_performance\n",
        "\n",
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "from scripts.model_architecture import *\n",
        "from scripts.dataset import *\n",
        "from scripts.train import *\n",
        "from tdc.single_pred import ADME\n",
        "from tdc.single_pred import Tox\n",
        "from tdc.utils import retrieve_label_name_list\n",
        "import pandas as pd\n",
        "\n",
        "label_list = retrieve_label_name_list('herg_central')\n",
        "\n",
        "def collect_data_10_27(names:list, clean_mol_=False, verbose=False):\n",
        "    if isinstance(names, str): names = [names]\n",
        "    name_adme = ['Caco2_Wang', 'Lipophilicity_AstraZeneca',\n",
        "                 'HydrationFreeEnergy_FreeSolv',\n",
        "                 'Solubility_AqSolDB'] # regression task\n",
        "    name_adme+= ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "                'CYP1A2_Veith', 'CYP2C9_Veith'] + \\\n",
        "                ['BBB_Martins', 'Bioavailability_Ma', 'Pgp_Broccatelli',\n",
        "                 'HIA_Hou','PAMPA_NCATS'] # classify\n",
        "    print('collect data for: ', names)\n",
        "    label_list = retrieve_label_name_list('herg_central')\n",
        "    for i, name in enumerate(names):\n",
        "        if verbose: print('*'*15, name, '*'*15)\n",
        "        if name in label_list: data = Tox(name='herg_central', label_name=name)\n",
        "        elif name in name_adme: data = ADME(name=name)\n",
        "        else:\n",
        "            try: data = Tox(name=name)\n",
        "            except: print('cannot read data!'); return\n",
        "            if verbose: data.label_distribution()\n",
        "            # data.label_distribution()\n",
        "        split = data.get_split()\n",
        "        train, valid, test = split['train'], split['valid'], split['test']\n",
        "        if clean_mol_:\n",
        "            train, valid, test = clean_mol(train), clean_mol(valid), clean_mol(test)\n",
        "\n",
        "        train = rename_cols(train[['Drug', 'Y']], name)\n",
        "        valid = rename_cols(valid[['Drug', 'Y']], name)\n",
        "        test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "\n",
        "        if i == 0: trains, valids, tests = train.copy(), valid.copy(), test.copy()\n",
        "        else:\n",
        "            trains = trains.merge(train, how='outer')\n",
        "            valids = valids.merge(valid, how='outer')\n",
        "            tests = tests.merge(test, how='outer')\n",
        "\n",
        "    return trains, valids, tests\n",
        "# trains, valids, tests = collect_data_10_27(names_reg[0])\n",
        "from scripts.get_vocab import *\n",
        "\n",
        "def get_multi_loader(trains, valids, tests, config):\n",
        "    names = config['prop_names']\n",
        "    vocab = None if 'vocab' not in config else config['vocab']\n",
        "    batch_size = config['batch_size']\n",
        "    model_type = config['model_type']\n",
        "\n",
        "    print('---> loader for', names)\n",
        "    params_ = {'batch_size': batch_size, 'shuffle': True,\n",
        "               'drop_last': False, 'num_workers': 0}\n",
        "    param_t = {'batch_size': batch_size, 'shuffle': False,\n",
        "               'drop_last': False, 'num_workers': 0}\n",
        "    if model_type == 'RNN'and vocab == None:\n",
        "        df = pd.concat([trains, valids, tests], ignore_index=True, axis=0)\n",
        "        vocab = get_vocab(df)\n",
        "    train_loader = get_loader(trains, names, params_, model_type, vocab)\n",
        "    valid_loader = get_loader(valids, names, params_, model_type, vocab)\n",
        "    test_loader  = get_loader(tests,  names, param_t, model_type, vocab)\n",
        "    return train_loader, valid_loader, test_loader, vocab\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLnu5z1pPGUC",
        "outputId": "e5c935d0-d4d7-4982-85b1-73c2e6cc2b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB_TYPE: smiles, could change from ['char', 'smiles', 'selfies'] at get_vocab.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params"
      ],
      "metadata": {
        "id": "iU4ke8gFPKir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CONSTANTS ###\n",
        "names_reg = ['Caco2_Wang', 'Lipophilicity_AstraZeneca',\n",
        "         'HydrationFreeEnergy_FreeSolv', 'Solubility_AqSolDB', 'LD50_Zhu'] # regression task\n",
        "names_cls = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "             'CYP1A2_Veith', 'CYP2C9_Veith'] + \\\n",
        "            ['BBB_Martins', 'Bioavailability_Ma',\n",
        "             'Pgp_Broccatelli', 'HIA_Hou','PAMPA_NCATS'] + \\\n",
        "            ['hERG_Karim', 'AMES']\n",
        "\n",
        "names_dict = {}\n",
        "for name in names_reg + names_cls:\n",
        "    if name in names_reg:   names_dict[name] = True  # regression task\n",
        "    elif name in names_cls: names_dict[name] = False # classification task\n",
        "names_all = list(names_dict.keys())\n",
        "\n",
        "model_types = ['MLP', 'AttentiveFP', 'GIN', 'RNN']"
      ],
      "metadata": {
        "id": "zmpR8f-VPGWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 256\n",
        "hid_dims = [128, 64, 16]\n",
        "dropout = 0.5\n",
        "lr = 3e-4\n",
        "wd = 1e-5\n",
        "MAX_EPOCH = 1000\n",
        "patience = 30           # stop if loss no decrease after epochs # patience\n",
        "verbose_frequency = 100 # print evaluation every # verbose_frequency epoch\n",
        "batch_size = 128\n",
        "\n",
        "# special for AttentiveFP\n",
        "graph_feat_size = 300\n",
        "n_layers = 5\n",
        "num_timesteps = 1   # times of updating the graph representations with GRU\n",
        "\n",
        "# special for GIN: pretrain model types for selection:\n",
        "pre_models_GIN = ['gin_supervised_contextpred', 'gin_supervised_infomax',\n",
        "                     'gin_supervised_edgepred', 'gin_supervised_masking']\n",
        "pre_model_num = 0    # choose from pre_models for GIN\n",
        "\n",
        "\n",
        "# if VOCAB_TYPE == 'smiles':\n",
        "import yaml\n",
        "def load_vocab(VOCAB_TYPE):\n",
        "    try:\n",
        "        with open(f'vocab/{VOCAB_TYPE}.yml', 'r') as f: data = yaml.safe_load(f)\n",
        "        vocab = data['vocab']; assert VOCAB_TYPE == data['vocab_type']\n",
        "    except: vocab = None\n",
        "    return vocab\n",
        "\n",
        "# special for RNN:\n",
        "VOCAB = load_vocab(VOCAB_TYPE)\n",
        "Bid = True\n",
        "GRU_num_layers = 3\n",
        "GRU_dim = 256\n",
        "\n",
        "\n",
        "\n",
        "scale_dict = None\n",
        "\n",
        "def get_config(model_type, names,\n",
        "               pre_model_num=pre_model_num, scale_dict=scale_dict):\n",
        "    \"\"\"\n",
        "    Get config to initialize model\n",
        "        param model_type: str, ['MLP', 'AttentiveFP', 'GIN', 'RNN']\n",
        "        param names: list, task names\n",
        "        param scale_dict: dict,\n",
        "            if the task is regression, could scale label values\n",
        "                            {name: [value_min, value_max], ...}\n",
        "        param pre_model_num: int, [0, 1, 2, 3]\n",
        "            if model_type is 'GIN', 4 types of pretrained models to choose from\n",
        "    Returns config that could be used as PRED(**config)\n",
        "    \"\"\"\n",
        "    pre_models_GIN = ['gin_supervised_contextpred', 'gin_supervised_infomax',\n",
        "                         'gin_supervised_edgepred', 'gin_supervised_masking']\n",
        "\n",
        "    # print(scale_dict)\n",
        "    if isinstance(names, str): names = [names]\n",
        "    IS_R = [names_dict[name] for name in names]\n",
        "    config_MLP = {'model_type': 'MLP',\n",
        "            'in_dim': 167,\n",
        "            'hid_dims': hid_dims,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'IS_R': IS_R,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr*2, # due to the simplicity of MLP, use larger lr\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'verbose_freq': verbose_frequency,\n",
        "            'model_path': f'ckpt_MLP.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    config_ATF = {'model_type': 'AttentiveFP',\n",
        "            'graph_feat_size': graph_feat_size,\n",
        "            'num_timesteps': num_timesteps,\n",
        "            'n_layers': n_layers,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'IS_R': IS_R,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr,\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'verbose_freq': verbose_frequency,\n",
        "            'model_path': 'ckpt_AT.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    config_GIN = {'model_type': 'GIN',\n",
        "            'pretrain_model': pre_models_GIN[pre_model_num],\n",
        "            'in_dim': in_dim,\n",
        "            'hid_dims': hid_dims,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'batch_size': batch_size,\n",
        "            'IS_R': IS_R,\n",
        "            'lr': lr,\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'verbose_freq': verbose_frequency,\n",
        "            'model_path': f'ckpt_GIN_{pre_models_GIN[pre_model_num]}.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    config_RNN = {'model_type': 'RNN',\n",
        "              'vocab': VOCAB,\n",
        "              'vocab_type': VOCAB_TYPE,\n",
        "              'Bidirect': Bid,\n",
        "              'num_layers': GRU_num_layers,\n",
        "              'GRU_dim': GRU_dim,\n",
        "              'out_dim': len(names),\n",
        "              'prop_names': names,\n",
        "              'dropout': dropout,\n",
        "              'IS_R': IS_R,\n",
        "              'device': 'cuda',\n",
        "              'batch_size': batch_size,\n",
        "              'lr': lr,\n",
        "              'wd': wd,\n",
        "              'patience': patience,\n",
        "              'verbose_freq': verbose_frequency,\n",
        "              'model_path': f'ckpt_RNN_{VOCAB_TYPE}.pt',\n",
        "              'scale_dict': scale_dict}\n",
        "\n",
        "    if model_type == 'MLP':           con_MO = config_MLP\n",
        "    elif model_type == 'AttentiveFP': con_MO = config_ATF\n",
        "    elif model_type == 'GIN':         con_MO = config_GIN\n",
        "    elif model_type == 'RNN':         con_MO = config_RNN\n",
        "    else: print('Error !{MLP, AttentiveFP, GIN, RNN}'); return None\n",
        "    con_MO['config_path'] = con_MO['model_path'].split('.')[0] + '.yml'\n",
        "    # different weight of task, initial weight the same\n",
        "    con_MO['weight_loss'] = [float(1.0/len(names))] * len(names)\n",
        "    con_MO['MAX_EPOCH'] = MAX_EPOCH\n",
        "    return con_MO\n",
        "\n",
        "\n",
        "import yaml\n",
        "def yml_report(yml_path, recalculate=False, ver=False):\n",
        "    \"\"\"\n",
        "    given yml path or yml data, return the test set performance\n",
        "    param\n",
        "        yml_path        : str,  the path of yml file\n",
        "        recalculate     : bool, if true, will calculate from scratch\n",
        "        ver             : bool, if true, will print detailed configs\n",
        "    return perfm_dict   : dict, contain performance and test loss\n",
        "    \"\"\"\n",
        "    if isinstance(yml_path, str): # the path string was input\n",
        "        with open(yml_path, 'r') as f: data = yaml.safe_load(f)\n",
        "    elif isinstance(yml_path, dict):   data = yml_path # data was input\n",
        "\n",
        "    config = data['config']\n",
        "    model_type = config['model_type']\n",
        "    task_names = config['prop_names']\n",
        "    perfm_dict =  data['performance']\n",
        "\n",
        "    if len(perfm_dict) != 0 and recalculate == False:\n",
        "        # during training, has evaluted test set, no need to calculate again\n",
        "        # However for regression, the pred vs true value for test is not saved\n",
        "        # if need the regression pred vs true value graph, need recalculate\n",
        "        if ver: # print model config, and the training saved info\n",
        "            print('#'*68); print('#'*30, 'CONFIG', '#'*30); print('#'*68)\n",
        "            for i, j in config.items(): print(i, ':', j)\n",
        "            print('#'*68)\n",
        "            print('Model parameters: ', data['params_num'])\n",
        "            times_list = data['times_list']\n",
        "            print(f'Train time: {np.mean(times_list):.3f}'\n",
        "                  f'+/-{np.std(times_list):.3f} ms')\n",
        "            print(f\"best epoch: {data['best_epoch']}, \",\n",
        "                  f\"min loss: {data['min_loss']:.4f}\")\n",
        "            plot_loss(data['train_dict'], data['valid_dict'], name='valid',\n",
        "                      title_name= f'loss during training {model_type}')\n",
        "\n",
        "    else: # recalculate from scratch using test data\n",
        "        vocab = None if 'vocab' not in config else config['vocab']\n",
        "        trains, valids, tests = collect_data_10_27(task_names)\n",
        "        if config['scale_dict'] != None: # scale is done\n",
        "            trains, valids, tests, dict_scale = scale(trains, valids, tests)\n",
        "            assert config['scale_dict'] == dict_scale\n",
        "        batch_size = config['batch_size']\n",
        "        param_t = {'batch_size': batch_size, 'shuffle': False,\n",
        "                'drop_last': False, 'num_workers': 0}\n",
        "        test_loader = get_loader(tests, task_names, param_t, model_type, vocab)\n",
        "        models = PRED(**config); models.load_status(data)\n",
        "        outputs = models.eval(test_loader, ver=ver)\n",
        "        perfm_dict = outputs[0]\n",
        "    return perfm_dict\n",
        "# def yml_report(yml_path, recalculate=False, ver=False):\n",
        "#     \"\"\"\n",
        "#     given yml path, return the test set performance\n",
        "#     param\n",
        "#         yml_path        : str,  the path of yml file\n",
        "#         recalculate     : bool, if true, will calculate from scratch\n",
        "#         ver             : bool, if true, will print detailed configs\n",
        "#     return perfm_dict   : dict, contain performance and test loss\n",
        "#     \"\"\"\n",
        "#     with open(yml_path, 'r') as f: data = yaml.safe_load(f)\n",
        "#     config = data['config']\n",
        "#     model_type = config['model_type']\n",
        "#     task_names = config['prop_names']\n",
        "#     perfm_dict =  data['performance']\n",
        "\n",
        "#     if len(perfm_dict) != 0 and recalculate == False:\n",
        "#         # during training, has evaluted test set, no need to calculate again\n",
        "#         # However for regression, the pred vs true value for test is not saved\n",
        "#         # if need the regression pred vs true value graph, need recalculate\n",
        "#         if ver: # print model config, and the training saved info\n",
        "#             print('#'*68); print('#'*30, 'CONFIG', '#'*30); print('#'*68)\n",
        "#             for i, j in config.items(): print(i, ':', j)\n",
        "#             print('#'*68)\n",
        "#             print('Model parameters: ', data['params_num'])\n",
        "#             times_list = data['times_list']\n",
        "#             print(f'Train time: {np.mean(times_list):.3f}'\n",
        "#                   f'+/-{np.std(times_list):.3f} ms')\n",
        "#             print(f\"best epoch: {data['best_epoch']}, min loss: {data['min_loss']:.4f}\")\n",
        "#             plot_loss(data['train_dict'], data['valid_dict'], name='valid',\n",
        "#                       title_name= f'loss during training {model_type}')\n",
        "#         # return perfm_dict\n",
        "\n",
        "#     else: # recalculate from scratch using test data\n",
        "#         vocab = None if 'vocab' not in config else config['vocab']\n",
        "#         trains, valids, tests = collect_data_10_27(task_names)\n",
        "#         if config['scale_dict'] != None: # scale is done\n",
        "#             trains, valids, tests, dict_scale = scale(trains, valids, tests)\n",
        "#             assert config['scale_dict'] == dict_scale\n",
        "#         batch_size = config['batch_size']\n",
        "#         param_t = {'batch_size': batch_size, 'shuffle': False,\n",
        "#                 'drop_last': False, 'num_workers': 0}\n",
        "#         test_loader = get_loader(tests, task_names, param_t, model_type, vocab)\n",
        "#         models = PRED(**config); models.load_status(data)\n",
        "#         outputs = models.eval(test_loader, ver=ver)\n",
        "#         perfm_dict = outputs[0]\n",
        "#     return perfm_dict\n",
        "\n",
        "import numpy as np\n",
        "cls_metrics = ['acc', 'w_acc', 'prec', 'recall', 'sp', 'f1', 'auc', 'mcc', 'ap']\n",
        "reg_metrics = ['mae', 'mse', 'rmse', 'r2']\n",
        "\n",
        "# evaluate performance list, if directly from yml_file saved performance (dict)\n",
        "# need to [yml_file_data['performance']] to convert dict into list\n",
        "def eval_perf_list(perfs:list, name:list,\n",
        "                   reg_metrics=reg_metrics,\n",
        "                   cls_metrics=cls_metrics):\n",
        "    \"\"\"\n",
        "    The same model type for multiple times, performance saved in list perfs\n",
        "    Aim: evaluate performance of name, calculate mean and std for multiple run\n",
        "    \"\"\"\n",
        "\n",
        "    repeat_time = len(perfs) # the same model was run for # repeat_time times\n",
        "    if repeat_time > 1: # multiple run, find the lowest loss\n",
        "        loss_list = [p['loss'] for p in perfs]\n",
        "        best_model_idx = np.argmin(loss_list) # has the lowest loss\n",
        "        # print(f'idx {best_model_idx} has the lowest loss')\n",
        "        best_perf = perfs[best_model_idx]\n",
        "    else: best_perf = None\n",
        "    for n in name:\n",
        "        IS_R = names_dict[n]\n",
        "        # print(n, '\\tRegression?', IS_R);\n",
        "        if IS_R: ms = reg_metrics # is regression,     use reg_metrics (#4)\n",
        "        else:    ms = cls_metrics # is classification, use cls_metrics (#9)\n",
        "        results = {}\n",
        "        for idx, i in enumerate(perfs): # access idx_th evaluation in perfs\n",
        "            r = i[n]; results[idx] = r  # collect the evaluation for name n\n",
        "\n",
        "        means, stds = [], []\n",
        "        print('*'*20, n, '*'*20, end='\\n\\t')\n",
        "        for k in ms: print('\\t', k, end = ' \\t ')\n",
        "        print()\n",
        "        for idx_v in range(len(r)):\n",
        "            cur_values = []\n",
        "            for idx in range(repeat_time):\n",
        "                cur_v = results[idx][idx_v]; cur_values.append(cur_v)\n",
        "            mean_here, std_here = np.mean(cur_values), np.std(cur_values)\n",
        "            means.append(mean_here); stds.append(std_here)\n",
        "            # print(f'{ms[idx_v]}\\t: {mean_here:.3f} +/- {std_here:.3f}')\n",
        "\n",
        "        for idx_final, (i, j) in enumerate(zip(means, stds)):\n",
        "            if idx_final == 0: print(end='\\t| ')\n",
        "            print(f'{i:.3f} +/- {j:.3f}', end=' | ')\n",
        "        if best_perf != None:\n",
        "            print(f'\\n idx {best_model_idx}: ', end='| ')\n",
        "            for i in range(len(ms)):\n",
        "                print(f'{best_perf[n][i]:.3f} +/- {0:.3f}', end=' | ')\n",
        "        print('\\n\\n')\n",
        "\n",
        "\n",
        "        # break\n"
      ],
      "metadata": {
        "id": "ZnG7o5adPGY-"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeat_time = 3\n",
        "name = ['Lipophilicity_AstraZeneca', 'Solubility_AqSolDB'] # have run MT on those 2 tasks\n",
        "\n",
        "for folder_ in ['no_scale', 'scale']:\n",
        "    print(folder_)\n",
        "    for model_type in model_types:\n",
        "        try:\n",
        "            print(model_type)\n",
        "            yml_files = [f'{folder_}/{model_type}_MT_{i}.yml' for i in range(repeat_time)]\n",
        "            perform_list = [yml_report(yml_file, ver=False) for yml_file in yml_files]\n",
        "            eval_perf_list(perform_list, name)\n",
        "        except: pass # no yml files saved yet, skip\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqROd2MXPh68",
        "outputId": "522e0953-89dc-4a64-bd79-8bfe8781e386"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_scale\n",
            "MLP\n",
            "******************** Lipophilicity_AstraZeneca ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.777 +/- 0.036 | 0.951 +/- 0.065 | 0.975 +/- 0.033 | 0.356 +/- 0.044 | \n",
            " idx 1: | 0.746 +/- 0.000 | 0.885 +/- 0.000 | 0.941 +/- 0.000 | 0.401 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** Solubility_AqSolDB ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.930 +/- 0.022 | 1.603 +/- 0.073 | 1.266 +/- 0.029 | 0.705 +/- 0.013 | \n",
            " idx 1: | 0.910 +/- 0.000 | 1.524 +/- 0.000 | 1.235 +/- 0.000 | 0.719 +/- 0.000 | \n",
            "\n",
            "\n",
            "AttentiveFP\n",
            "******************** Lipophilicity_AstraZeneca ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.480 +/- 0.008 | 0.402 +/- 0.010 | 0.634 +/- 0.008 | 0.728 +/- 0.007 | \n",
            " idx 0: | 0.477 +/- 0.000 | 0.406 +/- 0.000 | 0.637 +/- 0.000 | 0.725 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** Solubility_AqSolDB ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.660 +/- 0.007 | 0.963 +/- 0.029 | 0.981 +/- 0.015 | 0.823 +/- 0.005 | \n",
            " idx 0: | 0.650 +/- 0.000 | 0.922 +/- 0.000 | 0.960 +/- 0.000 | 0.830 +/- 0.000 | \n",
            "\n",
            "\n",
            "GIN\n",
            "RNN\n",
            "\n",
            "scale\n",
            "MLP\n",
            "******************** Lipophilicity_AstraZeneca ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.710 +/- 0.008 | 0.868 +/- 0.041 | 0.932 +/- 0.022 | 0.412 +/- 0.028 | \n",
            " idx 0: | 0.709 +/- 0.000 | 0.829 +/- 0.000 | 0.910 +/- 0.000 | 0.439 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** Solubility_AqSolDB ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.991 +/- 0.016 | 1.738 +/- 0.057 | 1.318 +/- 0.021 | 0.680 +/- 0.010 | \n",
            " idx 0: | 0.979 +/- 0.000 | 1.685 +/- 0.000 | 1.298 +/- 0.000 | 0.689 +/- 0.000 | \n",
            "\n",
            "\n",
            "AttentiveFP\n",
            "******************** Lipophilicity_AstraZeneca ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.437 +/- 0.017 | 0.367 +/- 0.022 | 0.606 +/- 0.018 | 0.751 +/- 0.015 | \n",
            " idx 0: | 0.415 +/- 0.000 | 0.339 +/- 0.000 | 0.583 +/- 0.000 | 0.770 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** Solubility_AqSolDB ********************\n",
            "\t\t mae \t \t mse \t \t rmse \t \t r2 \t \n",
            "\t| 0.683 +/- 0.014 | 0.990 +/- 0.021 | 0.995 +/- 0.011 | 0.817 +/- 0.004 | \n",
            " idx 0: | 0.663 +/- 0.000 | 0.960 +/- 0.000 | 0.980 +/- 0.000 | 0.823 +/- 0.000 | \n",
            "\n",
            "\n",
            "GIN\n",
            "RNN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in names_dict.items(): print(i, ': \\t Regression? :', j)\n",
        "\n",
        "print('\\nVOCAB TYPE for RNN:', VOCAB_TYPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF6QV8pzPGbU",
        "outputId": "ece594d7-7d8f-40b1-f828-eec36c6713c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caco2_Wang : \t Regression? : True\n",
            "Lipophilicity_AstraZeneca : \t Regression? : True\n",
            "HydrationFreeEnergy_FreeSolv : \t Regression? : True\n",
            "Solubility_AqSolDB : \t Regression? : True\n",
            "LD50_Zhu : \t Regression? : True\n",
            "CYP2C19_Veith : \t Regression? : False\n",
            "CYP2D6_Veith : \t Regression? : False\n",
            "CYP3A4_Veith : \t Regression? : False\n",
            "CYP1A2_Veith : \t Regression? : False\n",
            "CYP2C9_Veith : \t Regression? : False\n",
            "BBB_Martins : \t Regression? : False\n",
            "Bioavailability_Ma : \t Regression? : False\n",
            "Pgp_Broccatelli : \t Regression? : False\n",
            "HIA_Hou : \t Regression? : False\n",
            "PAMPA_NCATS : \t Regression? : False\n",
            "hERG_Karim : \t Regression? : False\n",
            "AMES : \t Regression? : False\n",
            "\n",
            "VOCAB TYPE for RNN: smiles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# test scale importance on Regression dataset\n",
        "# Specify task name,    whether scale dataset,\n",
        "# repeat how many times on the same model type\n",
        "\n",
        "# name = ['Lipophilicity_AstraZeneca', 'Solubility_AqSolDB']\n",
        "name = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "        'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "scale_dataset = False\n",
        "repeat_time = 3 # run the same model # repeat_time times\n",
        "##########################################################\n",
        "\n",
        "if len(name) > 1: run_type = 'MT' # multi task\n",
        "else: run_type = 'ST' # single task\n",
        "model_types = ['MLP', 'AttentiveFP', 'GIN', 'RNN']\n",
        "\n",
        "trn, val, tst = collect_data_10_27(name) # collect data for task: name\n",
        "\n",
        "if scale_dataset: # choose to scale dataset\n",
        "    trn, val, tst, dict_scale = scale(trn, val, tst); folder_name = 'scale'\n",
        "else: dict_scale = None; folder_name = 'no_scale'\n",
        "\n",
        "folder_name = 'M5' # 5 metabolism tasks\n",
        "\n",
        "make_path(folder_name, False)\n",
        "\n",
        "# loop all model types\n",
        "for model_type in model_types[3:]:\n",
        "    config = get_config(model_type, name); config['scale_dict'] = dict_scale\n",
        "    trn_l, val_l, tst_l, vocab = get_multi_loader(trn, val, tst, config)\n",
        "    if vocab != None and config['vocab'] == None:\n",
        "        \"\"\" If need vocab (RNN) yet no vocab provided: calculate using dataset \"\"\"\n",
        "        config['vocab'] = vocab # update config vocab info\n",
        "        print('RNN, no vocab provided, update vocab using dataset | ', end=\"\")\n",
        "        print('vocab length updated:', len(vocab))\n",
        "\n",
        "    perfs = [] # a list to store the performance outputted from the model\n",
        "    for i in range(repeat_time): # run the same model for repeat_time times\n",
        "        save_dir = f'{folder_name}/{model_type}_{run_type}_{i}'\n",
        "        config['model_path'] = save_dir + '.pt'\n",
        "        config['config_path'] = save_dir + '.yml'\n",
        "\n",
        "        print(f'\\nRun # {i} for {model_type} {run_type}', end='\\t')\n",
        "        try: # try open yml file, if file exists, and no need train\n",
        "            with open(config['config_path'], 'r') as f: data = yaml.safe_load(f)\n",
        "            if data != None: p = yml_report(data); print('--> pre data loaded')\n",
        "        except:  # model was not trained yet, train the model\n",
        "            models = PRED(**config); p = models.train(trn_l, val_l, tst_l)\n",
        "        perfs.append(p)\n",
        "\n",
        "    print('\\n', model_type)\n",
        "    eval_perf_list(perfs, name) # print the mean+/-std for model_type\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "556mp5BYPGdq",
        "outputId": "ebe3796f-36e4-401e-f79c-28cf976a5b0b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n",
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n",
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n",
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n",
            "Found local copy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collect data for:  ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith', 'CYP1A2_Veith', 'CYP2C9_Veith']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> loader for ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith', 'CYP1A2_Veith', 'CYP2C9_Veith']\n",
            "--> preparing data loader for model type  RNN\n",
            "--> preparing data loader for model type  RNN\n",
            "--> preparing data loader for model type  RNN\n",
            "\n",
            "Run # 0 for RNN MT\t--> pre data loaded\n",
            "\n",
            "Run # 1 for RNN MT\t--> pre data loaded\n",
            "\n",
            "Run # 2 for RNN MT\t--> pre data loaded\n",
            "\n",
            " RNN\n",
            "******************** CYP2C19_Veith ********************\n",
            "\t\t acc \t \t w_acc \t \t prec \t \t recall \t \t sp \t \t f1 \t \t auc \t \t mcc \t \t ap \t \n",
            "\t| 0.816 +/- 0.005 | 0.817 +/- 0.004 | 0.786 +/- 0.010 | 0.824 +/- 0.005 | 0.809 +/- 0.012 | 0.804 +/- 0.003 | 0.884 +/- 0.003 | 0.631 +/- 0.008 | 0.850 +/- 0.006 | \n",
            " idx 1: | 0.819 +/- 0.000 | 0.819 +/- 0.000 | 0.794 +/- 0.000 | 0.818 +/- 0.000 | 0.820 +/- 0.000 | 0.806 +/- 0.000 | 0.886 +/- 0.000 | 0.637 +/- 0.000 | 0.856 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2D6_Veith ********************\n",
            "\t\t acc \t \t w_acc \t \t prec \t \t recall \t \t sp \t \t f1 \t \t auc \t \t mcc \t \t ap \t \n",
            "\t| 0.858 +/- 0.004 | 0.692 +/- 0.023 | 0.693 +/- 0.033 | 0.428 +/- 0.057 | 0.956 +/- 0.011 | 0.525 +/- 0.037 | 0.833 +/- 0.003 | 0.467 +/- 0.025 | 0.619 +/- 0.012 | \n",
            " idx 1: | 0.858 +/- 0.000 | 0.666 +/- 0.000 | 0.739 +/- 0.000 | 0.361 +/- 0.000 | 0.971 +/- 0.000 | 0.485 +/- 0.000 | 0.830 +/- 0.000 | 0.449 +/- 0.000 | 0.628 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP3A4_Veith ********************\n",
            "\t\t acc \t \t w_acc \t \t prec \t \t recall \t \t sp \t \t f1 \t \t auc \t \t mcc \t \t ap \t \n",
            "\t| 0.781 +/- 0.005 | 0.777 +/- 0.007 | 0.727 +/- 0.005 | 0.753 +/- 0.020 | 0.801 +/- 0.009 | 0.740 +/- 0.009 | 0.863 +/- 0.002 | 0.552 +/- 0.012 | 0.815 +/- 0.004 | \n",
            " idx 1: | 0.788 +/- 0.000 | 0.785 +/- 0.000 | 0.732 +/- 0.000 | 0.766 +/- 0.000 | 0.803 +/- 0.000 | 0.749 +/- 0.000 | 0.866 +/- 0.000 | 0.566 +/- 0.000 | 0.821 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP1A2_Veith ********************\n",
            "\t\t acc \t \t w_acc \t \t prec \t \t recall \t \t sp \t \t f1 \t \t auc \t \t mcc \t \t ap \t \n",
            "\t| 0.838 +/- 0.002 | 0.839 +/- 0.002 | 0.812 +/- 0.006 | 0.854 +/- 0.008 | 0.823 +/- 0.008 | 0.833 +/- 0.002 | 0.919 +/- 0.000 | 0.676 +/- 0.004 | 0.911 +/- 0.001 | \n",
            " idx 1: | 0.841 +/- 0.000 | 0.842 +/- 0.000 | 0.817 +/- 0.000 | 0.855 +/- 0.000 | 0.828 +/- 0.000 | 0.836 +/- 0.000 | 0.919 +/- 0.000 | 0.683 +/- 0.000 | 0.910 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2C9_Veith ********************\n",
            "\t\t acc \t \t w_acc \t \t prec \t \t recall \t \t sp \t \t f1 \t \t auc \t \t mcc \t \t ap \t \n",
            "\t| 0.826 +/- 0.002 | 0.804 +/- 0.000 | 0.746 +/- 0.007 | 0.736 +/- 0.006 | 0.872 +/- 0.006 | 0.741 +/- 0.000 | 0.898 +/- 0.003 | 0.610 +/- 0.003 | 0.794 +/- 0.004 | \n",
            " idx 1: | 0.828 +/- 0.000 | 0.804 +/- 0.000 | 0.755 +/- 0.000 | 0.729 +/- 0.000 | 0.879 +/- 0.000 | 0.742 +/- 0.000 | 0.895 +/- 0.000 | 0.613 +/- 0.000 | 0.792 +/- 0.000 | \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repeat_time = 3\n",
        "name = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "        'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "\n",
        "for folder_ in ['M5']: # 5 metabolism tasks trained together\n",
        "    print(folder_)\n",
        "    for model_type in model_types:\n",
        "        try:\n",
        "            print(model_type)\n",
        "            yml_files = [f'{folder_}/{model_type}_MT_{i}.yml' for i in range(repeat_time)]\n",
        "            perform_list = [yml_report(yml_file, ver=False) for yml_file in yml_files]\n",
        "            loss_list = [p['loss'] for p in perform_list]\n",
        "            best_model_idx = np.argmin(loss_list) # has the lowest loss\n",
        "            print(f'model_type {model_type}, file with lowest loss:',\n",
        "                 f'{folder_}/{model_type}_MT_{best_model_idx}.yml\\n')\n",
        "            eval_perf_list(perform_list, name)\n",
        "            print('\\n\\n\\n\\n\\n')\n",
        "            # eval_perf_list([perform_list[best_model_idx]], name)\n",
        "        except: pass # no yml files saved yet, skip\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4PU3CngPGgi",
        "outputId": "0bc4b919-e0ca-4057-c2fd-dcbbe4517006"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M5\n",
            "MLP\n",
            "model_type MLP, file with lowest loss: M5/MLP_MT_1.yml\n",
            "\n",
            "******************** CYP2C19_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.774 +/- 0.007 | 0.774 +/- 0.008 | 0.747 +/- 0.008 | 0.768 +/- 0.014 | 0.779 +/- 0.009 | 0.757 +/- 0.009 | 0.845 +/- 0.005 | 0.546 +/- 0.015 | 0.800 +/- 0.008 | \n",
            " idx 1: | 0.776 +/- 0.000 | 0.776 +/- 0.000 | 0.743 +/- 0.000 | 0.782 +/- 0.000 | 0.770 +/- 0.000 | 0.762 +/- 0.000 | 0.847 +/- 0.000 | 0.551 +/- 0.000 | 0.805 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2D6_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.837 +/- 0.004 | 0.568 +/- 0.018 | 0.905 +/- 0.063 | 0.140 +/- 0.039 | 0.996 +/- 0.004 | 0.239 +/- 0.055 | 0.807 +/- 0.013 | 0.313 +/- 0.028 | 0.566 +/- 0.026 | \n",
            " idx 1: | 0.843 +/- 0.000 | 0.593 +/- 0.000 | 0.826 +/- 0.000 | 0.195 +/- 0.000 | 0.991 +/- 0.000 | 0.315 +/- 0.000 | 0.815 +/- 0.000 | 0.352 +/- 0.000 | 0.581 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP3A4_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.727 +/- 0.005 | 0.715 +/- 0.006 | 0.677 +/- 0.007 | 0.648 +/- 0.017 | 0.783 +/- 0.009 | 0.662 +/- 0.009 | 0.814 +/- 0.001 | 0.434 +/- 0.012 | 0.745 +/- 0.004 | \n",
            " idx 1: | 0.726 +/- 0.000 | 0.717 +/- 0.000 | 0.670 +/- 0.000 | 0.664 +/- 0.000 | 0.770 +/- 0.000 | 0.667 +/- 0.000 | 0.816 +/- 0.000 | 0.434 +/- 0.000 | 0.749 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP1A2_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.812 +/- 0.003 | 0.812 +/- 0.004 | 0.798 +/- 0.011 | 0.807 +/- 0.025 | 0.817 +/- 0.018 | 0.802 +/- 0.008 | 0.895 +/- 0.007 | 0.624 +/- 0.007 | 0.884 +/- 0.008 | \n",
            " idx 1: | 0.816 +/- 0.000 | 0.816 +/- 0.000 | 0.794 +/- 0.000 | 0.823 +/- 0.000 | 0.809 +/- 0.000 | 0.808 +/- 0.000 | 0.900 +/- 0.000 | 0.631 +/- 0.000 | 0.887 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2C9_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.792 +/- 0.007 | 0.748 +/- 0.011 | 0.730 +/- 0.010 | 0.613 +/- 0.024 | 0.884 +/- 0.007 | 0.666 +/- 0.015 | 0.858 +/- 0.005 | 0.521 +/- 0.017 | 0.722 +/- 0.012 | \n",
            " idx 1: | 0.795 +/- 0.000 | 0.748 +/- 0.000 | 0.743 +/- 0.000 | 0.603 +/- 0.000 | 0.893 +/- 0.000 | 0.666 +/- 0.000 | 0.862 +/- 0.000 | 0.526 +/- 0.000 | 0.736 +/- 0.000 | \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AttentiveFP\n",
            "GIN\n",
            "RNN\n",
            "model_type RNN, file with lowest loss: M5/RNN_MT_1.yml\n",
            "\n",
            "******************** CYP2C19_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.816 +/- 0.005 | 0.817 +/- 0.004 | 0.786 +/- 0.010 | 0.824 +/- 0.005 | 0.809 +/- 0.012 | 0.804 +/- 0.003 | 0.884 +/- 0.003 | 0.631 +/- 0.008 | 0.850 +/- 0.006 | \n",
            " idx 1: | 0.819 +/- 0.000 | 0.819 +/- 0.000 | 0.794 +/- 0.000 | 0.818 +/- 0.000 | 0.820 +/- 0.000 | 0.806 +/- 0.000 | 0.886 +/- 0.000 | 0.637 +/- 0.000 | 0.856 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2D6_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.858 +/- 0.004 | 0.692 +/- 0.023 | 0.693 +/- 0.033 | 0.428 +/- 0.057 | 0.956 +/- 0.011 | 0.525 +/- 0.037 | 0.833 +/- 0.003 | 0.467 +/- 0.025 | 0.619 +/- 0.012 | \n",
            " idx 1: | 0.858 +/- 0.000 | 0.666 +/- 0.000 | 0.739 +/- 0.000 | 0.361 +/- 0.000 | 0.971 +/- 0.000 | 0.485 +/- 0.000 | 0.830 +/- 0.000 | 0.449 +/- 0.000 | 0.628 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP3A4_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.781 +/- 0.005 | 0.777 +/- 0.007 | 0.727 +/- 0.005 | 0.753 +/- 0.020 | 0.801 +/- 0.009 | 0.740 +/- 0.009 | 0.863 +/- 0.002 | 0.552 +/- 0.012 | 0.815 +/- 0.004 | \n",
            " idx 1: | 0.788 +/- 0.000 | 0.785 +/- 0.000 | 0.732 +/- 0.000 | 0.766 +/- 0.000 | 0.803 +/- 0.000 | 0.749 +/- 0.000 | 0.866 +/- 0.000 | 0.566 +/- 0.000 | 0.821 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP1A2_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.838 +/- 0.002 | 0.839 +/- 0.002 | 0.812 +/- 0.006 | 0.854 +/- 0.008 | 0.823 +/- 0.008 | 0.833 +/- 0.002 | 0.919 +/- 0.000 | 0.676 +/- 0.004 | 0.911 +/- 0.001 | \n",
            " idx 1: | 0.841 +/- 0.000 | 0.842 +/- 0.000 | 0.817 +/- 0.000 | 0.855 +/- 0.000 | 0.828 +/- 0.000 | 0.836 +/- 0.000 | 0.919 +/- 0.000 | 0.683 +/- 0.000 | 0.910 +/- 0.000 | \n",
            "\n",
            "\n",
            "******************** CYP2C9_Veith ********************\n",
            "\t\t acc \t\t w_acc \t\t prec \t\t recall \t\t sp \t\t f1 \t\t auc \t\t mcc \t\t ap \t\n",
            "\t| 0.826 +/- 0.002 | 0.804 +/- 0.000 | 0.746 +/- 0.007 | 0.736 +/- 0.006 | 0.872 +/- 0.006 | 0.741 +/- 0.000 | 0.898 +/- 0.003 | 0.610 +/- 0.003 | 0.794 +/- 0.004 | \n",
            " idx 1: | 0.828 +/- 0.000 | 0.804 +/- 0.000 | 0.755 +/- 0.000 | 0.729 +/- 0.000 | 0.879 +/- 0.000 | 0.742 +/- 0.000 | 0.895 +/- 0.000 | 0.613 +/- 0.000 | 0.792 +/- 0.000 | \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HUYl-0xl45C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}