{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "_HvrTQzpmWgz",
        "DVyGaQLcmjtS"
      ],
      "authorship_tag": "ABX9TyOTeiXsqUSGW3x+9yEoT1aI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/examples/experiments/ADMET_10_24_runtime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCNpIgzOccz",
        "outputId": "604f4118-c145-4740-aed3-8b10a86558da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import walk\n",
        "import os\n",
        "files = next(walk('/content/drive/MyDrive/ADMET/'), (None, None, []))[2]\n",
        "for file in files:\n",
        "    if isinstance(file, str):\n",
        "        file_type = file.split('.')[-1]\n",
        "        # print(file_type)\n",
        "        if file_type == 'bin' or file_type == 'pth':\n",
        "            os.remove(file)"
      ],
      "metadata": {
        "id": "9VcLRDJDOw0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet\n",
        "\n",
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet"
      ],
      "metadata": {
        "id": "jya93CV1OfyL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CODE"
      ],
      "metadata": {
        "id": "nAbtuixryN6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMZKTqNlOf2V",
        "outputId": "84ce2236-db8b-4d40-82d9-1e5b9bc235a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_min(d:dict):\n",
        "    min_key = next(iter(d))\n",
        "\n",
        "    # Iterate over the keys in the dictionary\n",
        "    for key in d:\n",
        "        # If the value of the current key > the value of max_key, update max_key\n",
        "        if d[key] < d[min_key]:\n",
        "            min_key = key\n",
        "    return min_key, d[min_key]\n",
        "\n",
        "def plot_loss(train_dict, test_dict, name='test', title_name=None):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(list(train_dict.keys()), list(train_dict.values()), label='train')\n",
        "    plt.plot(list(test_dict.keys()), list(test_dict.values()), label=name)\n",
        "    argmin, min = get_min(test_dict)\n",
        "    plt.plot(argmin, min, '*', label=f'min epoch {argmin}')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    if title_name == None: title_name = 'loss during training'\n",
        "    plt.title(title_name)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "lOEimX2COf5-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_performance(list_of_dict, model_types, title=None):\n",
        "    assert len(list_of_dict) == len(model_types)\n",
        "    fig = plt.figure()\n",
        "    for model_name, per in zip(model_types, list_of_dict):\n",
        "        plt.plot(list(per.keys()), list(per.values()), label=model_name)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('performance')\n",
        "    if title == None: title = 'Performance on valid set during training'\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "## TEST CODE\n",
        "# a = {1: 0.2, 2: 0.3}\n",
        "# b = {1: 0.2, 2: 0.5, 3: 0.8}\n",
        "# plot_performance([a,b], ['MLP', 'GIN'])"
      ],
      "metadata": {
        "id": "osSiH-jdjhhG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "device = 'cuda'\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def reg_evaluate(label_clean, preds_clean):\n",
        "    mae = metrics.mean_absolute_error(label_clean, preds_clean)\n",
        "    mse = metrics.mean_squared_error(label_clean, preds_clean)\n",
        "    rmse = np.sqrt(mse) #mse**(0.5)\n",
        "    r2 = metrics.r2_score(label_clean, preds_clean)\n",
        "\n",
        "    print('  MAE     MSE     RMSE    R2')\n",
        "    print(\"&%5.3f\" % (mae), \" &%5.3f\" % (mse), \" &%5.3f\" % (rmse),\n",
        "      \" &%5.3f\" % (r2))\n",
        "\n",
        "    eval_result_r2 =   f'R2:     {r2:.3f}'\n",
        "    eval_result_mae =  f'MAE:   {mae:.3f}'\n",
        "    eval_result_rmse = f'RMSE: {rmse:.3f}'\n",
        "\n",
        "    return eval_result_r2, eval_result_mae, eval_result_rmse\n",
        "\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def eval_dict(y_probs:dict, y_label:dict, names:list, IS_R, draw_fig=False):\n",
        "    if isinstance(IS_R, list): task_list = IS_R\n",
        "    else: task_list = [IS_R] * len(names)\n",
        "    for i, (name, IS_R) in enumerate(zip(names, task_list)):\n",
        "        # IS_R = task_list[i]\n",
        "        print('*'*15, name, '*'*15)\n",
        "        # print('Regression task', IS_R)\n",
        "\n",
        "        probs = y_probs[name]\n",
        "        label = y_label[name]\n",
        "        assert len(probs) == len(label)\n",
        "        if IS_R == False: # classification task\n",
        "            preds = get_preds(0.5, probs)\n",
        "            evaluate(label, preds, probs)\n",
        "\n",
        "        else: # regression task\n",
        "            r2, mae, rmse = reg_evaluate(label, probs)\n",
        "            if draw_fig:\n",
        "                color = mcp.gen_color_normalized(cmap='viridis',\n",
        "                                                data_arr=label)\n",
        "                plt.scatter(label, probs, cmap='viridis', marker='.',\n",
        "                            s=10, alpha=0.5, edgecolors='none', c=color)\n",
        "                plt.xlabel(f'True {name}')\n",
        "                plt.ylabel(f'Predicted {name}')\n",
        "                plt.title(f'{name} prediction on test set')\n",
        "\n",
        "                x0, xmax = plt.xlim()\n",
        "                y0, ymax = plt.ylim()\n",
        "                data_width = xmax - x0\n",
        "                data_height = ymax - y0\n",
        "                # print(x0, xmax, y0, ymax, data_width, data_height)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8/0.95, r2)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8,  mae)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8*0.95, rmse)\n",
        "\n",
        "                plt.show()\n",
        "                plt.cla()\n",
        "                plt.clf()\n",
        "                plt.close()\n",
        "        print()\n",
        "\n",
        "# TEST Classification\n",
        "b = evaluate([1, 0, 1], [1, 1, 1], [1, 0.6, 1])\n",
        "print(b[0])\n",
        "\n",
        "# TEST Regression\n",
        "reg_evaluate([2.3, 2.1], [3, 2])\n"
      ],
      "metadata": {
        "id": "RhpyWqHUPFyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d505b60c-4ba7-4362-bd5e-9ee75478c6c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "equation for MCC is (TP*TN-FP*FN)*1.0/(math.sqrt(temp))\n",
            "TP, FP, TN, FN 2 1 0 0\n",
            "temp=0\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.667  &  0.500  &          0.667  &     1.000  &0.000  &0.800 &1.000 &  N/A &   1.000\n",
            "0.6666666666666666\n",
            "  MAE     MSE     RMSE    R2\n",
            "&0.400  &0.250  &0.500  &-24.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('R2:     -24.000', 'MAE:   0.400', 'RMSE: 0.500')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architectures of Models\n",
        "MLP architecture"
      ],
      "metadata": {
        "id": "_HvrTQzpmWgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super(Classifier, self).__init__()\n",
        "        dims = [config['in_dim'], config['hid_dims'], config['out_dim']]\n",
        "        self.dims = dims\n",
        "        neurons = [config['in_dim'], *config['hid_dims']]\n",
        "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                         for i in range(1, len(neurons))]\n",
        "        self.hidden = nn.ModuleList(linear_layers)\n",
        "        self.final = nn.Linear(config['hid_dims'][-1], config['out_dim'])\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden: x = F.relu(layer(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "    def get_dim(self): return self.dims\n"
      ],
      "metadata": {
        "id": "44Wa3HvKPH2H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AttentiveFP architecture"
      ],
      "metadata": {
        "id": "9xpkI9QumYeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from dgllife.model import model_zoo\n",
        "from dgllife.utils import smiles_to_bigraph\n",
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from dgllife.utils import AttentiveFPAtomFeaturizer\n",
        "from dgllife.utils import AttentiveFPBondFeaturizer\n",
        "from dgllife.data import MoleculeCSVDataset\n",
        "from dgllife.model.gnn import AttentiveFPGNN\n",
        "from dgllife.model.readout import AttentiveFPReadout\n",
        "\n",
        "def get_model_AT_10_17(names, n_layers, graph_feat_size, num_timesteps, dropout):\n",
        "    atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
        "    bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
        "    n_feats_num = atom_featurizer.feat_size('hv')\n",
        "    e_feats_num = bond_featurizer.feat_size('he')\n",
        "\n",
        "    model = model_zoo.AttentiveFPPredictor(\n",
        "            node_feat_size=n_feats_num, edge_feat_size=e_feats_num,\n",
        "            num_layers=n_layers, num_timesteps=num_timesteps,\n",
        "            graph_feat_size=graph_feat_size,\n",
        "            n_tasks=len(names), dropout=dropout)\n",
        "    return model\n",
        "\n",
        "def AttentiveFP(**config):\n",
        "    return get_model_AT_10_17(config['prop_names'], config['n_layers'],\n",
        "            config['graph_feat_size'], config['num_timesteps'], config['dropout'])"
      ],
      "metadata": {
        "id": "S-JCXhmtPQZq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIN architecture"
      ],
      "metadata": {
        "id": "8jjFPFc0ma9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://lifesci.dgl.ai/_modules/dgllife/model/pretrain.html\n",
        "\n",
        "\n",
        "class GIN_MOD(nn.Module):\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/encoders.py#L392\n",
        "    \"\"\"\n",
        "\t## adapted from https://github.com/awslabs/dgl-lifesci/blob/2fbf5fd6aca92675b709b6f1c3bc3c6ad5434e96/examples/property_prediction/moleculenet/utils.py#L76\n",
        "    def __init__(self, **config):\n",
        "        super(GIN_MOD, self).__init__()\n",
        "        self.gnn = load_pretrained(config['pretrain_model'])\n",
        "        self.readout = AvgPooling()\n",
        "        self.transform = nn.Linear(300, config['in_dim'])\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "        self.hidden_dims = config['hid_dims']\n",
        "        self.out_dim = config['out_dim']\n",
        "        if len(self.hidden_dims) == 0:\n",
        "            self.hidden = None\n",
        "            self.final = nn.Linear(config['in_dim'], self.out_dim)\n",
        "        else:\n",
        "        # layer_size = len(self.hidden_dims)\n",
        "            neurons = [config['in_dim'], *self.hidden_dims]\n",
        "            linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                                for i in range(1, len(neurons))]\n",
        "            self.hidden = nn.ModuleList(linear_layers)\n",
        "            self.final = nn.Linear(self.hidden_dims[-1], self.out_dim)\n",
        "\n",
        "    def forward(self, bg):\n",
        "        # bg = bg.to(device)\n",
        "        node_feats = [\n",
        "            bg.ndata.pop('atomic_number'),\n",
        "            bg.ndata.pop('chirality_type')\n",
        "        ]\n",
        "        edge_feats = [\n",
        "            bg.edata.pop('bond_type'),\n",
        "            bg.edata.pop('bond_direction_type')\n",
        "        ]\n",
        "        node_feats = self.gnn(bg, node_feats, edge_feats)\n",
        "        x = self.readout(bg, node_feats)\n",
        "        x = self.transform(x)\n",
        "        if self.hidden != None:\n",
        "            for layer in self.hidden: x = F.leaky_relu(layer(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.final(x)\n"
      ],
      "metadata": {
        "id": "VR3m1oc4PR5S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATALOADER AND DATASET"
      ],
      "metadata": {
        "id": "DVyGaQLcmjtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.MACCSkeys import GenMACCSKeys\n",
        "import torch.nn.functional as F\n",
        "\n",
        "m = Chem.MolFromSmiles\n",
        "header = ['bit' + str(i) for i in range(167)]\n",
        "\n",
        "def smile_list_to_MACCS(smi_list:list):\n",
        "    MACCS_list = []\n",
        "    for smi in smi_list:\n",
        "        maccs = [float(i) for i in list(GenMACCSKeys(m(smi)).ToBitString())]\n",
        "        MACCS_list.append(maccs)\n",
        "    return MACCS_list\n",
        "\n",
        "import torch\n",
        "# def process(data):\n",
        "\n",
        "#     # data = convert_with_qed_sa(data)\n",
        "#     print('---> converting SMILES to MACCS...')\n",
        "#     MACCS_list = smile_list_to_MACCS(data['Drug'].tolist())\n",
        "#     data[header] = pd.DataFrame(MACCS_list)\n",
        "#     print('---> FINISHED')\n",
        "#     return data\n",
        "def process(data_):\n",
        "    data = data_.copy()\n",
        "    # data = convert_with_qed_sa(data)\n",
        "    print('---> converting SMILES to MACCS...')\n",
        "    MACCS_list = smile_list_to_MACCS(data['Drug'].tolist())\n",
        "    data[header] = pd.DataFrame(MACCS_list)\n",
        "    print('---> FINISHED')\n",
        "    return data\n",
        "\n",
        "MASK = -100\n",
        "\n",
        "class nn_dataset(Dataset):\n",
        "    def __init__(self, df, prop_names, mask=MASK):\n",
        "        super(nn_dataset, self).__init__()\n",
        "        df = process(df)\n",
        "        df = df.fillna(mask)\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.fp = self.df[header]\n",
        "        if isinstance(prop_names, str): prop_names = [prop_names]\n",
        "        self.props = self.df[prop_names]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fp = torch.tensor(self.fp.iloc[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return fp, label\n",
        "\n",
        "    def __len__(self): return self.len\n",
        "\n",
        "    def get_df(self): return self.df"
      ],
      "metadata": {
        "id": "ezlar28YPxL4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_molgraphs(data):\n",
        "    assert len(data[0]) in [3, 4], \\\n",
        "        'Expect the tuple to be of length 3 or 4, got {:d}'.format(len(data[0]))\n",
        "    if len(data[0]) == 3:\n",
        "        smiles, graphs, labels = map(list, zip(*data))\n",
        "        masks = None\n",
        "    else:\n",
        "        smiles, graphs, labels, masks = map(list, zip(*data))\n",
        "\n",
        "    bg = dgl.batch(graphs)\n",
        "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    if masks is None:\n",
        "        masks = torch.ones(labels.shape)\n",
        "    else:\n",
        "        masks = torch.stack(masks, dim=0)\n",
        "        # masks = (labels == MASK).long()\n",
        "    return smiles, bg, labels, masks\n",
        "\n",
        "def get_AttentiveFP_dataset(df, name):\n",
        "    atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
        "    bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
        "    time_string = time.strftime(\"%m_%d_%Y_%H:%M:%S\", time.localtime())\n",
        "\n",
        "    params = {'smiles_to_graph': smiles_to_bigraph,\n",
        "            'node_featurizer': atom_featurizer,\n",
        "            'edge_featurizer': bond_featurizer,\n",
        "            'smiles_column': 'Drug',\n",
        "            'cache_file_path': time_string+'.bin',\n",
        "            'task_names': name, 'load': True, 'n_jobs': len(name)*2}\n",
        "    graph_dataset = MoleculeCSVDataset(df, **params)\n",
        "    return graph_dataset\n",
        "\n",
        "def get_AttentiveFP_loader(df, name, **loader_params):\n",
        "    dataset = get_AttentiveFP_dataset(df, name)\n",
        "    loader_params['collate_fn'] = collate_molgraphs\n",
        "    loader = DataLoader(dataset, **loader_params)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "HhE6MVgRmm1n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.model import load_pretrained\n",
        "from dgl.nn.pytorch.glob import AvgPooling\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "import torch\n",
        "from dgllife.utils import smiles_to_bigraph, PretrainAtomFeaturizer, PretrainBondFeaturizer\n",
        "\n",
        "MASK = -100\n",
        "\n",
        "class GIN_dataset(Dataset):\n",
        "    def __init__(self, df, names, mask=MASK):\n",
        "        df = df.fillna(mask)\n",
        "        self.names = names\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.props = self.df[names]\n",
        "        self.node_featurizer = PretrainAtomFeaturizer()\n",
        "        self.edge_featurizer = PretrainBondFeaturizer()\n",
        "        self.fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
        "    def __len__(self): return self.len\n",
        "    def __getitem__(self, idx):\n",
        "        v_d = self.df.iloc[idx]['Drug']\n",
        "        v_d = self.fc(smiles=v_d, node_featurizer = self.node_featurizer,\n",
        "                      edge_featurizer = self.edge_featurizer)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return v_d, label\n",
        "\n",
        "import dgl\n",
        "def get_GIN_dataloader(datasets, **loader_params):\n",
        "    def dgl_collate_func(data):\n",
        "        x, labels = map(list, zip(*data))\n",
        "        bg = dgl.batch(x)\n",
        "        labels = torch.stack(labels, dim=0)\n",
        "        bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "        bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "        return bg, labels\n",
        "    loader_params['collate_fn'] = dgl_collate_func\n",
        "    return DataLoader(datasets, **loader_params)"
      ],
      "metadata": {
        "id": "5-WFUMhomm5x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL initialization, train epoch function"
      ],
      "metadata": {
        "id": "TaKvYT_wmsFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def init_model(**config):\n",
        "    \"\"\"need incorporate all models here! \"\"\"\n",
        "    if config['model_type'] == 'MLP':\n",
        "        model = Classifier(**config)\n",
        "    elif config['model_type'] == 'GIN':\n",
        "        model = GIN_MOD(**config) # need work config GIN out_dim\n",
        "    elif config['model_type'] == 'AttentiveFP':\n",
        "        model = AttentiveFP(**config)\n",
        "    elif config['model_type'] == 'RNN': pass\n",
        "    return model\n",
        "\n",
        "def get_loss_fn(IS_R):\n",
        "    if IS_R: return nn.MSELoss(reduction='sum')\n",
        "    else: return nn.BCEWithLogitsLoss(reduction='sum')\n",
        "\n",
        "def get_train_fn(model_type):\n",
        "    if model_type == 'MLP': return train_epoch_MLP\n",
        "\n",
        "    elif model_type == 'GIN': return train_epoch_MLP\n",
        "    elif model_type == 'AttentiveFP': return train_epoch_MLP\n",
        "    elif model_type == 'RNN': pass\n",
        "\n",
        "def get_eval_fn(model_type):\n",
        "    if model_type == 'MLP': return train_epoch_MLP\n",
        "\n",
        "    elif model_type == 'GIN': return train_epoch_MLP\n",
        "    elif model_type == 'AttentiveFP': return train_epoch_MLP\n",
        "    elif model_type == 'RNN': pass\n",
        "\n",
        "\n",
        "def get_loader(df, names, params, model_type):\n",
        "    print('--> preparing data loader for model type ', model_type)\n",
        "    if model_type == 'MLP': return DataLoader(nn_dataset(df, names), **params)\n",
        "\n",
        "    elif model_type == 'GIN':\n",
        "        return get_GIN_dataloader(GIN_dataset(df, names), **params)\n",
        "\n",
        "    elif model_type == 'AttentiveFP':\n",
        "        return get_AttentiveFP_loader(df, names, **params)\n",
        "\n",
        "    elif model_type == 'RNN': pass\n",
        "\n",
        "import time\n",
        "def train_epoch_MLP(model, loader, IS_R, names, device,\n",
        "                    epoch=None, optimizer=None, MASK=-100,\n",
        "                    scale_dict=None, weight_loss=None):\n",
        "    \"\"\"\n",
        "    param weight_loss: list, the weight of loss for different tasks\n",
        "    \"\"\"\n",
        "\n",
        "    if optimizer==None: # no optimizer, either validation or test\n",
        "        model.eval()    # model evaluation for either valid or test\n",
        "        if epoch != None: train_type='Valid' # if epoch is inputted, its valid\n",
        "        else: train_type = 'Test' # if no epoch information, its test\n",
        "    else: model.train(); train_type='Train' # if optimizer inputted, its train\n",
        "\n",
        "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
        "    else: IS_R_list = [IS_R] * len(names)\n",
        "\n",
        "    if weight_loss == None: weight_loss = [1]*len(names)\n",
        "\n",
        "    losses, y_probs, y_label = 0, {}, {}\n",
        "    # y_probs = {}\n",
        "    # y_label = {}\n",
        "    for idx, batch_data in enumerate(loader):\n",
        "        \"\"\"\n",
        "        len(batch_data) could determine which algorithm\n",
        "        len(batch_data) == 2: MLP, GIN\n",
        "        len(batch_data) == 4: AttentiveFP\n",
        "        \"\"\"\n",
        "        if len(batch_data) == 2:  # MLP or GIN\n",
        "            fp, labels = batch_data\n",
        "            fp, labels = fp.to(device), labels.to(device)\n",
        "            mask = labels == MASK\n",
        "            pred = model(fp)\n",
        "        elif len(batch_data) == 4: # attentiveFP\n",
        "            smiles, bg, labels, masks = batch_data\n",
        "            bg, labels, masks = bg.to(device), labels.to(device), masks.to(device)\n",
        "            n_feats = bg.ndata.pop('hv').to(device)\n",
        "            e_feats = bg.edata.pop('he').to(device)\n",
        "            pred = model(bg, n_feats, e_feats)\n",
        "            mask = masks < 1\n",
        "\n",
        "        for j, (name, IS_R, w) in enumerate(zip(names, IS_R_list, weight_loss)):\n",
        "            loss_func = get_loss_fn(IS_R)\n",
        "            probs = pred[:, j][~mask[:, j]]\n",
        "            label = labels[:, j][~mask[:, j]]\n",
        "            if j == 0: loss  = loss_func(probs, label) * w\n",
        "            else:      loss += loss_func(probs, label) * w\n",
        "            if IS_R == False: probs = F.sigmoid(probs)\n",
        "\n",
        "            if train_type != 'Train': # validation\n",
        "                probs = probs.cpu().detach().numpy().tolist()\n",
        "                label = label.cpu().detach().numpy().tolist()\n",
        "                if scale_dict != None:\n",
        "                    min_here = scale_dict[name][0]\n",
        "                    max_here = scale_dict[name][1]\n",
        "                    del_here = max_here - min_here\n",
        "                    label = [l * del_here + min_here for l in label]\n",
        "                    probs = [p * del_here + min_here for p in probs]\n",
        "\n",
        "                if idx ==0: y_probs[name], y_label[name] = probs, label\n",
        "                else:\n",
        "                    y_probs[name] += probs\n",
        "                    y_label[name] += label\n",
        "\n",
        "        losses += loss.item()\n",
        "        if optimizer != None:\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "    total_loss = losses / len(loader.dataset)\n",
        "    if epoch != None: # train or valid\n",
        "        print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
        "    else: # test\n",
        "        print(f'[{train_type}] Loss: {total_loss:.3f}')\n",
        "        eval_dict(y_probs, y_label, names, IS_R_list, draw_fig=True)\n",
        "\n",
        "    if train_type == 'Train': return total_loss\n",
        "    else: return total_loss, y_probs, y_label\n"
      ],
      "metadata": {
        "id": "Ut8RaE8SPV3d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class PRED:\n",
        "    def __init__(self, **config):\n",
        "        cuda = torch.cuda.is_available()\n",
        "        if cuda: self.device = 'cuda'\n",
        "        else:    self.device = 'cpu'\n",
        "        self.prop_names = config['prop_names']\n",
        "        self.config = config\n",
        "        if 'scale_dict' not in config: self.scale_dict = None\n",
        "        else: self.scale_dict = config['scale_dict']\n",
        "        self.model_type = config['model_type']\n",
        "        print('model type: ', self.model_type)\n",
        "        self.model_path = config['model_path']\n",
        "\n",
        "        self.eval_fn = get_eval_fn(self.model_type)\n",
        "        self.train_fn = get_train_fn(self.model_type)\n",
        "\n",
        "        self.model = init_model(**config).to(self.device)\n",
        "\n",
        "        self.IS_R = config['IS_R'] # could be list, could be true/false\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
        "                        lr=config['lr'], weight_decay=config['wd'])\n",
        "        self.stopper = EarlyStopping(mode='lower', patience=config['patience'])\n",
        "\n",
        "        self.min_loss = np.inf\n",
        "        self.best_epoch = 0\n",
        "        self.train_dict = {}\n",
        "        self.valid_dict = {}\n",
        "        self.times_list = []\n",
        "        # self.perfo_dict = {}\n",
        "\n",
        "    def load_model(self, path):\n",
        "        con = self.config.copy()\n",
        "        con['dropout'] = 0\n",
        "        self.model = init_model(**con).to(self.device)\n",
        "        print('load pretrained model from ', path)\n",
        "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
        "\n",
        "    def get_runtime(self, verbose=True):\n",
        "        if verbose:\n",
        "            print(f'Train time: {np.mean(self.times_list):.3f}'\n",
        "                  f'+/-{np.std(self.times_list):.3f} ms')\n",
        "        return np.mean(self.times_list), np.std(self.times_list)\n",
        "\n",
        "    def eval(self, loader, path=None, ver=False):\n",
        "        print('#'*68)\n",
        "        print('#'*30, 'CONFIG', '#'*30)\n",
        "        print('#'*68)\n",
        "        for i, j in self.config.items():\n",
        "            print(i, ':', j)\n",
        "        print('#'*68)\n",
        "\n",
        "        if path != None: self.load_model(path)\n",
        "        if ver:\n",
        "            # print(f'Train time: {np.mean(self.times_list):.5f}'\n",
        "            #       f'+/-{np.std(self.times_list):.5f} ms')\n",
        "            self.get_runtime()\n",
        "            print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
        "            plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
        "                      title_name= f'loss during training {self.model_type}')\n",
        "        self.eval_fn(self.model, loader, self.IS_R, self.prop_names, self.device,\n",
        "               epoch=None, optimizer=None, MASK=-100, scale_dict=self.scale_dict)\n",
        "\n",
        "    def train(self, data_loader, val_loader, test_loader=None):\n",
        "        if self.best_epoch != 0:\n",
        "            self.model.load_state_dict(torch.load(self.model_path,\n",
        "                                                  map_location=self.device))\n",
        "        # train_dict, valid_dict = {}, {}\n",
        "        for epoch in range(500):\n",
        "            t = time.time()\n",
        "            score = self.train_fn(self.model, data_loader, self.IS_R,\n",
        "                                  self.prop_names, self.device, epoch,\n",
        "                                  self.optimizer, scale_dict=self.scale_dict)\n",
        "            train_time = (time.time() - t) * 1000 / len(data_loader.dataset)\n",
        "            self.times_list.append(train_time)\n",
        "            val_score, probs, labels = self.train_fn(self.model, val_loader,\n",
        "                                       self.IS_R, self.prop_names, self.device,\n",
        "                                       epoch, scale_dict=self.scale_dict)\n",
        "            self.train_dict[epoch] = score\n",
        "            self.valid_dict[epoch] = val_score\n",
        "            early_stop = self.stopper.step(val_score, self.model)\n",
        "            if val_score < self.min_loss:\n",
        "                print(f'\\tSAVE MODEL: loss: {self.min_loss:.3f} -> '\n",
        "                      f'{val_score:.3f} |',\n",
        "                      f'runtime: {train_time:.3f} ms')\n",
        "                self.min_loss = val_score; self.best_epoch = epoch\n",
        "                torch.save(self.model.state_dict(), self.model_path)\n",
        "\n",
        "            if epoch % 10 == 0 and epoch != 0:\n",
        "                self.get_runtime()\n",
        "                plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
        "                    title_name= f'loss during training {self.model_type}')\n",
        "                eval_dict(probs, labels, self.prop_names, IS_R=self.IS_R)\n",
        "            if early_stop: print('early stop'); break\n",
        "        # print(f'Train time: {np.mean(self.times_list):.5f}'\n",
        "        #       f'+/-{np.std(self.times_list):.5f} ms')\n",
        "        self.get_runtime()\n",
        "        print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
        "        plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
        "                  title_name= f'loss during training {self.model_type}')\n",
        "\n",
        "        if test_loader != None: self.eval(test_loader, self.model_path)\n"
      ],
      "metadata": {
        "id": "9E0fFFhmQC2n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collect data functions"
      ],
      "metadata": {
        "id": "6ZSs__AzeiRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.preprocess_mols import preprocess, rename_cols, clean_mol, scal\n",
        "from tdc.single_pred import ADME\n",
        "from tdc.single_pred import Tox\n",
        "from tdc.utils import retrieve_label_name_list\n",
        "label_list = retrieve_label_name_list('herg_central')\n",
        "\n",
        "def collect_data_10_17(names:list, clean_mol_=False):\n",
        "    for i, name in enumerate(names):\n",
        "        print('*'*15, name, '*'*15)\n",
        "        if name in label_list:\n",
        "            data = Tox(name='herg_central', label_name=name)\n",
        "        else:\n",
        "            try: data = ADME(name=name)\n",
        "            except:\n",
        "                try: data = Tox(name=name)\n",
        "                except: print('cannot read data!'); break\n",
        "            # data.label_distribution()\n",
        "        split = data.get_split()\n",
        "        train, valid, test = split['train'], split['valid'], split['test']\n",
        "        if clean_mol_:\n",
        "            train, valid, test = clean_mol(train), clean_mol(valid), clean_mol(test)\n",
        "\n",
        "        train = rename_cols(train[['Drug', 'Y']], name)\n",
        "        valid = rename_cols(valid[['Drug', 'Y']], name)\n",
        "        test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "\n",
        "        if i == 0: trains, valids, tests = train, valid, test\n",
        "        else:\n",
        "            trains = trains.merge(train, how='outer')\n",
        "            valids = valids.merge(valid, how='outer')\n",
        "            tests = tests.merge(test, how='outer')\n",
        "\n",
        "    return trains, valids, tests\n"
      ],
      "metadata": {
        "id": "ZW0DXREeQa_y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "# def count_(df:pd.DataFrame):\n",
        "#     for col in df.columns:\n",
        "#         if col != 'Drug':\n",
        "#             try:\n",
        "#                 ones = df[col].value_counts()[1]\n",
        "#                 zero = df[col].value_counts()[0]\n",
        "#             except: ones = 'Nan'; zero = 'Nan'\n",
        "#             print(col, f'\\t 0: {zero} | 1: {ones}')\n",
        "#     print()\n",
        "\n",
        "def scale(trains, valids, tests):\n",
        "    print('scaling train valid test data set for regression task ')\n",
        "    dict_scale = {}\n",
        "    for col in trains.columns:\n",
        "        if col == 'Drug': pass\n",
        "        else:\n",
        "            # print(col)\n",
        "            min_here = min(trains[col].min(), valids[col].min(), tests[col].min())\n",
        "            max_here = max(trains[col].max(), valids[col].max(), tests[col].max())\n",
        "            dict_scale[col] = [min_here, max_here]\n",
        "            delta_here = max_here - min_here\n",
        "            trains[col] = (trains[col] - min_here) / delta_here\n",
        "            valids[col] = (valids[col] - min_here) / delta_here\n",
        "            tests[col]  = (tests[col]  - min_here) / delta_here\n",
        "\n",
        "    return trains, valids, tests, dict_scale\n",
        "\n",
        "\n",
        "def get_multi_loader(trains, valids, tests, prop_names, batch_size, model_type):\n",
        "    print('---> loader for', prop_names)\n",
        "    loader_params = {'batch_size': batch_size, 'shuffle': True,\n",
        "                     'drop_last': False, 'num_workers': 0}\n",
        "    train_loader = get_loader(trains, prop_names, loader_params, model_type)\n",
        "    valid_loader = get_loader(valids, prop_names, loader_params, model_type)\n",
        "    test_params = {'batch_size': batch_size, 'shuffle': False,\n",
        "                   'drop_last': False, 'num_workers': 0}\n",
        "    test_loader = get_loader(tests, prop_names, test_params, model_type)\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "# trains, valids, tests, dict_scale = scale(trains, valids, tests)\n",
        "\n",
        "# batch_size = 64\n",
        "# loader_params = {'batch_size': batch_size, 'shuffle': True}\n",
        "# train_loader = get_loader(trains, names, loader_params, 'MLP')\n",
        "# valid_loader = get_loader(valids, names, loader_params, 'MLP')\n",
        "\n",
        "# test_params = {'batch_size': batch_size, 'shuffle': False}\n",
        "# test_loader  = get_loader(tests,  names,  test_params,  'MLP')\n"
      ],
      "metadata": {
        "id": "4fWwzSuGSGg-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_dict = {}\n",
        "names_reg = ['Caco2_Wang', 'Lipophilicity_AstraZeneca',\n",
        "         'HydrationFreeEnergy_FreeSolv', 'Solubility_AqSolDB', 'LD50_Zhu'] # regression task\n",
        "names_cls = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "             'CYP1A2_Veith', 'CYP2C9_Veith'] + \\\n",
        "            ['BBB_Martins', 'Bioavailability_Ma',\n",
        "             'Pgp_Broccatelli', 'HIA_Hou','PAMPA_NCATS'] + \\\n",
        "            ['hERG_Karim', 'AMES']\n",
        "\n",
        "for name in names_reg + names_cls:\n",
        "    if name in names_reg:   names_dict[name] = True  # regression task\n",
        "    elif name in names_cls: names_dict[name] = False # classification task\n",
        "\n",
        "names_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKUW2ZtTrK0T",
        "outputId": "a2fdabff-ffd1-441a-b61b-4bac84ca0d1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Caco2_Wang': True,\n",
              " 'Lipophilicity_AstraZeneca': True,\n",
              " 'HydrationFreeEnergy_FreeSolv': True,\n",
              " 'Solubility_AqSolDB': True,\n",
              " 'LD50_Zhu': True,\n",
              " 'CYP2C19_Veith': False,\n",
              " 'CYP2D6_Veith': False,\n",
              " 'CYP3A4_Veith': False,\n",
              " 'CYP1A2_Veith': False,\n",
              " 'CYP2C9_Veith': False,\n",
              " 'BBB_Martins': False,\n",
              " 'Bioavailability_Ma': False,\n",
              " 'Pgp_Broccatelli': False,\n",
              " 'HIA_Hou': False,\n",
              " 'PAMPA_NCATS': False,\n",
              " 'hERG_Karim': False,\n",
              " 'AMES': False}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "UB8trzWjep4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 256\n",
        "hid_dims = [128, 64, 16]\n",
        "dropout = 0.1\n",
        "lr = 5e-4\n",
        "wd = 1e-5\n",
        "patience = 5 # stop if loss no decrease after epochs # patience\n",
        "batch_size = 128\n",
        "\n",
        "# special for AttentiveFP\n",
        "graph_feat_size = 300\n",
        "n_layers = 5\n",
        "num_timesteps = 1 # times of updating the graph representations with GRU\n",
        "\n",
        "# special for GIN: pretrain model types for selection:\n",
        "pre_models_GIN = ['gin_supervised_contextpred', 'gin_supervised_infomax',\n",
        "                     'gin_supervised_edgepred', 'gin_supervised_masking']\n",
        "model_num = 3 # choose from pre_models for GIN\n",
        "dict_scale = None\n",
        "def get_config(model_type, names, pre_model_num=model_num, scale_dict=dict_scale):\n",
        "    \"\"\"\n",
        "    Get config to initialize model\n",
        "        param model_type: str, ['MLP', 'AttentiveFP', 'GIN']\n",
        "        param names: list, task names\n",
        "        param scale_dict: dict,\n",
        "            if the task is regression, could scale label values\n",
        "                            {name: [value_min, value_max], ...}\n",
        "        param pre_model_num: int, [0, 1, 2, 3]\n",
        "            if model_type is 'GIN', 4 types of pretrained models to choose from\n",
        "    Returns config that could be used as PRED(**config)\n",
        "    \"\"\"\n",
        "    pre_models_GIN = ['gin_supervised_contextpred', 'gin_supervised_infomax',\n",
        "                         'gin_supervised_edgepred', 'gin_supervised_masking']\n",
        "\n",
        "    # print(scale_dict)\n",
        "    IS_R = [names_dict[name] for name in names]\n",
        "    config_MLP = {'model_type': 'MLP',\n",
        "            'in_dim': 167,\n",
        "            'hid_dims': hid_dims,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'IS_R': IS_R,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr*2, # due to the simplicity of MLP, use larger lr\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'model_path': f'ckpt_MLP.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    config_ATF = {'model_type': 'AttentiveFP',\n",
        "            'graph_feat_size': graph_feat_size,\n",
        "            'num_timesteps': num_timesteps,\n",
        "            'n_layers': n_layers,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'IS_R': IS_R,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr,\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'model_path': 'ckpt_AT.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    config_GIN = {'model_type': 'GIN',\n",
        "            'pretrain_model': pre_models_GIN[pre_model_num],\n",
        "            'in_dim': in_dim,\n",
        "            'hid_dims': hid_dims,\n",
        "            'out_dim': len(names),\n",
        "            'prop_names': names,\n",
        "            'dropout': dropout,\n",
        "            'batch_size': batch_size,\n",
        "            'IS_R': IS_R,\n",
        "            'lr': lr,\n",
        "            'wd': wd,\n",
        "            'patience': patience,\n",
        "            'model_path': f'ckpt_GIN_{pre_models_GIN[pre_model_num]}.pt',\n",
        "            'scale_dict': scale_dict}\n",
        "\n",
        "    if model_type == 'MLP':           con_MO = config_MLP\n",
        "    elif model_type == 'AttentiveFP': con_MO = config_ATF\n",
        "    elif model_type == 'GIN':         con_MO = config_GIN\n",
        "    elif model_type == 'RNN':         pass\n",
        "    else: print('Error !{MLP, AttentiveFP, GIN, RNN}'); return None\n",
        "    return con_MO\n",
        "\n"
      ],
      "metadata": {
        "id": "Zq-nZN24QpRT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train MO"
      ],
      "metadata": {
        "id": "KP6nW-KLRUHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run time for GIN 1- 5 tasks"
      ],
      "metadata": {
        "id": "NZ5_2Q-rzak5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names_metabolism = ['CYP2C19_Veith','CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "                    'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "models_all = []\n",
        "test_loads = []\n",
        "config_all = []\n",
        "trains, valids, tests = collect_data_10_17(names_metabolism)\n",
        "\n",
        "print(f'train: {len(trains)} | valid: {len(valids)} | test: {len(tests)} | '\n",
        "      f'total: {len(trains) + len(valids) + len(tests)}')\n",
        "\n",
        "model_types = ['MLP', 'AttentiveFP', 'GIN']\n",
        "for model_type in model_types:\n",
        "    for i in range(5):\n",
        "        names = names_metabolism[:i+1]\n",
        "        print(f'\\n# {len(names)} tasks: {names}')\n",
        "        config = get_config(model_type, names)\n",
        "        config['model_path'] = f'ckpt_{model_type}_task_{i+1}.pt'\n",
        "        config_all.append(config)\n",
        "        print(config)\n",
        "        train_l, valid_l, test_l = get_multi_loader(trains, valids, tests,\n",
        "        config['prop_names'], config['batch_size'], config['model_type'])\n",
        "\n",
        "        models = PRED(**config); models.train(train_l, valid_l, test_l)\n",
        "        models_all.append(models); test_loads.append(test_l)"
      ],
      "metadata": {
        "id": "Gq05snzozGmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(config_all)):\n",
        "    if i %5 == 0: print(model_types[i//5])\n",
        "    models, config, test_loader = models_all[i], config_all[i], test_loads[i]\n",
        "    # models.eval(test_loader, config['model_path'], True)\n",
        "    mean_time, std_time = models.get_runtime(verbose=False)\n",
        "    # print(mean_time, std_time)\n",
        "    print(f'\\t{i%5}: {mean_time:.3f} $\\pm$ {std_time:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edqVLajLRg3u",
        "outputId": "8a74ac7a-6817-4cba-af09-7601e9a0c7e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP\n",
            "\t0: 0.207 $\\pm$ 0.062\n",
            "\t1: 0.189 $\\pm$ 0.004\n",
            "\t2: 0.201 $\\pm$ 0.005\n",
            "\t3: 0.198 $\\pm$ 0.004\n",
            "\t4: 0.205 $\\pm$ 0.004\n",
            "AttentiveFP\n",
            "\t0: 0.365 $\\pm$ 0.050\n",
            "\t1: 0.384 $\\pm$ 0.052\n",
            "\t2: 0.363 $\\pm$ 0.019\n",
            "\t3: 0.392 $\\pm$ 0.022\n",
            "\t4: 0.383 $\\pm$ 0.019\n",
            "GIN\n",
            "\t0: 2.586 $\\pm$ 0.041\n",
            "\t1: 2.583 $\\pm$ 0.031\n",
            "\t2: 2.602 $\\pm$ 0.054\n",
            "\t3: 2.609 $\\pm$ 0.055\n",
            "\t4: 2.630 $\\pm$ 0.037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FINAL RESULTS\n",
        "\n",
        "```\n",
        "5 tasks maximum on metabolism, runtime comparison\n",
        "MLP\n",
        "\t0: 0.207 $\\pm$ 0.062\n",
        "\t1: 0.189 $\\pm$ 0.004\n",
        "\t2: 0.201 $\\pm$ 0.005\n",
        "\t3: 0.198 $\\pm$ 0.004\n",
        "\t4: 0.205 $\\pm$ 0.004\n",
        "AttentiveFP\n",
        "\t0: 0.365 $\\pm$ 0.050\n",
        "\t1: 0.384 $\\pm$ 0.052\n",
        "\t2: 0.363 $\\pm$ 0.019\n",
        "\t3: 0.392 $\\pm$ 0.022\n",
        "\t4: 0.383 $\\pm$ 0.019\n",
        "GIN\n",
        "\t0: 2.586 $\\pm$ 0.041\n",
        "\t1: 2.583 $\\pm$ 0.031\n",
        "\t2: 2.602 $\\pm$ 0.054\n",
        "\t3: 2.609 $\\pm$ 0.055\n",
        "\t4: 2.630 $\\pm$ 0.037\n",
        "```"
      ],
      "metadata": {
        "id": "9T98MD_RffYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_types = ['MLP', 'AttentiveFP', 'GIN']\n",
        "# for i in range(15):\n",
        "#     if i %5 == 0: print(model_types[i//5])\n",
        "#     print(i%5, i//5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_8tle5p0sz0",
        "outputId": "17b53839-b155-489d-ffa2-b23a300beb9e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP\n",
            "0 0\n",
            "1 0\n",
            "2 0\n",
            "3 0\n",
            "4 0\n",
            "AttentiveFP\n",
            "0 1\n",
            "1 1\n",
            "2 1\n",
            "3 1\n",
            "4 1\n",
            "GIN\n",
            "0 2\n",
            "1 2\n",
            "2 2\n",
            "3 2\n",
            "4 2\n"
          ]
        }
      ]
    }
  ]
}