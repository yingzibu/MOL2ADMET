{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1vByFoJ9PAjdMWmw7eYPq3lHL8rwexGOl",
      "authorship_tag": "ABX9TyOIZc0DzR0SpYw3+FWC1PQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/MOL2ADMET/blob/main/results/chemberta_ADMET_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3GZjcYckfLC",
        "outputId": "97f293ac-9a31-4501-b891-41864e19cba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "cuda:  True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print('cuda: ', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "! pip install selfies  --quiet\n",
        "! pip install pubchempy --quiet\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet\n",
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet\n",
        "\n",
        "\n",
        "# specific for chemberta\n",
        "!pip uninstall transformers -y\n",
        "!pip install transformers==4.30.2 --quiet"
      ],
      "metadata": {
        "id": "P6w2qW2hk-de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ino4SfIvlKCo",
        "outputId": "ba226b58-5d18-4291-b4e8-86540ec8a230"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.func_utils import make_path, convert_with_qed_sa, get_min, \\\n",
        "                                plot_loss, plot_performance\n",
        "\n",
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "from scripts.model_architecture import *\n",
        "from scripts.dataset import *\n",
        "from scripts.train import *\n",
        "import yaml\n",
        "import pandas as pd\n",
        "from scripts.get_vocab import *\n",
        "\n",
        "from tdc.single_pred import ADME\n",
        "from tdc.single_pred import Tox\n",
        "from scripts.CONSTANT import *\n",
        "from scripts.yaml_utils import *\n",
        "from scripts.TRAIN import *\n",
        "from scripts.MUE import *\n",
        "from IPython.display import Code\n",
        "print('VOCAB TYPE:', VOCAB_TYPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE9KGbfGlpv6",
        "outputId": "8850c3ec-4e64-4786-8302-4a0e5cc84610"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB TYPE: smiles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Code('scripts/train.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ICn8TpdzLxaW",
        "outputId": "dc44dff8-dad2-4a01-8b11-14b2a741dc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\"\"\n",
              "Date: 09/07/2023\n",
              "Mods: 11/08/2023, edited train_epoch_VAE: add tqdm\n",
              "Athr: Bu\n",
              "Aims: train functions for all models\n",
              "Mods: \n",
              "      02/05/2024, add scale_back in model_predict function\n",
              "Func:\n",
              "      tbc...\n",
              "\"\"\"\n",
              "\n",
              "import yaml\n",
              "import time\n",
              "import torch\n",
              "import IPython\n",
              "import imageio\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "from os import walk\n",
              "import torch.nn as nn\n",
              "from tqdm import tqdm\n",
              "from torch.nn import Module\n",
              "import torch.nn.functional as F\n",
              "from torch.nn.utils import clip_grad_norm_\n",
              "from dgllife.utils import EarlyStopping, Meter\n",
              "from torch.utils.data import DataLoader, Dataset\n",
              "\n",
              "\n",
              "from scripts.CONSTANT import *\n",
              "from scripts.eval_utils import *\n",
              "from scripts.func_utils import *\n",
              "from scripts.dataset import get_loader\n",
              "from scripts.model_architecture import *\n",
              "\n",
              "clip_grad  = 50\n",
              "model_types = ['MLP', 'AttentiveFP', 'GIN', 'RNN', \n",
              "                'VAE', 'RNN_pretrain', 'MUE', 'chemBERTa']\n",
              "\n",
              "def count_bool(lst): return sum(lst)\n",
              "\n",
              "def count_parameters(model: Module):\n",
              "    return sum(p.numel() for p in model.parameters())\n",
              "\n",
              "def count_trainable(model):\n",
              "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
              "\n",
              "def get_optim_params(model):\n",
              "    return (p for p in model.parameters() if p.requires_grad)\n",
              "    \n",
              "def initialize_weights(m):\n",
              "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
              "        nn.init.xavier_uniform_(m.weight.data)\n",
              "\n",
              "def clamp(number, min_value=1e-5, max_value=1-1e-5):\n",
              "    return max(min_value, min(number, max_value))\n",
              "# uncertainty weight\n",
              "class MTLoss(Module): # calculate multitask loss with trainable parameters\n",
              "    def __init__(self, task_num, weight_loss=None, device='cuda'): \n",
              "        super(MTLoss, self).__init__()\n",
              "        self.task_num = task_num\n",
              "        self.device = device\n",
              "        if weight_loss==None: weight_loss = [1.0] * self.task_num\n",
              "        # ùúÇ := ùëôùëúùëîùúé2\n",
              "        self.eta = nn.Parameter(torch.tensor(weight_loss, device=self.device))\n",
              "        \n",
              "    def forward(self, loss_list, IS_R=None):\n",
              "        assert len(loss_list) == self.task_num\n",
              "        if IS_R != None: \n",
              "            assert len(IS_R) == len(loss_list)\n",
              "            for i in range(len(IS_R)):\n",
              "                if IS_R[i] == True: loss_list[i] /= 2 \n",
              "        loss_list = torch.Tensor(loss_list).to(self.device)\n",
              "        total_loss = loss_list * torch.exp(-self.eta) + self.eta * 0.5 \n",
              "\n",
              "        weight_loss = [float(self.eta[i].item()) for i in range(self.task_num)]\n",
              "        weight_loss = [np.exp(-1.0 * i) for i in weight_loss]\n",
              "        if IS_R != None:\n",
              "            for i in range(len(IS_R)):\n",
              "                if IS_R[i] == True: weight_loss[i] /= 2\n",
              "\n",
              "        weight_loss = [i/sum(weight_loss) for i in weight_loss]\n",
              "        \n",
              "        for n in range(len(weight_loss)): \n",
              "            if weight_loss[n] < 1e-5: weight_loss[n] = clamp(weight_loss[n])\n",
              "        weight_loss = [i/sum(weight_loss) for i in weight_loss]\n",
              "\n",
              "        \n",
              "        return total_loss.sum(), weight_loss\n",
              "\n",
              "\n",
              "def init_model(**config):\n",
              "    \"\"\"need incorporate all models here! \"\"\"\n",
              "    if   config['model_type'] == 'MLP':          model = Classifier(**config)\n",
              "    elif config['model_type'] == 'GIN':          model = GIN_MOD(**config) \n",
              "    elif config['model_type'] == 'AttentiveFP':  model = AttentiveFP(**config)\n",
              "    elif config['model_type'] == 'RNN':          model = RNN(**config)\n",
              "    elif config['model_type'] == 'VAE':          model = RNNVAE(**config)\n",
              "    elif config['model_type'] == 'RNN_pretrain': model = RNN_pretrain(**config)\n",
              "    elif config['model_type'] == 'MUE':          model = Classifier(**config)\n",
              "    elif config['model_type'] == 'chemBERTa':    model = chemBERTa(**config)\n",
              "    else:                    print('invalid model type:', config['model_type'])\n",
              "    return model\n",
              "\n",
              "\n",
              "def get_train_fn(model_type):\n",
              "    if   model_type == 'VAE':       return train_epoch_VAE\n",
              "    elif model_type in model_types: return train_epoch_MLP\n",
              "    else: print('invalid model type:', model_type); return\n",
              "\n",
              "def get_eval_fn(model_type):\n",
              "    if   model_type == 'VAE':       return train_epoch_VAE\n",
              "    elif model_type in model_types: return train_epoch_MLP\n",
              "    else: print('invalid model type:', model_type); return\n",
              "\n",
              "def train_epoch_MLP(model, loader, IS_R, names, device,\n",
              "                    epoch=None, optimizer=None, MASK=-100,\n",
              "                    scale_dict=None, weight_loss=None, \n",
              "                    model_type='model', ver=False):\n",
              "    \"\"\"\n",
              "    param weight_loss: list, the weight of loss for different tasks\n",
              "    \"\"\"\n",
              "    \n",
              "    if optimizer==None: # no optimizer, either validation or test\n",
              "        model.eval()    # model evaluation for either valid or test\n",
              "        if epoch != None: train_type='Valid' # if epoch is inputted, its valid\n",
              "        else: train_type = 'Test' # if no epoch information, its test\n",
              "    else: model.train(); train_type='Train' # if optimizer inputted, its train\n",
              "    \n",
              "\n",
              "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
              "    else: IS_R_list = [IS_R] * len(names)\n",
              "    if weight_loss == None: weight_loss = [1.0/len(names)]*len(names)\n",
              "\n",
              "    total_loss, losses_list, y_probs, y_label = 0, [], {}, {}\n",
              "    for idx, batch_data in enumerate(loader):\n",
              "        \"\"\"\n",
              "        len(batch_data) could determine which algorithm\n",
              "        len(batch_data) == 2: MLP, GIN, RNN, ENSEMBLE\n",
              "        len(batch_data) == 4: AttentiveFP\n",
              "        \"\"\"\n",
              "        if len(batch_data) == 2:  # MLP or GIN or RNN or chemBERTa\n",
              "            fp, labels = batch_data \n",
              "            # fp, labels = fp.to(device), labels.to(device)\n",
              "            labels = labels.to(device)\n",
              "            \n",
              "            try: fp = fp.to(device) # MLP, GIN, RNN\n",
              "            except: # chemberta\n",
              "                del batch_data\n",
              "                fp = list(fp)   # actually SMILES, convert tuple to list\n",
              "                if len(names) == 1: \n",
              "                    labels = labels.reshape(len(fp), len(names))\n",
              "            \n",
              "            mask = labels == MASK\n",
              "            pred = model(fp)\n",
              "            del fp\n",
              "            \n",
              "        elif len(batch_data) == 4: # attentiveFP\n",
              "            smiles, bg, labels, masks = batch_data\n",
              "            bg,labels,masks = bg.to(device), labels.to(device), masks.to(device)\n",
              "            n_feats = bg.ndata.pop('hv').to(device)\n",
              "            e_feats = bg.edata.pop('he').to(device)\n",
              "            pred = model(bg, n_feats, e_feats)\n",
              "            mask = masks < 1\n",
              "        \n",
              "        batch_loss_list = []\n",
              "        for j, (name, IS_R, w) in enumerate(zip(names, IS_R_list, weight_loss)):\n",
              "            loss_func = get_loss_fn(IS_R)\n",
              "            probs = pred[:, j][~mask[:, j]]\n",
              "            label = labels[:, j][~mask[:, j]]\n",
              "             \n",
              "            \n",
              "            len_here = label.shape[0] # num of data with labels\n",
              "            loss_here = loss_func(probs, label) \n",
              "            if len_here != 0:\n",
              "                loss_here /= len_here\n",
              "                batch_loss_list.append(loss_here.item())\n",
              "            else:       batch_loss_list.append(float(0))\n",
              "            \n",
              "            if j == 0: loss  = loss_here * w\n",
              "            else:      loss += loss_here * w\n",
              "\n",
              "            if IS_R == False: probs = F.sigmoid(probs)\n",
              "            if train_type != 'Train': # valid or test, output probs and labels\n",
              "                                      # if train, no process prob to save time\n",
              "                probs = probs.cpu().detach().numpy().tolist()\n",
              "                label = label.cpu().detach().numpy().tolist()\n",
              "                if scale_dict != None:\n",
              "                    if name in scale_dict.keys():\n",
              "                        min_here = scale_dict[name][0]\n",
              "                        max_here = scale_dict[name][1]\n",
              "                        del_here = max_here - min_here\n",
              "                        label = [l * del_here + min_here for l in label]\n",
              "                        probs = [p * del_here + min_here for p in probs]\n",
              "                    \n",
              "                if idx == 0: y_probs[name], y_label[name] = probs, label\n",
              "                else:     y_probs[name] += probs; y_label[name] += label\n",
              "        \n",
              "        if len(losses_list) == 0:               losses_list = batch_loss_list\n",
              "        else: losses_list = [i+j for i, j in zip(losses_list, batch_loss_list)]\n",
              "\n",
              "        total_loss += loss.item()\n",
              "\n",
              "        if optimizer != None:\n",
              "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
              "\n",
              "    total_loss /= len(loader) # no need /loader.dataset since has / len_here \n",
              "    \n",
              "    if epoch != None: # train or valid\n",
              "        if ver: print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
              "    \n",
              "    elif epoch == None: # test\n",
              "        print(f'[{train_type}] Loss: {total_loss:.3f}')\n",
              "        performance = eval_dict(y_probs, y_label, names, IS_R_list, \n",
              "                                model_type=model_type, draw_fig=True)\n",
              "        performance['loss'] = float(total_loss)\n",
              "\n",
              "    IS_R = IS_R_list\n",
              "    if   train_type == 'Train': return total_loss, losses_list, IS_R # train\n",
              "    elif train_type == 'Valid': return total_loss,  y_probs, y_label # valid\n",
              "    else:                       return performance, y_probs, y_label # test\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "def train_epoch_VAE(model, loader, IS_R, names, device, \n",
              "                    kl_weight=1, cls_weight=1,\n",
              "                    epoch=None, optimizer=None, \n",
              "                    MASK=-100, scale_dict=None, \n",
              "                    weight_loss=None, model_type='model'):\n",
              "\n",
              "    if optimizer == None: \n",
              "        model.eval()          # Valid or Test\n",
              "        if epoch != None: train_type = 'Valid'\n",
              "        else:             train_type = 'Test'\n",
              "    else:  model.train(); train_type = 'Train'\n",
              "\n",
              "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
              "    else: IS_R_list = [IS_R] * len(names)\n",
              "    \n",
              "    if weight_loss == None: weight_loss = [1.0/len(names)]*len(names)\n",
              "    total_loss, losses_list, y_probs, y_label = 0, [], {}, {}\n",
              "    klds, recs, clss = 0, 0, 0\n",
              "    for idx, batch_data in tqdm(enumerate(loader), \n",
              "                            total=len(loader), desc=f'{train_type}'):\n",
              "        if len(batch_data) == 2: x, labels = batch_data\n",
              "        else: x, labels = batch_data, None\n",
              "        kld, rec, pred = model(x, labels)\n",
              "        if pred == None: cls = torch.tensor([0]).to(device)\n",
              "        else: # label is not none, and has pred, calculate: \n",
              "            labels = labels.to(device)\n",
              "            mask = labels == MASK\n",
              "            batch_loss_list = []\n",
              "            for j, (name, IS_R, w) in enumerate(\n",
              "                zip(names, IS_R_list, weight_loss)):\n",
              "                loss_func = get_loss_fn(IS_R)\n",
              "                probs = pred[:,j][~mask[:,j]]\n",
              "                label = labels[:,j][~mask[:,j]]\n",
              "                len_here = label.shape[0]\n",
              "                loss_here = loss_func(probs, label)\n",
              "                if len_here != 0: \n",
              "                    loss_here /= len_here\n",
              "                    batch_loss_list.append(loss_here.item())\n",
              "                else: batch_loss_list.append(float(0))\n",
              "\n",
              "                if j == 0: cls  = loss_here * w\n",
              "                else:      cls += loss_here * w\n",
              "\n",
              "                if IS_R == False: probs = F.sigmoid(probs)\n",
              "                if train_type != 'Train': \n",
              "                    probs = probs.cpu().detach().numpy().tolist()\n",
              "                    label = label.cpu().detach().numpy().tolist()\n",
              "                    if scale_dict != None: \n",
              "                        if name in scale_dict.keys():\n",
              "                            min_here = scale_dict[name][0]\n",
              "                            max_here = scale_dict[name][1]\n",
              "                            del_here = max_here - min_here\n",
              "                            label = [l * del_here + min_here for l in label]\n",
              "                            probs = [p * del_here + min_here for p in probs]\n",
              "                    if idx == 0: y_probs[name], y_label[name] = probs, label\n",
              "                    else:     y_probs[name] += probs; y_label[name] += label \n",
              "            if len(losses_list) == 0: losses_list = batch_loss_list\n",
              "            else: losses_list = [i+j for i, j in zip(\n",
              "                                    losses_list, batch_loss_list)]\n",
              "            \n",
              "        loss = kl_weight * kld + rec + cls_weight * cls\n",
              "        total_loss += loss.item()\n",
              "        klds += kld.item(); recs += rec.item(); clss += cls.item()\n",
              "\n",
              "        if optimizer != None: \n",
              "            optimizer.zero_grad(); loss.backward()\n",
              "            clip_grad_norm_(get_optim_params(model), clip_grad)\n",
              "            optimizer.step()\n",
              "        lr=(optimizer.param_groups[0]['lr'] if optimizer is not None else None)\n",
              "    \n",
              "    IS_R = IS_R_list\n",
              "    total_loss /= len(loader)\n",
              "    klds /= len(loader); recs /= len(loader); clss /= len(loader)\n",
              "    if epoch != None: \n",
              "        print(f'Epoch:{epoch} [{train_type}] Loss: {total_loss:.3f} |',\n",
              "              f'KL Div: {klds:.3f} | Recon: {recs:.3f} | Classify: {clss:.3f}',\n",
              "              f'| KL w: {kl_weight:.3f} | cls w: {cls_weight:.3f}') \n",
              "    else:\n",
              "        print(f'[{train_type}] Loss: {total_loss:.3f} | Classify: {clss:.3f}')\n",
              "        perf = eval_dict(y_probs, y_label, names, IS_R, \n",
              "                         model_type=model_type, draw_fig=True)\n",
              "        perf['loss'] = float(clss)\n",
              "    \n",
              "    if   train_type == 'Train': return [total_loss, clss], losses_list, IS_R\n",
              "    elif train_type == 'Valid': return [total_loss, clss], y_probs, y_label\n",
              "    elif train_type == 'Test':  return perf,       y_probs, y_label\n",
              "\n",
              "def eval_VAE(model, loader, names, scale_dict=None, MASK=MASK):\n",
              "    model.eval()\n",
              "    if isinstance(names, str): names = [names]\n",
              "    IS_R = [names_dict[name] for name in names]\n",
              "    y_probs, y_label, mu_dict = {}, {}, {}\n",
              "    for idx, (input_, labels) in enumerate(loader):\n",
              "        input_, labels = input_.to(model.device), labels.to(model.device)\n",
              "        mu, _ = model.encoder(input_)\n",
              "        preds = model.classifier(mu)\n",
              "        mask = labels == MASK\n",
              "        del input_\n",
              "\n",
              "        for j, (name, is_r) in enumerate(zip(names, IS_R)):\n",
              "            probs = preds[:,j][~mask[:,j]]\n",
              "            label = labels[:,j][~mask[:,j]]\n",
              "            mask_here = mask[:,j].reshape(mask[:, j].shape[0], 1).expand_as(mu)\n",
              "            mu_ = mu * (~mask_here)\n",
              "            del mask_here\n",
              "            if is_r == False: probs = F.sigmoid(probs)\n",
              "            probs = probs.cpu().detach().numpy().tolist()\n",
              "            label = label.cpu().detach().numpy().tolist()\n",
              "            mu_   = mu_.cpu().detach().numpy()\n",
              "\n",
              "            if scale_dict != None:\n",
              "                if name in scale_dict.keys():\n",
              "                    min_here = scale_dict[name][0]\n",
              "                    max_here = scale_dict[name][1]\n",
              "                    del_here = max_here - min_here\n",
              "                    label = [l*del_here + min_here for l in label]\n",
              "                    probs = [p*del_here + min_here for p in probs]\n",
              "            if idx == 0:\n",
              "                y_probs[name], y_label[name], mu_dict[name] = probs, label, mu_\n",
              "            else:\n",
              "                y_probs[name] += probs; y_label[name] += label\n",
              "                mu_dict[name] = np.append(mu_dict[name], mu_, axis=0)\n",
              "\n",
              "    return mu_dict, y_probs, y_label \n",
              "\n",
              "def model_predict(model, loader, IS_R, names, device, model_type, \n",
              "        MASK=-100, scale_dict=None, scale_back=True):\n",
              "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
              "    else: IS_R_list = [IS_R] * len(names)\n",
              "    model.eval()\n",
              "    y_probs = {}\n",
              "    for idx, batch_data in tqdm(enumerate(loader), total=len(loader), \n",
              "                                desc='Predicting...'):\n",
              "        if len(batch_data) == 1: print('dataloader error'); return\n",
              "        elif len(batch_data) == 2: \n",
              "            fp, labels = batch_data;    labels = labels.to(device)\n",
              "            if model_type == 'VAE': _, _, pred = model(fp, labels)\n",
              "            else: fp = fp.to(device);     pred = model(fp)\n",
              "        elif len(batch_data) == 4: \n",
              "            _,bg,_,_=batch_data; bg = bg.to(device)\n",
              "            # bg, labels = bg.to(device), labels.to(device)\n",
              "            n_feats = bg.ndata.pop('hv').to(device)\n",
              "            e_feats = bg.edata.pop('he').to(device)\n",
              "            pred = model(bg, n_feats, e_feats)\n",
              "        # print(pred.shape)\n",
              "        # print(fp.shape)\n",
              "        for j, (name, IS_R) in enumerate(zip(names, IS_R_list)):\n",
              "            probs = pred[:, j]\n",
              "            if IS_R == False: probs = F.sigmoid(probs)\n",
              "            probs = probs.cpu().detach().numpy().tolist()\n",
              "            if scale_dict != None and scale_back == True: \n",
              "                if name in scale_dict.keys():\n",
              "                    min_here = scale_dict[name][0]\n",
              "                    max_here = scale_dict[name][1]\n",
              "                    del_here = max_here - min_here\n",
              "                    probs = [p * del_here + min_here for p in probs]\n",
              "            if idx == 0: y_probs[name]  = probs\n",
              "            else:        y_probs[name] += probs\n",
              "    return y_probs\n",
              "\n",
              "\n",
              "class PRED:\n",
              "    def __init__(self, **config):\n",
              "        if 'device' in config: self.device = config['device']\n",
              "        else: \n",
              "            cuda = torch.cuda.is_available()\n",
              "            if cuda: self.device = 'cuda'\n",
              "            else:    self.device = 'cpu'\n",
              "        \n",
              "        self.config = config; self.prop_names = config['prop_names']\n",
              "        \n",
              "        if 'scale_dict' not in config: self.scale_dict = None\n",
              "        else:           self.scale_dict = config['scale_dict']\n",
              "        if 'weight_loss' not in config: self.weight_loss = None\n",
              "        else:          self.weight_loss = config['weight_loss']\n",
              "        self.model_type = config['model_type']\n",
              "        self.model = init_model(**config).to(self.device)\n",
              "        self.params_num = count_parameters(self.model)\n",
              "        print('Model type: ', self.model_type, end=\"\")\n",
              "        print(' | Model parameters: ',self.params_num)\n",
              "        self.vocab = None if 'vocab' not in config else config['vocab']\n",
              "        \n",
              "        if 'vocab_type' not in config: self.vocab_type = None\n",
              "        else:           self.vocab_type = config['vocab_type']\n",
              "        \n",
              "        # initialize model paths and config path\n",
              "        self.model_path = config['model_path']\n",
              "        if 'encoder_path' not in config: self.encoder_path = None\n",
              "        else:          self.encoder_path = config['encoder_path']\n",
              "        if 'decoder_path' not in config: self.decoder_path = None\n",
              "        else:          self.decoder_path = config['decoder_path']\n",
              "        if 'classifier_path' not in config: self.classifier_path = None\n",
              "        else:          self.classifier_path = config['classifier_path']\n",
              "        if 'config_path' not in config: \n",
              "            c_p = self.model_path.split('.')[0] + '.yml'\n",
              "            self.config_path = c_p; self.config['config_path'] = c_p\n",
              "        else: self.config_path = config['config_path']\n",
              "        if 'figure_path' not in config:\n",
              "            figure_path = self.model_path.split('.')[0]\n",
              "            self.figure_path = figure_path\n",
              "            self.config['figure_path'] = figure_path\n",
              "        else: self.figure_path = config['figure_path']\n",
              "        \n",
              "        self.eval_fn = get_eval_fn(self.model_type)\n",
              "        self.train_fn = get_train_fn(self.model_type)\n",
              "        self.IS_R = config['IS_R'] # could be list, could be true/false\n",
              "        self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
              "                        lr=config['lr'], weight_decay=config['wd'])\n",
              "        self.stopper = EarlyStopping(mode='lower', patience=config['patience'])\n",
              "        if 'verbose_freq' not in config:\n",
              "            self.verbose_freq = 10\n",
              "            self.config['verbose_freq'] = self.verbose_freq\n",
              "        else: self.verbose_freq = config['verbose_freq']\n",
              "        if 'uncertainty_weight' not in config: \n",
              "            if len(self.prop_names) == 1: self.uw = False # single task\n",
              "            else: self.uw = True\n",
              "        else: self.uw = config['uncertainty_weight']    \n",
              "        self.min_loss, self.best_epoch = np.inf, 0\n",
              "        if 'MAX_EPOCH' not in self.config: self.MAX_EPOCH = 1000\n",
              "        else:          self.MAX_EPOCH = self.config['MAX_EPOCH']\n",
              "        \n",
              "        if 'max_kl_weight' not in self.config: self.max_kl_weight = 0.5\n",
              "        else: self.max_kl_weight = self.config['max_kl_weight']\n",
              "        if 'cls_weight' not in self.config: self.cls_weight = 0.5\n",
              "        else: self.cls_weight = self.config['cls_weight'] \n",
              "\n",
              "        self.train_dict, self.valid_dict, self.times_list = {}, {}, []\n",
              "        \n",
              "        # will store the results on test set, if test set == None, leave blank\n",
              "        self.performance_dict = {} \n",
              "\n",
              "        self.data = dict(config     = self.config,\n",
              "                         min_loss   = self.min_loss,\n",
              "                         best_epoch = self.best_epoch, \n",
              "                         train_dict = self.train_dict, \n",
              "                         valid_dict = self.valid_dict,\n",
              "                         times_list = self.times_list,\n",
              "                         params_num = self.params_num, \n",
              "                         performance= self.performance_dict)\n",
              "    \n",
              "    def save_train_status(self): \n",
              "        self.data = dict(\n",
              "            config = self.config,\n",
              "            min_loss = self.min_loss,\n",
              "            best_epoch = self.best_epoch, \n",
              "            train_dict = self.train_dict, \n",
              "            valid_dict = self.valid_dict,\n",
              "            times_list = self.times_list,\n",
              "            params_num = self.params_num, \n",
              "            performance = self.performance_dict)\n",
              "\n",
              "        with open(self.config_path, 'w') as fl:\n",
              "            yaml.dump(self.data, fl, default_flow_style=False)\n",
              "        print('\\n--> Train status saved at', self.config_path)\n",
              "\n",
              "    def load_encoder(self, encoder_path=None):# this is VAE or RNN_pretrain\n",
              "        if encoder_path == None: encoder_path = self.encoder_path \n",
              "        self.model.encoder.load_state_dict(torch.load(\n",
              "               encoder_path, map_location=self.device))\n",
              "        print('Finish load encoder from', encoder_path)\n",
              "    \n",
              "    def load_decoder(self, decoder_path=None):\n",
              "        if decoder_path == None: decoder_path = self.decoder_path\n",
              "        self.model.decoder.load_state_dict(torch.load(\n",
              "               decoder_path, map_location=self.device))\n",
              "        print('Finish load decoder from', decoder_path)\n",
              "\n",
              "    def load_classifier(self, classifier_path=None):\n",
              "        if classifier_path == None: classifier_path=self.classifier_path\n",
              "        self.model.classifier.load_state_dict(torch.load(classifier_path, \n",
              "                                               map_location=self.device)) \n",
              "        print('Finish load classifier from', classifier_path)\n",
              "\n",
              "    def load_vae_pretrain(self, encoder_path=None, classifier_path=None):\n",
              "        self.load_encoder(encoder_path)\n",
              "        self.load_classifier(classifier_path)\n",
              "    \n",
              "    def load_vae(self, encoder_path=None, decoder_path=None):\n",
              "        self.load_encoder(encoder_path); self.load_decoder(decoder_path)\n",
              "\n",
              "    def load_model(self, path=None):\n",
              "        if self.model_type == 'AttentiveFP': \n",
              "            con = self.config.copy(); con['dropout'] = 0\n",
              "            self.model = init_model(**con).to(self.device)\n",
              "        if path == None: path = self.model_path\n",
              "        print('load pretrained model from ', path)\n",
              "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
              "    \n",
              "    def load_status(self, data):\n",
              "        # with open(yml_file_path, 'r') as f:\n",
              "        #     data = yaml.safe_load(f)\n",
              "        self.data = data\n",
              "        self.config = data['config']\n",
              "        self.model_path = self.config['model_path'] \n",
              "        # self.load_model(self.config['model_path'])\n",
              "        self.min_loss = data['min_loss']\n",
              "        self.best_epoch = data['best_epoch']\n",
              "        self.train_dict = data['train_dict']\n",
              "        self.valid_dict = data['valid_dict']\n",
              "        self.times_list = data['times_list']\n",
              "        self.params_num = data['params_num']\n",
              "        self.performance_dict = data['performance']\n",
              "        print('finish load data status \\n')\n",
              "\n",
              "    def get_runtime(self, verbose=True):\n",
              "        if verbose:\n",
              "            print(f'Train time: {np.mean(self.times_list):.3f}'\n",
              "                  f'+/-{np.std(self.times_list):.3f} ms')\n",
              "        return np.mean(self.times_list), np.std(self.times_list)\n",
              "\n",
              "    def print_config(self): \n",
              "        print('#'*68); print('#'*30, 'CONFIG', '#'*30); print('#'*68)\n",
              "        for i, j in self.config.items():             print(i, ':', j)\n",
              "        print('#'*68)\n",
              "\n",
              "    def eval(self, loader, path=None, ver=False):\n",
              "        if ver: self.print_config()\n",
              "        \n",
              "        if path != None: self.load_model(path)\n",
              "        else: self.load_model(self.model_path)\n",
              "        if self.model_type == 'VAE': self.load_vae_pretrain()\n",
              "        if ver:\n",
              "            # if self.weight_loss != None: print('task weight: ',self.weight_loss)\n",
              "            print('Model parameters: ', count_parameters(self.model))\n",
              "            self.get_runtime()\n",
              "            print(f\"epoch {self.best_epoch} -> min loss {self.min_loss:.4f}\")\n",
              "            plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
              "                      title_name= f'loss during training {self.model_type}')\n",
              "        \n",
              "        performance, probs, label = self.eval_fn(self.model, loader, self.IS_R, \n",
              "            self.prop_names, self.device, epoch=None, optimizer=None, \n",
              "            MASK=-100, scale_dict=self.scale_dict, weight_loss=None,\n",
              "            # weight_loss=self.weight_loss, # should not use the weightloss\n",
              "            model_type=self.model_type)\n",
              "        return performance, probs, label\n",
              "\n",
              "\n",
              "    def train_VAE(self, loader, val_loader, test_loader=None, \n",
              "                 data_df=pd.DataFrame(), sample_num=1, latent_eval_freq=1):\n",
              "        \"\"\"\n",
              "        Aim: Train Variational AutoEncoder (VAE), evaluate latent space \n",
              "        params: \n",
              "            loader:       DataLoader, for train\n",
              "            val_loader:   DataLoader, for valid, save model based on its loss\n",
              "            test_loader:  DataLoader, for test,  final performance evaluation\n",
              "            data_df: pd.DataFrame, if no empty, will plot PCA on latent sapce\n",
              "            sample_num:       int, the number of entries sampled from data_df\n",
              "            latent_eval_freq: int, the frequency of plot PCA and save figures\n",
              "        Return performance: dict, performance on test loader\n",
              "                            performance[name]: metrics nums evaluated on name\n",
              "                            performance[loss]: total loss of VAE for test set \n",
              "        \"\"\"\n",
              "        \n",
              "        if len(self.prop_names) == 1: self.uw = False \n",
              "        if self.uw: \n",
              "            m_w = MTLoss(len(self.prop_names), device=self.device) \n",
              "            optimizer = torch.optim.SGD(m_w.parameters(), lr=0.1); m_w.train()\n",
              "\n",
              "        # self.optimizer = torch.optim.AdamW(\n",
              "        #     get_optim_params(self.model), lr=lr_start)\n",
              "        # lr_annealer = CosineAnnealingLRWithRestart(self.optimizer)\n",
              "        \n",
              "        self.model.zero_grad(); start_epoch = self.best_epoch\n",
              "        min_total_loss = np.inf; train_total, valid_total = {}, {} \n",
              "        for epoch in range(start_epoch, self.MAX_EPOCH):\n",
              "            \n",
              "            if epoch % latent_eval_freq == 0:\n",
              "                if len(data_df) > 0: # plot PCA before training one epoch \n",
              "                    if epoch % self.verbose_freq == 0: plot_show = True\n",
              "                    else: plot_show = False\n",
              "                    tmp_ = data_df.sample(n=sample_num).reset_index(drop=True)\n",
              "                    tmp_ = self.model.encoder.cal_mu(tmp_)\n",
              "                    header_here = self.model.encoder.header\n",
              "                    for n in self.prop_names: \n",
              "                        # there might be MASK values in tmp, delete entire row\n",
              "                        tmp = tmp_[tmp_[n]!= MASK]\n",
              "                        plot_dim_reduced(tmp[header_here],tmp[n],names_dict[n],\n",
              "                        dim_reduct='PCA',title = f'PCA on {n} in latent space',\n",
              "                        savepath=self.figure_path, \n",
              "                        savename=f'PCA_{n}_{epoch}.png', plot_show=plot_show)\n",
              "\n",
              "            inc = (epoch - start_epoch) / (self.MAX_EPOCH - start_epoch)\n",
              "            kl_weight = self.max_kl_weight * inc\n",
              "            # cls_weight = self.cls_weight\n",
              "            cls_weight = self.cls_weight * inc\n",
              "            t = time.time()\n",
              "            score, l, r = self.train_fn(self.model, loader, self.IS_R,\n",
              "                                        self.prop_names, self.device, kl_weight, \n",
              "                                        cls_weight, epoch, self.optimizer, \n",
              "                                        scale_dict  = self.scale_dict,\n",
              "                                        weight_loss = self.weight_loss,\n",
              "                                        model_type  = self.model_type)\n",
              "            train_time = (time.time() - t) * 1000 / len(loader.dataset)\n",
              "            \n",
              "            val_s, probs, label = self.train_fn(\n",
              "                self.model, val_loader, self.IS_R, self.prop_names, self.device, \n",
              "                kl_weight, cls_weight, epoch, scale_dict=self.scale_dict,\n",
              "                weight_loss=self.weight_loss, model_type=self.model_type)\n",
              "            \n",
              "            \n",
              "            self.times_list.append(train_time)\n",
              "            if self.uw:\n",
              "                optimizer.zero_grad()\n",
              "                total_loss, self.weight_loss = m_w(l, r)\n",
              "                total_loss.backward(); optimizer.step()\n",
              "            \n",
              "\n",
              "            self.train_dict[epoch] = score[1]; train_total[epoch] = score[0]\n",
              "            self.valid_dict[epoch] = val_s[1]; valid_total[epoch] = val_s[0]\n",
              "            if val_s[0] < min_total_loss:\n",
              "                print(f'# SAVE MODEL: loss: {min_total_loss:.3f} ->',\n",
              "                      f'{val_s[0]:.3f}', end=\" | \")\n",
              "                min_total_loss = val_s[0];  self.best_epoch = epoch\n",
              "                torch.save(self.model.state_dict(), self.model_path)\n",
              "\n",
              "            if val_s[1] < self.min_loss: \n",
              "                # use cls loss as save indicator of enc, dec cls model\n",
              "                # seperate save to simplify later load pretrain models\n",
              "                # load model for MLP, just need to load encoder for FP\n",
              "                # load model for RNN_pretrain, no need to load decoder\n",
              "                # load model for VAE on different tasks, no classifier\n",
              "                print(f'## SAVE Enc, Dec, Cls: classify loss:',\n",
              "                      f'{self.min_loss:.3f} -> {val_s[1]:.3f} ',\n",
              "                      f'| runtime: {train_time:.3f} ms')\n",
              "                self.min_loss = val_s[1]\n",
              "                torch.save(self.model.encoder.state_dict(), self.encoder_path)\n",
              "                torch.save(self.model.decoder.state_dict(), self.decoder_path)\n",
              "                torch.save(self.model.classifier.state_dict(), \n",
              "                           self.classifier_path)\n",
              "            \n",
              "            \n",
              "\n",
              "            early_stop = self.stopper.step(val_s[1], self.model) # cls loss\n",
              "            \n",
              "            \n",
              "            if epoch % self.verbose_freq == 0 and epoch != 0:\n",
              "                self.get_runtime()\n",
              "                if self.uw:                 print('different task weight', \n",
              "                            ['{:.3f}'.format(i) for i in self.weight_loss])\n",
              "                plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
              "                title_name= f'Classify loss during training {self.model_type}')\n",
              "                \n",
              "                plot_loss(train_total, valid_total, name='valid',\n",
              "                title_name= f'Total loss during training {self.model_type}')\n",
              "                \n",
              "                eval_dict(probs, label, self.prop_names,  IS_R=self.IS_R)\n",
              "            \n",
              "            if early_stop: print('early stop'); break\n",
              "\n",
              "        print('Finished training\\n')\n",
              "        if len(data_df) > 0: # evaluated PCA on data_df, create gif\n",
              "            for n in self.prop_names: \n",
              "                images = []\n",
              "                for i in range(epoch+1):\n",
              "                    file_name = self.figure_path + f'/PCA_{n}_{i}.png'\n",
              "                    # print(file_name)\n",
              "                    for j in range(5): \n",
              "                        try: images.append(imageio.imread(file_name))\n",
              "                        except: pass\n",
              "                gif_path = f'{self.figure_path}_{n}.gif'\n",
              "                imageio.mimsave(gif_path, images, duration=1)\n",
              "                print('save gif at: ', gif_path)\n",
              "                # from IPython.display import Image\n",
              "                display(IPython.display.Image(data=open(gif_path, 'rb').read(),\n",
              "                        format='png'))\n",
              "\n",
              "        \n",
              "        self.save_train_status() # status yml is saved iff train finished\n",
              "        # print('task weight', \n",
              "        #                 ['{:.3f}'.format(i) for i in self.weight_loss])\n",
              "        print('Model parameters: ', count_parameters(self.model))\n",
              "        self.get_runtime()\n",
              "        print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
              "        plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
              "                title_name= f'loss during training {self.model_type}')\n",
              "        plot_loss(train_cls, valid_cls, name='valid',\n",
              "                title_name= f'Classify loss during training {self.model_type}')\n",
              "        \n",
              "        if test_loader != None: # evaluate test set\n",
              "            self.performance_dict,_,_ = self.eval(test_loader, self.model_path)\n",
              "            self.save_train_status() # update train status with test performance\n",
              "        print('Finished evaluate test performance, outputs performance dict')\n",
              "        return self.performance_dict\n",
              "\n",
              "    def predict(self, smile_list:list, return_probs=False, scale_back=True):\n",
              "        if self.model_type == 'VAE': self.load_vae_pretrain()\n",
              "        else: self.load_model(self.model_path)\n",
              "        if isinstance(smile_list, str): smile_list = [smile_list]\n",
              "        df = pd.DataFrame(); df['Drug'] = smile_list \n",
              "        \n",
              "        for name in self.prop_names:\n",
              "            df[name] = [MASK] * len(smile_list)\n",
              "        \n",
              "        prm = {'batch_size': 64, 'shuffle': False, \n",
              "               'drop_last': False, 'num_workers': 0}\n",
              "        loader = get_loader(df, self.prop_names, prm, self.model_type,\n",
              "                            self.vocab, self.vocab_type)\n",
              "        \n",
              "        y_probs = model_predict(self.model, loader, self.IS_R, self.prop_names,\n",
              "                self.device, self.model_type, MASK, self.scale_dict, scale_back)\n",
              "        for name in y_probs.keys():\n",
              "            is_r = names_dict[name]\n",
              "            if is_r == False and return_probs==False: # cls, prob -> pred\n",
              "                df[name] = get_preds(0.5, y_probs[name])\n",
              "            else: df[name] = y_probs[name]\n",
              "        return df\n",
              "\n",
              "    def train(self, data_loader, val_loader, test_loader=None,\n",
              "                 data_df=pd.DataFrame(), sample_num=1, latent_eval_freq=1): \n",
              "        if self.best_epoch != 0:\n",
              "            self.model.load_state_dict(torch.load(\n",
              "                self.model_path, map_location=self.device))\n",
              "        else: print(f'Start training {self.model_type}...')\n",
              "        # if 'MAX_EPOCH' not in self.config: MAX_EPOCH = 1000\n",
              "        # else:          MAX_EPOCH = self.config['MAX_EPOCH']\n",
              "        # single task, no need uncertainty weight\n",
              "        if self.model_type == 'VAE': \n",
              "            return self.train_VAE(data_loader, val_loader, test_loader,\n",
              "                                  data_df, sample_num, latent_eval_freq)\n",
              "\n",
              "        if len(self.prop_names) == 1: self.uw = False \n",
              "        if self.uw: \n",
              "            m_w = MTLoss(len(self.prop_names), device=self.device) \n",
              "            optimizer = torch.optim.SGD(m_w.parameters(), lr=0.1); m_w.train()\n",
              "    \n",
              "        \n",
              "        for epoch in range(self.best_epoch, self.MAX_EPOCH):\n",
              "            t = time.time()\n",
              "            score, l, r  = self.train_fn(self.model, data_loader, self.IS_R,\n",
              "                                  self.prop_names, self.device, epoch,\n",
              "                                  self.optimizer, scale_dict=self.scale_dict,\n",
              "                                  weight_loss=self.weight_loss)\n",
              "            train_time = (time.time() - t) * 1000 / len(data_loader.dataset)\n",
              "            self.times_list.append(train_time)\n",
              "\n",
              "            if self.uw: # uncertainty weight training\n",
              "                optimizer.zero_grad()\n",
              "                total_loss, self.weight_loss = m_w(l, r)\n",
              "                total_loss.backward(); optimizer.step()\n",
              "            # do not use weight loss for val?  \n",
              "            val_score, probs, labels = self.train_fn(self.model,  val_loader,\n",
              "                                       self.IS_R,self.prop_names,self.device,\n",
              "                                       epoch,   scale_dict = self.scale_dict,\n",
              "                                       weight_loss=self.weight_loss) \n",
              "            \n",
              "            self.train_dict[epoch] = score\n",
              "            self.valid_dict[epoch] = val_score\n",
              "            print(f'Epoch:{epoch} [Train] Loss: {score:.3f} |',\n",
              "                  f'[Valid] Loss: {val_score:.3f}', end=\"\\t\")\n",
              "            early_stop = self.stopper.step(val_score, self.model)\n",
              "            \n",
              "            if val_score < self.min_loss: # loss drop, save model\n",
              "                print(f'SAVE MODEL: loss: {self.min_loss:.3f} -> '\n",
              "                      f'{val_score:.3f} | runtime: {train_time:.3f} ms')\n",
              "                self.min_loss = val_score;  self.best_epoch = epoch\n",
              "                torch.save(self.model.state_dict(), self.model_path)\n",
              "\n",
              "            if epoch % self.verbose_freq == 0 and epoch != 0:\n",
              "                self.get_runtime()\n",
              "                if self.uw:                 print('different task weight', \n",
              "                           ['{:.3f}'.format(i) for i in self.weight_loss])\n",
              "                plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
              "                    title_name= f'loss during training {self.model_type}')\n",
              "                eval_dict(probs, labels, self.prop_names,  IS_R=self.IS_R)\n",
              "                \n",
              "            if early_stop: print('early stop'); break\n",
              "\n",
              "        print('Finished training\\n')\n",
              "        \n",
              "        self.save_train_status() # status yml file is saved iff train finished\n",
              "        print('task weight', \n",
              "                        ['{:.3f}'.format(i) for i in self.weight_loss])\n",
              "        print('Model parameters: ', count_parameters(self.model))\n",
              "        self.get_runtime()\n",
              "        print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
              "        plot_loss(self.train_dict, self.valid_dict, name='valid',\n",
              "                  title_name= f'loss during training {self.model_type}')\n",
              "        \n",
              "        if test_loader != None: # evaluate test set\n",
              "            self.performance_dict,_,_ = self.eval(test_loader, self.model_path)\n",
              "            self.save_train_status() # update status yml with test performance\n",
              "        print('Finished evaluate test performance, outputs performance dict')\n",
              "        return self.performance_dict\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<style>pre { line-height: 125%; }\n",
              "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              ".output_html .hll { background-color: #ffffcc }\n",
              ".output_html { background: #f8f8f8; }\n",
              ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
              ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
              ".output_html .go { color: #717171 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #687822 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #767600 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
              "<span class=\"sd\">Date: 09/07/2023</span>\n",
              "<span class=\"sd\">Mods: 11/08/2023, edited train_epoch_VAE: add tqdm</span>\n",
              "<span class=\"sd\">Athr: Bu</span>\n",
              "<span class=\"sd\">Aims: train functions for all models</span>\n",
              "<span class=\"sd\">Mods: </span>\n",
              "<span class=\"sd\">      02/05/2024, add scale_back in model_predict function</span>\n",
              "<span class=\"sd\">Func:</span>\n",
              "<span class=\"sd\">      tbc...</span>\n",
              "<span class=\"sd\">&quot;&quot;&quot;</span>\n",
              "\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">yaml</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">IPython</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">imageio</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">os</span> <span class=\"kn\">import</span> <span class=\"n\">walk</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">tqdm</span> <span class=\"kn\">import</span> <span class=\"n\">tqdm</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">Module</span>\n",
              "<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">torch.nn.utils</span> <span class=\"kn\">import</span> <span class=\"n\">clip_grad_norm_</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">dgllife.utils</span> <span class=\"kn\">import</span> <span class=\"n\">EarlyStopping</span><span class=\"p\">,</span> <span class=\"n\">Meter</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">Dataset</span>\n",
              "\n",
              "\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">scripts.CONSTANT</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">scripts.eval_utils</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">scripts.func_utils</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">scripts.dataset</span> <span class=\"kn\">import</span> <span class=\"n\">get_loader</span>\n",
              "<span class=\"kn\">from</span> <span class=\"nn\">scripts.model_architecture</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n",
              "\n",
              "<span class=\"n\">clip_grad</span>  <span class=\"o\">=</span> <span class=\"mi\">50</span>\n",
              "<span class=\"n\">model_types</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;MLP&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;AttentiveFP&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GIN&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;RNN&#39;</span><span class=\"p\">,</span> \n",
              "                <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;RNN_pretrain&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;MUE&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;chemBERTa&#39;</span><span class=\"p\">]</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">count_bool</span><span class=\"p\">(</span><span class=\"n\">lst</span><span class=\"p\">):</span> <span class=\"k\">return</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">lst</span><span class=\"p\">)</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">count_parameters</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">Module</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">return</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">count_trainable</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">return</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">()</span> <span class=\"k\">if</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">requires_grad</span><span class=\"p\">)</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">get_optim_params</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">p</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">()</span> <span class=\"k\">if</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">requires_grad</span><span class=\"p\">)</span>\n",
              "    \n",
              "<span class=\"k\">def</span> <span class=\"nf\">initialize_weights</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">if</span> <span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"s1\">&#39;weight&#39;</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">weight</span><span class=\"o\">.</span><span class=\"n\">dim</span><span class=\"p\">()</span> <span class=\"o\">&gt;</span> <span class=\"mi\">1</span><span class=\"p\">:</span>\n",
              "        <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"o\">.</span><span class=\"n\">xavier_uniform_</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">weight</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">)</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">clamp</span><span class=\"p\">(</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">min_value</span><span class=\"o\">=</span><span class=\"mf\">1e-5</span><span class=\"p\">,</span> <span class=\"n\">max_value</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mf\">1e-5</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">return</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">min_value</span><span class=\"p\">,</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">max_value</span><span class=\"p\">))</span>\n",
              "<span class=\"c1\"># uncertainty weight</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">MTLoss</span><span class=\"p\">(</span><span class=\"n\">Module</span><span class=\"p\">):</span> <span class=\"c1\"># calculate multitask loss with trainable parameters</span>\n",
              "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">task_num</span><span class=\"p\">,</span> <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">):</span> \n",
              "        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MTLoss</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task_num</span> <span class=\"o\">=</span> <span class=\"n\">task_num</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">device</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">weight_loss</span><span class=\"o\">==</span><span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">1.0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task_num</span>\n",
              "        <span class=\"c1\"># ùúÇ := ùëôùëúùëîùúé2</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eta</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">weight_loss</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
              "        \n",
              "    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">loss_list</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">assert</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loss_list</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task_num</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">IS_R</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> \n",
              "            <span class=\"k\">assert</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loss_list</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">)):</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">IS_R</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"kc\">True</span><span class=\"p\">:</span> <span class=\"n\">loss_list</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">/=</span> <span class=\"mi\">2</span> \n",
              "        <span class=\"n\">loss_list</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">(</span><span class=\"n\">loss_list</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">total_loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_list</span> <span class=\"o\">*</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eta</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eta</span> <span class=\"o\">*</span> <span class=\"mf\">0.5</span> \n",
              "\n",
              "        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eta</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">())</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">task_num</span><span class=\"p\">)]</span>\n",
              "        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mf\">1.0</span> <span class=\"o\">*</span> <span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">weight_loss</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">IS_R</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">)):</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">IS_R</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"kc\">True</span><span class=\"p\">:</span> <span class=\"n\">weight_loss</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">/=</span> <span class=\"mi\">2</span>\n",
              "\n",
              "        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">/</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">weight_loss</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">weight_loss</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">weight_loss</span><span class=\"p\">)):</span> \n",
              "            <span class=\"k\">if</span> <span class=\"n\">weight_loss</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"mf\">1e-5</span><span class=\"p\">:</span> <span class=\"n\">weight_loss</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">clamp</span><span class=\"p\">(</span><span class=\"n\">weight_loss</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">])</span>\n",
              "        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">/</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">weight_loss</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">weight_loss</span><span class=\"p\">]</span>\n",
              "\n",
              "        \n",
              "        <span class=\"k\">return</span> <span class=\"n\">total_loss</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(),</span> <span class=\"n\">weight_loss</span>\n",
              "\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">init_model</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">):</span>\n",
              "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;need incorporate all models here! &quot;&quot;&quot;</span>\n",
              "    <span class=\"k\">if</span>   <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;MLP&#39;</span><span class=\"p\">:</span>          <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Classifier</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;GIN&#39;</span><span class=\"p\">:</span>          <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">GIN_MOD</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span> \n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;AttentiveFP&#39;</span><span class=\"p\">:</span>  <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">AttentiveFP</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;RNN&#39;</span><span class=\"p\">:</span>          <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">RNN</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span>          <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">RNNVAE</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;RNN_pretrain&#39;</span><span class=\"p\">:</span> <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">RNN_pretrain</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;MUE&#39;</span><span class=\"p\">:</span>          <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Classifier</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;chemBERTa&#39;</span><span class=\"p\">:</span>    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">chemBERTa</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span>                    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;invalid model type:&#39;</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">])</span>\n",
              "    <span class=\"k\">return</span> <span class=\"n\">model</span>\n",
              "\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">get_train_fn</span><span class=\"p\">(</span><span class=\"n\">model_type</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">if</span>   <span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span>       <span class=\"k\">return</span> <span class=\"n\">train_epoch_VAE</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">model_type</span> <span class=\"ow\">in</span> <span class=\"n\">model_types</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"n\">train_epoch_MLP</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;invalid model type:&#39;</span><span class=\"p\">,</span> <span class=\"n\">model_type</span><span class=\"p\">);</span> <span class=\"k\">return</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">get_eval_fn</span><span class=\"p\">(</span><span class=\"n\">model_type</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">if</span>   <span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span>       <span class=\"k\">return</span> <span class=\"n\">train_epoch_VAE</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">model_type</span> <span class=\"ow\">in</span> <span class=\"n\">model_types</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"n\">train_epoch_MLP</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;invalid model type:&#39;</span><span class=\"p\">,</span> <span class=\"n\">model_type</span><span class=\"p\">);</span> <span class=\"k\">return</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">train_epoch_MLP</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span>\n",
              "                    <span class=\"n\">epoch</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">MASK</span><span class=\"o\">=-</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n",
              "                    <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> \n",
              "                    <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;model&#39;</span><span class=\"p\">,</span> <span class=\"n\">ver</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
              "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
              "<span class=\"sd\">    param weight_loss: list, the weight of loss for different tasks</span>\n",
              "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
              "    \n",
              "    <span class=\"k\">if</span> <span class=\"n\">optimizer</span><span class=\"o\">==</span><span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"c1\"># no optimizer, either validation or test</span>\n",
              "        <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>    <span class=\"c1\"># model evaluation for either valid or test</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">train_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;Valid&#39;</span> <span class=\"c1\"># if epoch is inputted, its valid</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">train_type</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Test&#39;</span> <span class=\"c1\"># if no epoch information, its test</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">();</span> <span class=\"n\">train_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;Train&#39;</span> <span class=\"c1\"># if optimizer inputted, its train</span>\n",
              "    \n",
              "\n",
              "    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">):</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"n\">IS_R</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">IS_R</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">if</span> <span class=\"n\">weight_loss</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">1.0</span><span class=\"o\">/</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)]</span><span class=\"o\">*</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"p\">[],</span> <span class=\"p\">{},</span> <span class=\"p\">{}</span>\n",
              "    <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">batch_data</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">):</span>\n",
              "<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
              "<span class=\"sd\">        len(batch_data) could determine which algorithm</span>\n",
              "<span class=\"sd\">        len(batch_data) == 2: MLP, GIN, RNN, ENSEMBLE</span>\n",
              "<span class=\"sd\">        len(batch_data) == 4: AttentiveFP</span>\n",
              "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">2</span><span class=\"p\">:</span>  <span class=\"c1\"># MLP or GIN or RNN or chemBERTa</span>\n",
              "            <span class=\"n\">fp</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">batch_data</span> \n",
              "            <span class=\"c1\"># fp, labels = fp.to(device), labels.to(device)</span>\n",
              "            <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            \n",
              "            <span class=\"k\">try</span><span class=\"p\">:</span> <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span> <span class=\"c1\"># MLP, GIN, RNN</span>\n",
              "            <span class=\"k\">except</span><span class=\"p\">:</span> <span class=\"c1\"># chemberta</span>\n",
              "                <span class=\"k\">del</span> <span class=\"n\">batch_data</span>\n",
              "                <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">)</span>   <span class=\"c1\"># actually SMILES, convert tuple to list</span>\n",
              "                <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span> \n",
              "                    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">),</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">))</span>\n",
              "            \n",
              "            <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">labels</span> <span class=\"o\">==</span> <span class=\"n\">MASK</span>\n",
              "            <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">del</span> <span class=\"n\">fp</span>\n",
              "            \n",
              "        <span class=\"k\">elif</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">4</span><span class=\"p\">:</span> <span class=\"c1\"># attentiveFP</span>\n",
              "            <span class=\"n\">smiles</span><span class=\"p\">,</span> <span class=\"n\">bg</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">masks</span> <span class=\"o\">=</span> <span class=\"n\">batch_data</span>\n",
              "            <span class=\"n\">bg</span><span class=\"p\">,</span><span class=\"n\">labels</span><span class=\"p\">,</span><span class=\"n\">masks</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">masks</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">n_feats</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">ndata</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;hv&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">e_feats</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">edata</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;he&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">bg</span><span class=\"p\">,</span> <span class=\"n\">n_feats</span><span class=\"p\">,</span> <span class=\"n\">e_feats</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">masks</span> <span class=\"o\">&lt;</span> <span class=\"mi\">1</span>\n",
              "        \n",
              "        <span class=\"n\">batch_loss_list</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R_list</span><span class=\"p\">,</span> <span class=\"n\">weight_loss</span><span class=\"p\">)):</span>\n",
              "            <span class=\"n\">loss_func</span> <span class=\"o\">=</span> <span class=\"n\">get_loss_fn</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "            <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "             \n",
              "            \n",
              "            <span class=\"n\">len_here</span> <span class=\"o\">=</span> <span class=\"n\">label</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"c1\"># num of data with labels</span>\n",
              "            <span class=\"n\">loss_here</span> <span class=\"o\">=</span> <span class=\"n\">loss_func</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span> \n",
              "            <span class=\"k\">if</span> <span class=\"n\">len_here</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "                <span class=\"n\">loss_here</span> <span class=\"o\">/=</span> <span class=\"n\">len_here</span>\n",
              "                <span class=\"n\">batch_loss_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss_here</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">())</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span>       <span class=\"n\">batch_loss_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "            \n",
              "            <span class=\"k\">if</span> <span class=\"n\">j</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">loss</span>  <span class=\"o\">=</span> <span class=\"n\">loss_here</span> <span class=\"o\">*</span> <span class=\"n\">w</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span>      <span class=\"n\">loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss_here</span> <span class=\"o\">*</span> <span class=\"n\">w</span>\n",
              "\n",
              "            <span class=\"k\">if</span> <span class=\"n\">IS_R</span> <span class=\"o\">==</span> <span class=\"kc\">False</span><span class=\"p\">:</span> <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">train_type</span> <span class=\"o\">!=</span> <span class=\"s1\">&#39;Train&#39;</span><span class=\"p\">:</span> <span class=\"c1\"># valid or test, output probs and labels</span>\n",
              "                                      <span class=\"c1\"># if train, no process prob to save time</span>\n",
              "                <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "                <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">label</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">scale_dict</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
              "                    <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">scale_dict</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n",
              "                        <span class=\"n\">min_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "                        <span class=\"n\">max_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
              "                        <span class=\"n\">del_here</span> <span class=\"o\">=</span> <span class=\"n\">max_here</span> <span class=\"o\">-</span> <span class=\"n\">min_here</span>\n",
              "                        <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">l</span> <span class=\"o\">*</span> <span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"n\">label</span><span class=\"p\">]</span>\n",
              "                        <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">p</span> <span class=\"o\">*</span> <span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">probs</span><span class=\"p\">]</span>\n",
              "                    \n",
              "                <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">],</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
              "                <span class=\"k\">else</span><span class=\"p\">:</span>     <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">probs</span><span class=\"p\">;</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">label</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">losses_list</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>               <span class=\"n\">losses_list</span> <span class=\"o\">=</span> <span class=\"n\">batch_loss_list</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">losses_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"n\">j</span> <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">batch_loss_list</span><span class=\"p\">)]</span>\n",
              "\n",
              "        <span class=\"n\">total_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n",
              "\n",
              "        <span class=\"k\">if</span> <span class=\"n\">optimizer</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
              "            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">();</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">();</span> <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n",
              "\n",
              "    <span class=\"n\">total_loss</span> <span class=\"o\">/=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">)</span> <span class=\"c1\"># no need /loader.dataset since has / len_here </span>\n",
              "    \n",
              "    <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"c1\"># train or valid</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">ver</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Epoch:</span><span class=\"si\">{</span><span class=\"n\">epoch</span><span class=\"si\">}</span><span class=\"s1\">, [</span><span class=\"si\">{</span><span class=\"n\">train_type</span><span class=\"si\">}</span><span class=\"s1\">] Loss: </span><span class=\"si\">{</span><span class=\"n\">total_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">elif</span> <span class=\"n\">epoch</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"c1\"># test</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;[</span><span class=\"si\">{</span><span class=\"n\">train_type</span><span class=\"si\">}</span><span class=\"s1\">] Loss: </span><span class=\"si\">{</span><span class=\"n\">total_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">performance</span> <span class=\"o\">=</span> <span class=\"n\">eval_dict</span><span class=\"p\">(</span><span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R_list</span><span class=\"p\">,</span> \n",
              "                                <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"n\">model_type</span><span class=\"p\">,</span> <span class=\"n\">draw_fig</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">performance</span><span class=\"p\">[</span><span class=\"s1\">&#39;loss&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">total_loss</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"n\">IS_R</span> <span class=\"o\">=</span> <span class=\"n\">IS_R_list</span>\n",
              "    <span class=\"k\">if</span>   <span class=\"n\">train_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;Train&#39;</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span> <span class=\"c1\"># train</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">train_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;Valid&#39;</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"n\">total_loss</span><span class=\"p\">,</span>  <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span> <span class=\"c1\"># valid</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span>                       <span class=\"k\">return</span> <span class=\"n\">performance</span><span class=\"p\">,</span> <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span> <span class=\"c1\"># test</span>\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">train_epoch_VAE</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> \n",
              "                    <span class=\"n\">kl_weight</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">cls_weight</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n",
              "                    <span class=\"n\">epoch</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> \n",
              "                    <span class=\"n\">MASK</span><span class=\"o\">=-</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> \n",
              "                    <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;model&#39;</span><span class=\"p\">):</span>\n",
              "\n",
              "    <span class=\"k\">if</span> <span class=\"n\">optimizer</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> \n",
              "        <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>          <span class=\"c1\"># Valid or Test</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">train_type</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Valid&#39;</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>             <span class=\"n\">train_type</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Test&#39;</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span>  <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">();</span> <span class=\"n\">train_type</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Train&#39;</span>\n",
              "\n",
              "    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">):</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"n\">IS_R</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">IS_R</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">if</span> <span class=\"n\">weight_loss</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">1.0</span><span class=\"o\">/</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)]</span><span class=\"o\">*</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span>\n",
              "    <span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"p\">[],</span> <span class=\"p\">{},</span> <span class=\"p\">{}</span>\n",
              "    <span class=\"n\">klds</span><span class=\"p\">,</span> <span class=\"n\">recs</span><span class=\"p\">,</span> <span class=\"n\">clss</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span>\n",
              "    <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">batch_data</span> <span class=\"ow\">in</span> <span class=\"n\">tqdm</span><span class=\"p\">(</span><span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">),</span> \n",
              "                            <span class=\"n\">total</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">),</span> <span class=\"n\">desc</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"n\">train_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">2</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">batch_data</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">batch_data</span><span class=\"p\">,</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"n\">kld</span><span class=\"p\">,</span> <span class=\"n\">rec</span><span class=\"p\">,</span> <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">pred</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"bp\">cls</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"c1\"># label is not none, and has pred, calculate: </span>\n",
              "            <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">labels</span> <span class=\"o\">==</span> <span class=\"n\">MASK</span>\n",
              "            <span class=\"n\">batch_loss_list</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span>\n",
              "                <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R_list</span><span class=\"p\">,</span> <span class=\"n\">weight_loss</span><span class=\"p\">)):</span>\n",
              "                <span class=\"n\">loss_func</span> <span class=\"o\">=</span> <span class=\"n\">get_loss_fn</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "                <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "                <span class=\"n\">len_here</span> <span class=\"o\">=</span> <span class=\"n\">label</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "                <span class=\"n\">loss_here</span> <span class=\"o\">=</span> <span class=\"n\">loss_func</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">len_here</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span> \n",
              "                    <span class=\"n\">loss_here</span> <span class=\"o\">/=</span> <span class=\"n\">len_here</span>\n",
              "                    <span class=\"n\">batch_loss_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss_here</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">())</span>\n",
              "                <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">batch_loss_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "\n",
              "                <span class=\"k\">if</span> <span class=\"n\">j</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"bp\">cls</span>  <span class=\"o\">=</span> <span class=\"n\">loss_here</span> <span class=\"o\">*</span> <span class=\"n\">w</span>\n",
              "                <span class=\"k\">else</span><span class=\"p\">:</span>      <span class=\"bp\">cls</span> <span class=\"o\">+=</span> <span class=\"n\">loss_here</span> <span class=\"o\">*</span> <span class=\"n\">w</span>\n",
              "\n",
              "                <span class=\"k\">if</span> <span class=\"n\">IS_R</span> <span class=\"o\">==</span> <span class=\"kc\">False</span><span class=\"p\">:</span> <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">)</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">train_type</span> <span class=\"o\">!=</span> <span class=\"s1\">&#39;Train&#39;</span><span class=\"p\">:</span> \n",
              "                    <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "                    <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">label</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "                    <span class=\"k\">if</span> <span class=\"n\">scale_dict</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> \n",
              "                        <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">scale_dict</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n",
              "                            <span class=\"n\">min_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "                            <span class=\"n\">max_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
              "                            <span class=\"n\">del_here</span> <span class=\"o\">=</span> <span class=\"n\">max_here</span> <span class=\"o\">-</span> <span class=\"n\">min_here</span>\n",
              "                            <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">l</span> <span class=\"o\">*</span> <span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"n\">label</span><span class=\"p\">]</span>\n",
              "                            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">p</span> <span class=\"o\">*</span> <span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">probs</span><span class=\"p\">]</span>\n",
              "                    <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">],</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
              "                    <span class=\"k\">else</span><span class=\"p\">:</span>     <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">probs</span><span class=\"p\">;</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">label</span> \n",
              "            <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">losses_list</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">losses_list</span> <span class=\"o\">=</span> <span class=\"n\">batch_loss_list</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">losses_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"n\">j</span> <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span>\n",
              "                                    <span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">batch_loss_list</span><span class=\"p\">)]</span>\n",
              "            \n",
              "        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">kl_weight</span> <span class=\"o\">*</span> <span class=\"n\">kld</span> <span class=\"o\">+</span> <span class=\"n\">rec</span> <span class=\"o\">+</span> <span class=\"n\">cls_weight</span> <span class=\"o\">*</span> <span class=\"bp\">cls</span>\n",
              "        <span class=\"n\">total_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n",
              "        <span class=\"n\">klds</span> <span class=\"o\">+=</span> <span class=\"n\">kld</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">();</span> <span class=\"n\">recs</span> <span class=\"o\">+=</span> <span class=\"n\">rec</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">();</span> <span class=\"n\">clss</span> <span class=\"o\">+=</span> <span class=\"bp\">cls</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n",
              "\n",
              "        <span class=\"k\">if</span> <span class=\"n\">optimizer</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">();</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n",
              "            <span class=\"n\">clip_grad_norm_</span><span class=\"p\">(</span><span class=\"n\">get_optim_params</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">),</span> <span class=\"n\">clip_grad</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n",
              "        <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">param_groups</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"s1\">&#39;lr&#39;</span><span class=\"p\">]</span> <span class=\"k\">if</span> <span class=\"n\">optimizer</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span> <span class=\"k\">else</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"n\">IS_R</span> <span class=\"o\">=</span> <span class=\"n\">IS_R_list</span>\n",
              "    <span class=\"n\">total_loss</span> <span class=\"o\">/=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">)</span>\n",
              "    <span class=\"n\">klds</span> <span class=\"o\">/=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">);</span> <span class=\"n\">recs</span> <span class=\"o\">/=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">);</span> <span class=\"n\">clss</span> <span class=\"o\">/=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">)</span>\n",
              "    <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> \n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Epoch:</span><span class=\"si\">{</span><span class=\"n\">epoch</span><span class=\"si\">}</span><span class=\"s1\"> [</span><span class=\"si\">{</span><span class=\"n\">train_type</span><span class=\"si\">}</span><span class=\"s1\">] Loss: </span><span class=\"si\">{</span><span class=\"n\">total_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> |&#39;</span><span class=\"p\">,</span>\n",
              "              <span class=\"sa\">f</span><span class=\"s1\">&#39;KL Div: </span><span class=\"si\">{</span><span class=\"n\">klds</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> | Recon: </span><span class=\"si\">{</span><span class=\"n\">recs</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> | Classify: </span><span class=\"si\">{</span><span class=\"n\">clss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">,</span>\n",
              "              <span class=\"sa\">f</span><span class=\"s1\">&#39;| KL w: </span><span class=\"si\">{</span><span class=\"n\">kl_weight</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> | cls w: </span><span class=\"si\">{</span><span class=\"n\">cls_weight</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span> \n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;[</span><span class=\"si\">{</span><span class=\"n\">train_type</span><span class=\"si\">}</span><span class=\"s1\">] Loss: </span><span class=\"si\">{</span><span class=\"n\">total_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> | Classify: </span><span class=\"si\">{</span><span class=\"n\">clss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">perf</span> <span class=\"o\">=</span> <span class=\"n\">eval_dict</span><span class=\"p\">(</span><span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> \n",
              "                         <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"n\">model_type</span><span class=\"p\">,</span> <span class=\"n\">draw_fig</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">perf</span><span class=\"p\">[</span><span class=\"s1\">&#39;loss&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">clss</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">if</span>   <span class=\"n\">train_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;Train&#39;</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"n\">clss</span><span class=\"p\">],</span> <span class=\"n\">losses_list</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">train_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;Valid&#39;</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"n\">clss</span><span class=\"p\">],</span> <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span>\n",
              "    <span class=\"k\">elif</span> <span class=\"n\">train_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;Test&#39;</span><span class=\"p\">:</span>  <span class=\"k\">return</span> <span class=\"n\">perf</span><span class=\"p\">,</span>       <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span>\n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">eval_VAE</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">MASK</span><span class=\"o\">=</span><span class=\"n\">MASK</span><span class=\"p\">):</span>\n",
              "    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n",
              "    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">):</span> <span class=\"n\">names</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">names</span><span class=\"p\">]</span>\n",
              "    <span class=\"n\">IS_R</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">names_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">names</span><span class=\"p\">]</span>\n",
              "    <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span><span class=\"p\">,</span> <span class=\"n\">mu_dict</span> <span class=\"o\">=</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">{}</span>\n",
              "    <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">input_</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">):</span>\n",
              "        <span class=\"n\">input_</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">input_</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">(</span><span class=\"n\">input_</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">preds</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">classifier</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">labels</span> <span class=\"o\">==</span> <span class=\"n\">MASK</span>\n",
              "        <span class=\"k\">del</span> <span class=\"n\">input_</span>\n",
              "\n",
              "        <span class=\"k\">for</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">is_r</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">)):</span>\n",
              "            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">preds</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "            <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"o\">~</span><span class=\"n\">mask</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">]]</span>\n",
              "            <span class=\"n\">mask_here</span> <span class=\"o\">=</span> <span class=\"n\">mask</span><span class=\"p\">[:,</span><span class=\"n\">j</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">expand_as</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">mu_</span> <span class=\"o\">=</span> <span class=\"n\">mu</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"o\">~</span><span class=\"n\">mask_here</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">del</span> <span class=\"n\">mask_here</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">is_r</span> <span class=\"o\">==</span> <span class=\"kc\">False</span><span class=\"p\">:</span> <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "            <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">label</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "            <span class=\"n\">mu_</span>   <span class=\"o\">=</span> <span class=\"n\">mu_</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span>\n",
              "\n",
              "            <span class=\"k\">if</span> <span class=\"n\">scale_dict</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
              "                <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">scale_dict</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n",
              "                    <span class=\"n\">min_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "                    <span class=\"n\">max_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
              "                    <span class=\"n\">del_here</span> <span class=\"o\">=</span> <span class=\"n\">max_here</span> <span class=\"o\">-</span> <span class=\"n\">min_here</span>\n",
              "                    <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">l</span><span class=\"o\">*</span><span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"n\">label</span><span class=\"p\">]</span>\n",
              "                    <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">p</span><span class=\"o\">*</span><span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">probs</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "                <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">],</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">],</span> <span class=\"n\">mu_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">,</span> <span class=\"n\">mu_</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span>\n",
              "                <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">probs</span><span class=\"p\">;</span> <span class=\"n\">y_label</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">label</span>\n",
              "                <span class=\"n\">mu_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">mu_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">],</span> <span class=\"n\">mu_</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">return</span> <span class=\"n\">mu_dict</span><span class=\"p\">,</span> <span class=\"n\">y_probs</span><span class=\"p\">,</span> <span class=\"n\">y_label</span> \n",
              "\n",
              "<span class=\"k\">def</span> <span class=\"nf\">model_predict</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">model_type</span><span class=\"p\">,</span> \n",
              "        <span class=\"n\">MASK</span><span class=\"o\">=-</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">scale_back</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n",
              "    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">):</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"n\">IS_R</span>\n",
              "    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">IS_R_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">IS_R</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">)</span>\n",
              "    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n",
              "    <span class=\"n\">y_probs</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n",
              "    <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">batch_data</span> <span class=\"ow\">in</span> <span class=\"n\">tqdm</span><span class=\"p\">(</span><span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">),</span> <span class=\"n\">total</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">),</span> \n",
              "                                <span class=\"n\">desc</span><span class=\"o\">=</span><span class=\"s1\">&#39;Predicting...&#39;</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;dataloader error&#39;</span><span class=\"p\">);</span> <span class=\"k\">return</span>\n",
              "        <span class=\"k\">elif</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">2</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">fp</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">batch_data</span><span class=\"p\">;</span>    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">);</span>     <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">elif</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch_data</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">4</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">_</span><span class=\"p\">,</span><span class=\"n\">bg</span><span class=\"p\">,</span><span class=\"n\">_</span><span class=\"p\">,</span><span class=\"n\">_</span><span class=\"o\">=</span><span class=\"n\">batch_data</span><span class=\"p\">;</span> <span class=\"n\">bg</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"c1\"># bg, labels = bg.to(device), labels.to(device)</span>\n",
              "            <span class=\"n\">n_feats</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">ndata</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;hv&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">e_feats</span> <span class=\"o\">=</span> <span class=\"n\">bg</span><span class=\"o\">.</span><span class=\"n\">edata</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;he&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">bg</span><span class=\"p\">,</span> <span class=\"n\">n_feats</span><span class=\"p\">,</span> <span class=\"n\">e_feats</span><span class=\"p\">)</span>\n",
              "        <span class=\"c1\"># print(pred.shape)</span>\n",
              "        <span class=\"c1\"># print(fp.shape)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">IS_R</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">IS_R_list</span><span class=\"p\">)):</span>\n",
              "            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[:,</span> <span class=\"n\">j</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">IS_R</span> <span class=\"o\">==</span> <span class=\"kc\">False</span><span class=\"p\">:</span> <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"n\">probs</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">scale_dict</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span> <span class=\"ow\">and</span> <span class=\"n\">scale_back</span> <span class=\"o\">==</span> <span class=\"kc\">True</span><span class=\"p\">:</span> \n",
              "                <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">scale_dict</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n",
              "                    <span class=\"n\">min_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "                    <span class=\"n\">max_here</span> <span class=\"o\">=</span> <span class=\"n\">scale_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
              "                    <span class=\"n\">del_here</span> <span class=\"o\">=</span> <span class=\"n\">max_here</span> <span class=\"o\">-</span> <span class=\"n\">min_here</span>\n",
              "                    <span class=\"n\">probs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">p</span> <span class=\"o\">*</span> <span class=\"n\">del_here</span> <span class=\"o\">+</span> <span class=\"n\">min_here</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">probs</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span>  <span class=\"o\">=</span> <span class=\"n\">probs</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span>        <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">probs</span>\n",
              "    <span class=\"k\">return</span> <span class=\"n\">y_probs</span>\n",
              "\n",
              "\n",
              "<span class=\"k\">class</span> <span class=\"nc\">PRED</span><span class=\"p\">:</span>\n",
              "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;device&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;device&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">cuda</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">cuda</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cuda&#39;</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span>    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span>\n",
              "        \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">;</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;prop_names&#39;</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;scale_dict&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>           <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;scale_dict&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;weight_loss&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>          <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;weight_loss&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_type&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">init_model</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">config</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">params_num</span> <span class=\"o\">=</span> <span class=\"n\">count_parameters</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">)</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Model type: &#39;</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39; | Model parameters: &#39;</span><span class=\"p\">,</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">params_num</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab</span> <span class=\"o\">=</span> <span class=\"kc\">None</span> <span class=\"k\">if</span> <span class=\"s1\">&#39;vocab&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span> <span class=\"k\">else</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;vocab&#39;</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;vocab_type&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab_type</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>           <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab_type</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;vocab_type&#39;</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"c1\"># initialize model paths and config path</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_path&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;encoder_path&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder_path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>          <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;encoder_path&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;decoder_path&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder_path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>          <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;decoder_path&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;classifier_path&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier_path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>          <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;classifier_path&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;config_path&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">c_p</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"s1\">&#39;.yml&#39;</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config_path</span> <span class=\"o\">=</span> <span class=\"n\">c_p</span><span class=\"p\">;</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;config_path&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">c_p</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;config_path&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;figure_path&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span>\n",
              "            <span class=\"n\">figure_path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">figure_path</span> <span class=\"o\">=</span> <span class=\"n\">figure_path</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;figure_path&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">figure_path</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">figure_path</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;figure_path&#39;</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eval_fn</span> <span class=\"o\">=</span> <span class=\"n\">get_eval_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_fn</span> <span class=\"o\">=</span> <span class=\"n\">get_train_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;IS_R&#39;</span><span class=\"p\">]</span> <span class=\"c1\"># could be list, could be true/false</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">AdamW</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span>\n",
              "                        <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;lr&#39;</span><span class=\"p\">],</span> <span class=\"n\">weight_decay</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;wd&#39;</span><span class=\"p\">])</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stopper</span> <span class=\"o\">=</span> <span class=\"n\">EarlyStopping</span><span class=\"p\">(</span><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;lower&#39;</span><span class=\"p\">,</span> <span class=\"n\">patience</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;patience&#39;</span><span class=\"p\">])</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;verbose_freq&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;verbose_freq&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;verbose_freq&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;uncertainty_weight&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">config</span><span class=\"p\">:</span> \n",
              "            <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># single task</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span> <span class=\"o\">=</span> <span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;uncertainty_weight&#39;</span><span class=\"p\">]</span>    \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">inf</span><span class=\"p\">,</span> <span class=\"mi\">0</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;MAX_EPOCH&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">MAX_EPOCH</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span>          <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">MAX_EPOCH</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;MAX_EPOCH&#39;</span><span class=\"p\">]</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;max_kl_weight&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">max_kl_weight</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">max_kl_weight</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;max_kl_weight&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">if</span> <span class=\"s1\">&#39;cls_weight&#39;</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cls_weight</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cls_weight</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;cls_weight&#39;</span><span class=\"p\">]</span> \n",
              "\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span> <span class=\"o\">=</span> <span class=\"p\">{},</span> <span class=\"p\">{},</span> <span class=\"p\">[]</span>\n",
              "        \n",
              "        <span class=\"c1\"># will store the results on test set, if test set == None, leave blank</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span> \n",
              "\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">config</span>     <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">,</span>\n",
              "                         <span class=\"n\">min_loss</span>   <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"p\">,</span>\n",
              "                         <span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"p\">,</span> \n",
              "                         <span class=\"n\">train_dict</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> \n",
              "                         <span class=\"n\">valid_dict</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span>\n",
              "                         <span class=\"n\">times_list</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">,</span>\n",
              "                         <span class=\"n\">params_num</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">params_num</span><span class=\"p\">,</span> \n",
              "                         <span class=\"n\">performance</span><span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">def</span> <span class=\"nf\">save_train_status</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span> \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n",
              "            <span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">,</span>\n",
              "            <span class=\"n\">min_loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"p\">,</span>\n",
              "            <span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"p\">,</span> \n",
              "            <span class=\"n\">train_dict</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> \n",
              "            <span class=\"n\">valid_dict</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span>\n",
              "            <span class=\"n\">times_list</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">,</span>\n",
              "            <span class=\"n\">params_num</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">params_num</span><span class=\"p\">,</span> \n",
              "            <span class=\"n\">performance</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span><span class=\"p\">)</span>\n",
              "\n",
              "        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config_path</span><span class=\"p\">,</span> <span class=\"s1\">&#39;w&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">fl</span><span class=\"p\">:</span>\n",
              "            <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">fl</span><span class=\"p\">,</span> <span class=\"n\">default_flow_style</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;</span><span class=\"se\">\\n</span><span class=\"s1\">--&gt; Train status saved at&#39;</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config_path</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_encoder</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">encoder_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span><span class=\"c1\"># this is VAE or RNN_pretrain</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">encoder_path</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">encoder_path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder_path</span> \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span>\n",
              "               <span class=\"n\">encoder_path</span><span class=\"p\">,</span> <span class=\"n\">map_location</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finish load encoder from&#39;</span><span class=\"p\">,</span> <span class=\"n\">encoder_path</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_decoder</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">decoder_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">decoder_path</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">decoder_path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder_path</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span>\n",
              "               <span class=\"n\">decoder_path</span><span class=\"p\">,</span> <span class=\"n\">map_location</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finish load decoder from&#39;</span><span class=\"p\">,</span> <span class=\"n\">decoder_path</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_classifier</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">classifier_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">classifier_path</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">classifier_path</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier_path</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">classifier_path</span><span class=\"p\">,</span> \n",
              "                                               <span class=\"n\">map_location</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span> \n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finish load classifier from&#39;</span><span class=\"p\">,</span> <span class=\"n\">classifier_path</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_vae_pretrain</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">encoder_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">classifier_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_encoder</span><span class=\"p\">(</span><span class=\"n\">encoder_path</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_classifier</span><span class=\"p\">(</span><span class=\"n\">classifier_path</span><span class=\"p\">)</span>\n",
              "    \n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_vae</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">encoder_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">decoder_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_encoder</span><span class=\"p\">(</span><span class=\"n\">encoder_path</span><span class=\"p\">);</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_decoder</span><span class=\"p\">(</span><span class=\"n\">decoder_path</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_model</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;AttentiveFP&#39;</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">con</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">();</span> <span class=\"n\">con</span><span class=\"p\">[</span><span class=\"s1\">&#39;dropout&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">init_model</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">con</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">path</span> <span class=\"o\">==</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;load pretrained model from &#39;</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"p\">)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">map_location</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
              "    \n",
              "    <span class=\"k\">def</span> <span class=\"nf\">load_status</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">):</span>\n",
              "        <span class=\"c1\"># with open(yml_file_path, &#39;r&#39;) as f:</span>\n",
              "        <span class=\"c1\">#     data = yaml.safe_load(f)</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;config&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">&#39;model_path&#39;</span><span class=\"p\">]</span> \n",
              "        <span class=\"c1\"># self.load_model(self.config[&#39;model_path&#39;])</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;min_loss&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;best_epoch&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;train_dict&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;valid_dict&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;times_list&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">params_num</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;params_num&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">&#39;performance&#39;</span><span class=\"p\">]</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;finish load data status </span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">get_runtime</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">verbose</span><span class=\"p\">:</span>\n",
              "            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Train time: </span><span class=\"si\">{</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">)</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span>\n",
              "                  <span class=\"sa\">f</span><span class=\"s1\">&#39;+/-</span><span class=\"si\">{</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">)</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> ms&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">print_config</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span> \n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;#&#39;</span><span class=\"o\">*</span><span class=\"mi\">68</span><span class=\"p\">);</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;#&#39;</span><span class=\"o\">*</span><span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CONFIG&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;#&#39;</span><span class=\"o\">*</span><span class=\"mi\">30</span><span class=\"p\">);</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;#&#39;</span><span class=\"o\">*</span><span class=\"mi\">68</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>             <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"s1\">&#39;:&#39;</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">)</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;#&#39;</span><span class=\"o\">*</span><span class=\"mi\">68</span><span class=\"p\">)</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">eval</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">ver</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">ver</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">print_config</span><span class=\"p\">()</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"n\">path</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_vae_pretrain</span><span class=\"p\">()</span>\n",
              "        <span class=\"k\">if</span> <span class=\"n\">ver</span><span class=\"p\">:</span>\n",
              "            <span class=\"c1\"># if self.weight_loss != None: print(&#39;task weight: &#39;,self.weight_loss)</span>\n",
              "            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Model parameters: &#39;</span><span class=\"p\">,</span> <span class=\"n\">count_parameters</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">))</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_runtime</span><span class=\"p\">()</span>\n",
              "            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;epoch </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"si\">}</span><span class=\"s2\"> -&gt; min loss </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                      <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"n\">performance</span><span class=\"p\">,</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eval_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> \n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> \n",
              "            <span class=\"n\">MASK</span><span class=\"o\">=-</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span> <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n",
              "            <span class=\"c1\"># weight_loss=self.weight_loss, # should not use the weightloss</span>\n",
              "            <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">return</span> <span class=\"n\">performance</span><span class=\"p\">,</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span>\n",
              "\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">train_VAE</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> \n",
              "                 <span class=\"n\">data_df</span><span class=\"o\">=</span><span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(),</span> <span class=\"n\">sample_num</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">latent_eval_freq</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n",
              "<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
              "<span class=\"sd\">        Aim: Train Variational AutoEncoder (VAE), evaluate latent space </span>\n",
              "<span class=\"sd\">        params: </span>\n",
              "<span class=\"sd\">            loader:       DataLoader, for train</span>\n",
              "<span class=\"sd\">            val_loader:   DataLoader, for valid, save model based on its loss</span>\n",
              "<span class=\"sd\">            test_loader:  DataLoader, for test,  final performance evaluation</span>\n",
              "<span class=\"sd\">            data_df: pd.DataFrame, if no empty, will plot PCA on latent sapce</span>\n",
              "<span class=\"sd\">            sample_num:       int, the number of entries sampled from data_df</span>\n",
              "<span class=\"sd\">            latent_eval_freq: int, the frequency of plot PCA and save figures</span>\n",
              "<span class=\"sd\">        Return performance: dict, performance on test loader</span>\n",
              "<span class=\"sd\">                            performance[name]: metrics nums evaluated on name</span>\n",
              "<span class=\"sd\">                            performance[loss]: total loss of VAE for test set </span>\n",
              "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> \n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">m_w</span> <span class=\"o\">=</span> <span class=\"n\">MTLoss</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span> \n",
              "            <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">m_w</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">);</span> <span class=\"n\">m_w</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n",
              "\n",
              "        <span class=\"c1\"># self.optimizer = torch.optim.AdamW(</span>\n",
              "        <span class=\"c1\">#     get_optim_params(self.model), lr=lr_start)</span>\n",
              "        <span class=\"c1\"># lr_annealer = CosineAnnealingLRWithRestart(self.optimizer)</span>\n",
              "        \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">();</span> <span class=\"n\">start_epoch</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span>\n",
              "        <span class=\"n\">min_total_loss</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">inf</span><span class=\"p\">;</span> <span class=\"n\">train_total</span><span class=\"p\">,</span> <span class=\"n\">valid_total</span> <span class=\"o\">=</span> <span class=\"p\">{},</span> <span class=\"p\">{}</span> \n",
              "        <span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">start_epoch</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">MAX_EPOCH</span><span class=\"p\">):</span>\n",
              "            \n",
              "            <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">%</span> <span class=\"n\">latent_eval_freq</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "                <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">data_df</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"c1\"># plot PCA before training one epoch </span>\n",
              "                    <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"n\">plot_show</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n",
              "                    <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">plot_show</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n",
              "                    <span class=\"n\">tmp_</span> <span class=\"o\">=</span> <span class=\"n\">data_df</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">=</span><span class=\"n\">sample_num</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">(</span><span class=\"n\">drop</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">tmp_</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">cal_mu</span><span class=\"p\">(</span><span class=\"n\">tmp_</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">header_here</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">header</span>\n",
              "                    <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">:</span> \n",
              "                        <span class=\"c1\"># there might be MASK values in tmp, delete entire row</span>\n",
              "                        <span class=\"n\">tmp</span> <span class=\"o\">=</span> <span class=\"n\">tmp_</span><span class=\"p\">[</span><span class=\"n\">tmp_</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span><span class=\"o\">!=</span> <span class=\"n\">MASK</span><span class=\"p\">]</span>\n",
              "                        <span class=\"n\">plot_dim_reduced</span><span class=\"p\">(</span><span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">header_here</span><span class=\"p\">],</span><span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">],</span><span class=\"n\">names_dict</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">],</span>\n",
              "                        <span class=\"n\">dim_reduct</span><span class=\"o\">=</span><span class=\"s1\">&#39;PCA&#39;</span><span class=\"p\">,</span><span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;PCA on </span><span class=\"si\">{</span><span class=\"n\">n</span><span class=\"si\">}</span><span class=\"s1\"> in latent space&#39;</span><span class=\"p\">,</span>\n",
              "                        <span class=\"n\">savepath</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">figure_path</span><span class=\"p\">,</span> \n",
              "                        <span class=\"n\">savename</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">&#39;PCA_</span><span class=\"si\">{</span><span class=\"n\">n</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">epoch</span><span class=\"si\">}</span><span class=\"s1\">.png&#39;</span><span class=\"p\">,</span> <span class=\"n\">plot_show</span><span class=\"o\">=</span><span class=\"n\">plot_show</span><span class=\"p\">)</span>\n",
              "\n",
              "            <span class=\"n\">inc</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">epoch</span> <span class=\"o\">-</span> <span class=\"n\">start_epoch</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">MAX_EPOCH</span> <span class=\"o\">-</span> <span class=\"n\">start_epoch</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">kl_weight</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">max_kl_weight</span> <span class=\"o\">*</span> <span class=\"n\">inc</span>\n",
              "            <span class=\"c1\"># cls_weight = self.cls_weight</span>\n",
              "            <span class=\"n\">cls_weight</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cls_weight</span> <span class=\"o\">*</span> <span class=\"n\">inc</span>\n",
              "            <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n",
              "            <span class=\"n\">score</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span>\n",
              "                                        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">kl_weight</span><span class=\"p\">,</span> \n",
              "                                        <span class=\"n\">cls_weight</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> \n",
              "                                        <span class=\"n\">scale_dict</span>  <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span>\n",
              "                                        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">,</span>\n",
              "                                        <span class=\"n\">model_type</span>  <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">train_time</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">t</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mi\">1000</span> <span class=\"o\">/</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n",
              "            \n",
              "            <span class=\"n\">val_s</span><span class=\"p\">,</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_fn</span><span class=\"p\">(</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> \n",
              "                <span class=\"n\">kl_weight</span><span class=\"p\">,</span> <span class=\"n\">cls_weight</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span>\n",
              "                <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">,</span> <span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">)</span>\n",
              "            \n",
              "            \n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">train_time</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span>\n",
              "                <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n",
              "                <span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"n\">m_w</span><span class=\"p\">(</span><span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">total_loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">();</span> <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n",
              "            \n",
              "\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">score</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">];</span> <span class=\"n\">train_total</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">score</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">];</span> <span class=\"n\">valid_total</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"n\">min_total_loss</span><span class=\"p\">:</span>\n",
              "                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;# SAVE MODEL: loss: </span><span class=\"si\">{</span><span class=\"n\">min_total_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> -&gt;&#39;</span><span class=\"p\">,</span>\n",
              "                      <span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s2\">&quot; | &quot;</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">min_total_loss</span> <span class=\"o\">=</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"n\">epoch</span>\n",
              "                <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "\n",
              "            <span class=\"k\">if</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"p\">:</span> \n",
              "                <span class=\"c1\"># use cls loss as save indicator of enc, dec cls model</span>\n",
              "                <span class=\"c1\"># seperate save to simplify later load pretrain models</span>\n",
              "                <span class=\"c1\"># load model for MLP, just need to load encoder for FP</span>\n",
              "                <span class=\"c1\"># load model for RNN_pretrain, no need to load decoder</span>\n",
              "                <span class=\"c1\"># load model for VAE on different tasks, no classifier</span>\n",
              "                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;## SAVE Enc, Dec, Cls: classify loss:&#39;</span><span class=\"p\">,</span>\n",
              "                      <span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> -&gt; </span><span class=\"si\">{</span><span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> &#39;</span><span class=\"p\">,</span>\n",
              "                      <span class=\"sa\">f</span><span class=\"s1\">&#39;| runtime: </span><span class=\"si\">{</span><span class=\"n\">train_time</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> ms&#39;</span><span class=\"p\">)</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span> <span class=\"o\">=</span> <span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
              "                <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder_path</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder_path</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span> \n",
              "                           <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier_path</span><span class=\"p\">)</span>\n",
              "            \n",
              "            \n",
              "\n",
              "            <span class=\"n\">early_stop</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stopper</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">(</span><span class=\"n\">val_s</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">)</span> <span class=\"c1\"># cls loss</span>\n",
              "            \n",
              "            \n",
              "            <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"ow\">and</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_runtime</span><span class=\"p\">()</span>\n",
              "                <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span>                 <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;different task weight&#39;</span><span class=\"p\">,</span> \n",
              "                            <span class=\"p\">[</span><span class=\"s1\">&#39;</span><span class=\"si\">{:.3f}</span><span class=\"s1\">&#39;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;Classify loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "                \n",
              "                <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"n\">train_total</span><span class=\"p\">,</span> <span class=\"n\">valid_total</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;Total loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "                \n",
              "                <span class=\"n\">eval_dict</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span>  <span class=\"n\">IS_R</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">)</span>\n",
              "            \n",
              "            <span class=\"k\">if</span> <span class=\"n\">early_stop</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;early stop&#39;</span><span class=\"p\">);</span> <span class=\"k\">break</span>\n",
              "\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finished training</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">data_df</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"c1\"># evaluated PCA on data_df, create gif</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">:</span> \n",
              "                <span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">epoch</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n",
              "                    <span class=\"n\">file_name</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">figure_path</span> <span class=\"o\">+</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;/PCA_</span><span class=\"si\">{</span><span class=\"n\">n</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">}</span><span class=\"s1\">.png&#39;</span>\n",
              "                    <span class=\"c1\"># print(file_name)</span>\n",
              "                    <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">):</span> \n",
              "                        <span class=\"k\">try</span><span class=\"p\">:</span> <span class=\"n\">images</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">imageio</span><span class=\"o\">.</span><span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"n\">file_name</span><span class=\"p\">))</span>\n",
              "                        <span class=\"k\">except</span><span class=\"p\">:</span> <span class=\"k\">pass</span>\n",
              "                <span class=\"n\">gif_path</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">figure_path</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">n</span><span class=\"si\">}</span><span class=\"s1\">.gif&#39;</span>\n",
              "                <span class=\"n\">imageio</span><span class=\"o\">.</span><span class=\"n\">mimsave</span><span class=\"p\">(</span><span class=\"n\">gif_path</span><span class=\"p\">,</span> <span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">duration</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
              "                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;save gif at: &#39;</span><span class=\"p\">,</span> <span class=\"n\">gif_path</span><span class=\"p\">)</span>\n",
              "                <span class=\"c1\"># from IPython.display import Image</span>\n",
              "                <span class=\"n\">display</span><span class=\"p\">(</span><span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">display</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">=</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">gif_path</span><span class=\"p\">,</span> <span class=\"s1\">&#39;rb&#39;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(),</span>\n",
              "                        <span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">&#39;png&#39;</span><span class=\"p\">))</span>\n",
              "\n",
              "        \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_train_status</span><span class=\"p\">()</span> <span class=\"c1\"># status yml is saved iff train finished</span>\n",
              "        <span class=\"c1\"># print(&#39;task weight&#39;, </span>\n",
              "        <span class=\"c1\">#                 [&#39;{:.3f}&#39;.format(i) for i in self.weight_loss])</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Model parameters: &#39;</span><span class=\"p\">,</span> <span class=\"n\">count_parameters</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">))</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_runtime</span><span class=\"p\">()</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;best epoch: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"si\">}</span><span class=\"s2\">, min loss: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"n\">train_cls</span><span class=\"p\">,</span> <span class=\"n\">valid_cls</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;Classify loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"n\">test_loader</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"c1\"># evaluate test set</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span><span class=\"p\">,</span><span class=\"n\">_</span><span class=\"p\">,</span><span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">(</span><span class=\"n\">test_loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_train_status</span><span class=\"p\">()</span> <span class=\"c1\"># update train status with test performance</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finished evaluate test performance, outputs performance dict&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">smile_list</span><span class=\"p\">:</span><span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">return_probs</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">scale_back</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_vae_pretrain</span><span class=\"p\">()</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">smile_list</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">):</span> <span class=\"n\">smile_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">smile_list</span><span class=\"p\">]</span>\n",
              "        <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">();</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">&#39;Drug&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">smile_list</span> \n",
              "        \n",
              "        <span class=\"k\">for</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">:</span>\n",
              "            <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">MASK</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">smile_list</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"n\">prm</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;batch_size&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;shuffle&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> \n",
              "               <span class=\"s1\">&#39;drop_last&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"s1\">&#39;num_workers&#39;</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">}</span>\n",
              "        <span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">get_loader</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span> <span class=\"n\">prm</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">,</span>\n",
              "                            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab_type</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"n\">y_probs</span> <span class=\"o\">=</span> <span class=\"n\">model_predict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"p\">,</span> <span class=\"n\">MASK</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span> <span class=\"n\">scale_back</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">name</span> <span class=\"ow\">in</span> <span class=\"n\">y_probs</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n",
              "            <span class=\"n\">is_r</span> <span class=\"o\">=</span> <span class=\"n\">names_dict</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">if</span> <span class=\"n\">is_r</span> <span class=\"o\">==</span> <span class=\"kc\">False</span> <span class=\"ow\">and</span> <span class=\"n\">return_probs</span><span class=\"o\">==</span><span class=\"kc\">False</span><span class=\"p\">:</span> <span class=\"c1\"># cls, prob -&gt; pred</span>\n",
              "                <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">get_preds</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">])</span>\n",
              "            <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">y_probs</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">return</span> <span class=\"n\">df</span>\n",
              "\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n",
              "                 <span class=\"n\">data_df</span><span class=\"o\">=</span><span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(),</span> <span class=\"n\">sample_num</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">latent_eval_freq</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span> \n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">map_location</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
              "        <span class=\"k\">else</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Start training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">...&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"c1\"># if &#39;MAX_EPOCH&#39; not in self.config: MAX_EPOCH = 1000</span>\n",
              "        <span class=\"c1\"># else:          MAX_EPOCH = self.config[&#39;MAX_EPOCH&#39;]</span>\n",
              "        <span class=\"c1\"># single task, no need uncertainty weight</span>\n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;VAE&#39;</span><span class=\"p\">:</span> \n",
              "            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_VAE</span><span class=\"p\">(</span><span class=\"n\">data_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">,</span> <span class=\"n\">test_loader</span><span class=\"p\">,</span>\n",
              "                                  <span class=\"n\">data_df</span><span class=\"p\">,</span> <span class=\"n\">sample_num</span><span class=\"p\">,</span> <span class=\"n\">latent_eval_freq</span><span class=\"p\">)</span>\n",
              "\n",
              "        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> \n",
              "        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span> \n",
              "            <span class=\"n\">m_w</span> <span class=\"o\">=</span> <span class=\"n\">MTLoss</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span> \n",
              "            <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">m_w</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">);</span> <span class=\"n\">m_w</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n",
              "    \n",
              "        \n",
              "        <span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">MAX_EPOCH</span><span class=\"p\">):</span>\n",
              "            <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n",
              "            <span class=\"n\">score</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">r</span>  <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">data_loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span>\n",
              "                                  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"p\">,</span>\n",
              "                                  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">scale_dict</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span>\n",
              "                                  <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">train_time</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">t</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mi\">1000</span> <span class=\"o\">/</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">data_loader</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">times_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">train_time</span><span class=\"p\">)</span>\n",
              "\n",
              "            <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span> <span class=\"c1\"># uncertainty weight training</span>\n",
              "                <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n",
              "                <span class=\"n\">total_loss</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"n\">m_w</span><span class=\"p\">(</span><span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">total_loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">();</span> <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n",
              "            <span class=\"c1\"># do not use weight loss for val?  </span>\n",
              "            <span class=\"n\">val_score</span><span class=\"p\">,</span> <span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_fn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span>  <span class=\"n\">val_loader</span><span class=\"p\">,</span>\n",
              "                                       <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">,</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span>\n",
              "                                       <span class=\"n\">epoch</span><span class=\"p\">,</span>   <span class=\"n\">scale_dict</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">scale_dict</span><span class=\"p\">,</span>\n",
              "                                       <span class=\"n\">weight_loss</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">)</span> \n",
              "            \n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">score</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">[</span><span class=\"n\">epoch</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">val_score</span>\n",
              "            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Epoch:</span><span class=\"si\">{</span><span class=\"n\">epoch</span><span class=\"si\">}</span><span class=\"s1\"> [Train] Loss: </span><span class=\"si\">{</span><span class=\"n\">score</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> |&#39;</span><span class=\"p\">,</span>\n",
              "                  <span class=\"sa\">f</span><span class=\"s1\">&#39;[Valid] Loss: </span><span class=\"si\">{</span><span class=\"n\">val_score</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s2\">&quot;</span><span class=\"se\">\\t</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
              "            <span class=\"n\">early_stop</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stopper</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">(</span><span class=\"n\">val_score</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">)</span>\n",
              "            \n",
              "            <span class=\"k\">if</span> <span class=\"n\">val_score</span> <span class=\"o\">&lt;</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"p\">:</span> <span class=\"c1\"># loss drop, save model</span>\n",
              "                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;SAVE MODEL: loss: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> -&gt; &#39;</span>\n",
              "                      <span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"n\">val_score</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> | runtime: </span><span class=\"si\">{</span><span class=\"n\">train_time</span><span class=\"si\">:</span><span class=\"s1\">.3f</span><span class=\"si\">}</span><span class=\"s1\"> ms&#39;</span><span class=\"p\">)</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span> <span class=\"o\">=</span> <span class=\"n\">val_score</span><span class=\"p\">;</span>  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span> <span class=\"o\">=</span> <span class=\"n\">epoch</span>\n",
              "                <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "\n",
              "            <span class=\"k\">if</span> <span class=\"n\">epoch</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">verbose_freq</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"ow\">and</span> <span class=\"n\">epoch</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n",
              "                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_runtime</span><span class=\"p\">()</span>\n",
              "                <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">uw</span><span class=\"p\">:</span>                 <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;different task weight&#39;</span><span class=\"p\">,</span> \n",
              "                           <span class=\"p\">[</span><span class=\"s1\">&#39;</span><span class=\"si\">{:.3f}</span><span class=\"s1\">&#39;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                    <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">eval_dict</span><span class=\"p\">(</span><span class=\"n\">probs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop_names</span><span class=\"p\">,</span>  <span class=\"n\">IS_R</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">IS_R</span><span class=\"p\">)</span>\n",
              "                \n",
              "            <span class=\"k\">if</span> <span class=\"n\">early_stop</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;early stop&#39;</span><span class=\"p\">);</span> <span class=\"k\">break</span>\n",
              "\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finished training</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_train_status</span><span class=\"p\">()</span> <span class=\"c1\"># status yml file is saved iff train finished</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;task weight&#39;</span><span class=\"p\">,</span> \n",
              "                        <span class=\"p\">[</span><span class=\"s1\">&#39;</span><span class=\"si\">{:.3f}</span><span class=\"s1\">&#39;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weight_loss</span><span class=\"p\">])</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Model parameters: &#39;</span><span class=\"p\">,</span> <span class=\"n\">count_parameters</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">))</span>\n",
              "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">get_runtime</span><span class=\"p\">()</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;best epoch: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">best_epoch</span><span class=\"si\">}</span><span class=\"s2\">, min loss: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">min_loss</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dict</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">valid_dict</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;valid&#39;</span><span class=\"p\">,</span>\n",
              "                  <span class=\"n\">title_name</span><span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">&#39;loss during training </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_type</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
              "        \n",
              "        <span class=\"k\">if</span> <span class=\"n\">test_loader</span> <span class=\"o\">!=</span> <span class=\"kc\">None</span><span class=\"p\">:</span> <span class=\"c1\"># evaluate test set</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span><span class=\"p\">,</span><span class=\"n\">_</span><span class=\"p\">,</span><span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">(</span><span class=\"n\">test_loader</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model_path</span><span class=\"p\">)</span>\n",
              "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">save_train_status</span><span class=\"p\">()</span> <span class=\"c1\"># update status yml with test performance</span>\n",
              "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Finished evaluate test performance, outputs performance dict&#39;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">performance_dict</span>\n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n\\PY{l+s+sd}{Date: 09/07/2023}\n\\PY{l+s+sd}{Mods: 11/08/2023, edited train\\PYZus{}epoch\\PYZus{}VAE: add tqdm}\n\\PY{l+s+sd}{Athr: Bu}\n\\PY{l+s+sd}{Aims: train functions for all models}\n\\PY{l+s+sd}{Mods: }\n\\PY{l+s+sd}{      02/05/2024, add scale\\PYZus{}back in model\\PYZus{}predict function}\n\\PY{l+s+sd}{Func:}\n\\PY{l+s+sd}{      tbc...}\n\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n\n\\PY{k+kn}{import} \\PY{n+nn}{yaml}\n\\PY{k+kn}{import} \\PY{n+nn}{time}\n\\PY{k+kn}{import} \\PY{n+nn}{torch}\n\\PY{k+kn}{import} \\PY{n+nn}{IPython}\n\\PY{k+kn}{import} \\PY{n+nn}{imageio}\n\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n\\PY{k+kn}{from} \\PY{n+nn}{os} \\PY{k+kn}{import} \\PY{n}{walk}\n\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn} \\PY{k}{as} \\PY{n+nn}{nn}\n\\PY{k+kn}{from} \\PY{n+nn}{tqdm} \\PY{k+kn}{import} \\PY{n}{tqdm}\n\\PY{k+kn}{from} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn} \\PY{k+kn}{import} \\PY{n}{Module}\n\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn}\\PY{n+nn}{.}\\PY{n+nn}{functional} \\PY{k}{as} \\PY{n+nn}{F}\n\\PY{k+kn}{from} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn}\\PY{n+nn}{.}\\PY{n+nn}{utils} \\PY{k+kn}{import} \\PY{n}{clip\\PYZus{}grad\\PYZus{}norm\\PYZus{}}\n\\PY{k+kn}{from} \\PY{n+nn}{dgllife}\\PY{n+nn}{.}\\PY{n+nn}{utils} \\PY{k+kn}{import} \\PY{n}{EarlyStopping}\\PY{p}{,} \\PY{n}{Meter}\n\\PY{k+kn}{from} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{utils}\\PY{n+nn}{.}\\PY{n+nn}{data} \\PY{k+kn}{import} \\PY{n}{DataLoader}\\PY{p}{,} \\PY{n}{Dataset}\n\n\n\\PY{k+kn}{from} \\PY{n+nn}{scripts}\\PY{n+nn}{.}\\PY{n+nn}{CONSTANT} \\PY{k+kn}{import} \\PY{o}{*}\n\\PY{k+kn}{from} \\PY{n+nn}{scripts}\\PY{n+nn}{.}\\PY{n+nn}{eval\\PYZus{}utils} \\PY{k+kn}{import} \\PY{o}{*}\n\\PY{k+kn}{from} \\PY{n+nn}{scripts}\\PY{n+nn}{.}\\PY{n+nn}{func\\PYZus{}utils} \\PY{k+kn}{import} \\PY{o}{*}\n\\PY{k+kn}{from} \\PY{n+nn}{scripts}\\PY{n+nn}{.}\\PY{n+nn}{dataset} \\PY{k+kn}{import} \\PY{n}{get\\PYZus{}loader}\n\\PY{k+kn}{from} \\PY{n+nn}{scripts}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}architecture} \\PY{k+kn}{import} \\PY{o}{*}\n\n\\PY{n}{clip\\PYZus{}grad}  \\PY{o}{=} \\PY{l+m+mi}{50}\n\\PY{n}{model\\PYZus{}types} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MLP}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{AttentiveFP}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GIN}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{RNN}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \n                \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{RNN\\PYZus{}pretrain}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MUE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{chemBERTa}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n\n\\PY{k}{def} \\PY{n+nf}{count\\PYZus{}bool}\\PY{p}{(}\\PY{n}{lst}\\PY{p}{)}\\PY{p}{:} \\PY{k}{return} \\PY{n+nb}{sum}\\PY{p}{(}\\PY{n}{lst}\\PY{p}{)}\n\n\\PY{k}{def} \\PY{n+nf}{count\\PYZus{}parameters}\\PY{p}{(}\\PY{n}{model}\\PY{p}{:} \\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{return} \\PY{n+nb}{sum}\\PY{p}{(}\\PY{n}{p}\\PY{o}{.}\\PY{n}{numel}\\PY{p}{(}\\PY{p}{)} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n\n\\PY{k}{def} \\PY{n+nf}{count\\PYZus{}trainable}\\PY{p}{(}\\PY{n}{model}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{return} \\PY{n+nb}{sum}\\PY{p}{(}\\PY{n}{p}\\PY{o}{.}\\PY{n}{numel}\\PY{p}{(}\\PY{p}{)} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)} \\PY{k}{if} \\PY{n}{p}\\PY{o}{.}\\PY{n}{requires\\PYZus{}grad}\\PY{p}{)}\n\n\\PY{k}{def} \\PY{n+nf}{get\\PYZus{}optim\\PYZus{}params}\\PY{p}{(}\\PY{n}{model}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{return} \\PY{p}{(}\\PY{n}{p} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)} \\PY{k}{if} \\PY{n}{p}\\PY{o}{.}\\PY{n}{requires\\PYZus{}grad}\\PY{p}{)}\n    \n\\PY{k}{def} \\PY{n+nf}{initialize\\PYZus{}weights}\\PY{p}{(}\\PY{n}{m}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{if} \\PY{n+nb}{hasattr}\\PY{p}{(}\\PY{n}{m}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)} \\PY{o+ow}{and} \\PY{n}{m}\\PY{o}{.}\\PY{n}{weight}\\PY{o}{.}\\PY{n}{dim}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZgt{}} \\PY{l+m+mi}{1}\\PY{p}{:}\n        \\PY{n}{nn}\\PY{o}{.}\\PY{n}{init}\\PY{o}{.}\\PY{n}{xavier\\PYZus{}uniform\\PYZus{}}\\PY{p}{(}\\PY{n}{m}\\PY{o}{.}\\PY{n}{weight}\\PY{o}{.}\\PY{n}{data}\\PY{p}{)}\n\n\\PY{k}{def} \\PY{n+nf}{clamp}\\PY{p}{(}\\PY{n}{number}\\PY{p}{,} \\PY{n}{min\\PYZus{}value}\\PY{o}{=}\\PY{l+m+mf}{1e\\PYZhy{}5}\\PY{p}{,} \\PY{n}{max\\PYZus{}value}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{o}{\\PYZhy{}}\\PY{l+m+mf}{1e\\PYZhy{}5}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{return} \\PY{n+nb}{max}\\PY{p}{(}\\PY{n}{min\\PYZus{}value}\\PY{p}{,} \\PY{n+nb}{min}\\PY{p}{(}\\PY{n}{number}\\PY{p}{,} \\PY{n}{max\\PYZus{}value}\\PY{p}{)}\\PY{p}{)}\n\\PY{c+c1}{\\PYZsh{} uncertainty weight}\n\\PY{k}{class} \\PY{n+nc}{MTLoss}\\PY{p}{(}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} calculate multitask loss with trainable parameters}\n    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{task\\PYZus{}num}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{device}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{cuda}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{:} \n        \\PY{n+nb}{super}\\PY{p}{(}\\PY{n}{MTLoss}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task\\PYZus{}num} \\PY{o}{=} \\PY{n}{task\\PYZus{}num}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device} \\PY{o}{=} \\PY{n}{device}\n        \\PY{k}{if} \\PY{n}{weight\\PYZus{}loss}\\PY{o}{==}\\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{l+m+mf}{1.0}\\PY{p}{]} \\PY{o}{*} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task\\PYZus{}num}\n        \\PY{c+c1}{\\PYZsh{} ùúÇ := ùëôùëúùëîùúé2}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eta} \\PY{o}{=} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Parameter}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{tensor}\\PY{p}{(}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{,} \\PY{n}{device}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n        \n    \\PY{k}{def} \\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{loss\\PYZus{}list}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{assert} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loss\\PYZus{}list}\\PY{p}{)} \\PY{o}{==} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task\\PYZus{}num}\n        \\PY{k}{if} \\PY{n}{IS\\PYZus{}R} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \n            \\PY{k}{assert} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)} \\PY{o}{==} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loss\\PYZus{}list}\\PY{p}{)}\n            \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{if} \\PY{n}{IS\\PYZus{}R}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]} \\PY{o}{==} \\PY{k+kc}{True}\\PY{p}{:} \\PY{n}{loss\\PYZus{}list}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]} \\PY{o}{/}\\PY{o}{=} \\PY{l+m+mi}{2} \n        \\PY{n}{loss\\PYZus{}list} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{n}{loss\\PYZus{}list}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\n        \\PY{n}{total\\PYZus{}loss} \\PY{o}{=} \\PY{n}{loss\\PYZus{}list} \\PY{o}{*} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{exp}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eta}\\PY{p}{)} \\PY{o}{+} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eta} \\PY{o}{*} \\PY{l+m+mf}{0.5} \n\n        \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{n+nb}{float}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eta}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{task\\PYZus{}num}\\PY{p}{)}\\PY{p}{]}\n        \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{n}{np}\\PY{o}{.}\\PY{n}{exp}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{l+m+mf}{1.0} \\PY{o}{*} \\PY{n}{i}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\n        \\PY{k}{if} \\PY{n}{IS\\PYZus{}R} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:}\n            \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{if} \\PY{n}{IS\\PYZus{}R}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]} \\PY{o}{==} \\PY{k+kc}{True}\\PY{p}{:} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]} \\PY{o}{/}\\PY{o}{=} \\PY{l+m+mi}{2}\n\n        \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{n}{i}\\PY{o}{/}\\PY{n+nb}{sum}\\PY{p}{(}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\n        \n        \\PY{k}{for} \\PY{n}{n} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:} \n            \\PY{k}{if} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]} \\PY{o}{\\PYZlt{}} \\PY{l+m+mf}{1e\\PYZhy{}5}\\PY{p}{:} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]} \\PY{o}{=} \\PY{n}{clamp}\\PY{p}{(}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]}\\PY{p}{)}\n        \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{n}{i}\\PY{o}{/}\\PY{n+nb}{sum}\\PY{p}{(}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\n\n        \n        \\PY{k}{return} \\PY{n}{total\\PYZus{}loss}\\PY{o}{.}\\PY{n}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\n\n\n\\PY{k}{def} \\PY{n+nf}{init\\PYZus{}model}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\\PY{p}{:}\n\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}need incorporate all models here! \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n    \\PY{k}{if}   \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MLP}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}          \\PY{n}{model} \\PY{o}{=} \\PY{n}{Classifier}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GIN}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}          \\PY{n}{model} \\PY{o}{=} \\PY{n}{GIN\\PYZus{}MOD}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)} \n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{AttentiveFP}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}  \\PY{n}{model} \\PY{o}{=} \\PY{n}{AttentiveFP}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{RNN}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}          \\PY{n}{model} \\PY{o}{=} \\PY{n}{RNN}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}          \\PY{n}{model} \\PY{o}{=} \\PY{n}{RNNVAE}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{RNN\\PYZus{}pretrain}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n}{model} \\PY{o}{=} \\PY{n}{RNN\\PYZus{}pretrain}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MUE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}          \\PY{n}{model} \\PY{o}{=} \\PY{n}{Classifier}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{elif} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{chemBERTa}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}    \\PY{n}{model} \\PY{o}{=} \\PY{n}{chemBERTa}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\n    \\PY{k}{else}\\PY{p}{:}                    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{invalid model type:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n    \\PY{k}{return} \\PY{n}{model}\n\n\n\\PY{k}{def} \\PY{n+nf}{get\\PYZus{}train\\PYZus{}fn}\\PY{p}{(}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{if}   \\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}       \\PY{k}{return} \\PY{n}{train\\PYZus{}epoch\\PYZus{}VAE}\n    \\PY{k}{elif} \\PY{n}{model\\PYZus{}type} \\PY{o+ow}{in} \\PY{n}{model\\PYZus{}types}\\PY{p}{:} \\PY{k}{return} \\PY{n}{train\\PYZus{}epoch\\PYZus{}MLP}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{invalid model type:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{model\\PYZus{}type}\\PY{p}{)}\\PY{p}{;} \\PY{k}{return}\n\n\\PY{k}{def} \\PY{n+nf}{get\\PYZus{}eval\\PYZus{}fn}\\PY{p}{(}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{if}   \\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}       \\PY{k}{return} \\PY{n}{train\\PYZus{}epoch\\PYZus{}VAE}\n    \\PY{k}{elif} \\PY{n}{model\\PYZus{}type} \\PY{o+ow}{in} \\PY{n}{model\\PYZus{}types}\\PY{p}{:} \\PY{k}{return} \\PY{n}{train\\PYZus{}epoch\\PYZus{}MLP}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{invalid model type:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{model\\PYZus{}type}\\PY{p}{)}\\PY{p}{;} \\PY{k}{return}\n\n\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}epoch\\PYZus{}MLP}\\PY{p}{(}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{device}\\PY{p}{,}\n                    \\PY{n}{epoch}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{optimizer}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{MASK}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{100}\\PY{p}{,}\n                    \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \n                    \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{ver}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n\\PY{l+s+sd}{    param weight\\PYZus{}loss: list, the weight of loss for different tasks}\n\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n    \n    \\PY{k}{if} \\PY{n}{optimizer}\\PY{o}{==}\\PY{k+kc}{None}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} no optimizer, either validation or test}\n        \\PY{n}{model}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{p}{)}    \\PY{c+c1}{\\PYZsh{} model evaluation for either valid or test}\n        \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{train\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Valid}\\PY{l+s+s1}{\\PYZsq{}} \\PY{c+c1}{\\PYZsh{} if epoch is inputted, its valid}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n}{train\\PYZus{}type} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Test}\\PY{l+s+s1}{\\PYZsq{}} \\PY{c+c1}{\\PYZsh{} if no epoch information, its test}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n}{model}\\PY{o}{.}\\PY{n}{train}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{train\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}} \\PY{c+c1}{\\PYZsh{} if optimizer inputted, its train}\n    \n\n    \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n+nb}{list}\\PY{p}{)}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{n}{IS\\PYZus{}R}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{IS\\PYZus{}R}\\PY{p}{]} \\PY{o}{*} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\n    \\PY{k}{if} \\PY{n}{weight\\PYZus{}loss} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{l+m+mf}{1.0}\\PY{o}{/}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\\PY{p}{]}\\PY{o}{*}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\n\n    \\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label} \\PY{o}{=} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{p}{[}\\PY{p}{]}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\n    \\PY{k}{for} \\PY{n}{idx}\\PY{p}{,} \\PY{n}{batch\\PYZus{}data} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{:}\n\\PY{+w}{        }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n\\PY{l+s+sd}{        len(batch\\PYZus{}data) could determine which algorithm}\n\\PY{l+s+sd}{        len(batch\\PYZus{}data) == 2: MLP, GIN, RNN, ENSEMBLE}\n\\PY{l+s+sd}{        len(batch\\PYZus{}data) == 4: AttentiveFP}\n\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{2}\\PY{p}{:}  \\PY{c+c1}{\\PYZsh{} MLP or GIN or RNN or chemBERTa}\n            \\PY{n}{fp}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{batch\\PYZus{}data} \n            \\PY{c+c1}{\\PYZsh{} fp, labels = fp.to(device), labels.to(device)}\n            \\PY{n}{labels} \\PY{o}{=} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \n            \\PY{k}{try}\\PY{p}{:} \\PY{n}{fp} \\PY{o}{=} \\PY{n}{fp}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} MLP, GIN, RNN}\n            \\PY{k}{except}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} chemberta}\n                \\PY{k}{del} \\PY{n}{batch\\PYZus{}data}\n                \\PY{n}{fp} \\PY{o}{=} \\PY{n+nb}{list}\\PY{p}{(}\\PY{n}{fp}\\PY{p}{)}   \\PY{c+c1}{\\PYZsh{} actually SMILES, convert tuple to list}\n                \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{1}\\PY{p}{:} \n                    \\PY{n}{labels} \\PY{o}{=} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{fp}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\\PY{p}{)}\n            \n            \\PY{n}{mask} \\PY{o}{=} \\PY{n}{labels} \\PY{o}{==} \\PY{n}{MASK}\n            \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{fp}\\PY{p}{)}\n            \\PY{k}{del} \\PY{n}{fp}\n            \n        \\PY{k}{elif} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{4}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} attentiveFP}\n            \\PY{n}{smiles}\\PY{p}{,} \\PY{n}{bg}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{,} \\PY{n}{masks} \\PY{o}{=} \\PY{n}{batch\\PYZus{}data}\n            \\PY{n}{bg}\\PY{p}{,}\\PY{n}{labels}\\PY{p}{,}\\PY{n}{masks} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\\PY{p}{,} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\\PY{p}{,} \\PY{n}{masks}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{n\\PYZus{}feats} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{ndata}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{hv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{e\\PYZus{}feats} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{edata}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{he}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{bg}\\PY{p}{,} \\PY{n}{n\\PYZus{}feats}\\PY{p}{,} \\PY{n}{e\\PYZus{}feats}\\PY{p}{)}\n            \\PY{n}{mask} \\PY{o}{=} \\PY{n}{masks} \\PY{o}{\\PYZlt{}} \\PY{l+m+mi}{1}\n        \n        \\PY{n}{batch\\PYZus{}loss\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n        \\PY{k}{for} \\PY{n}{j}\\PY{p}{,} \\PY{p}{(}\\PY{n}{name}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n}{w}\\PY{p}{)} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n+nb}{zip}\\PY{p}{(}\\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n            \\PY{n}{loss\\PYZus{}func} \\PY{o}{=} \\PY{n}{get\\PYZus{}loss\\PYZus{}fn}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\n            \\PY{n}{probs} \\PY{o}{=} \\PY{n}{pred}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n            \\PY{n}{label} \\PY{o}{=} \\PY{n}{labels}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n             \n            \n            \\PY{n}{len\\PYZus{}here} \\PY{o}{=} \\PY{n}{label}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]} \\PY{c+c1}{\\PYZsh{} num of data with labels}\n            \\PY{n}{loss\\PYZus{}here} \\PY{o}{=} \\PY{n}{loss\\PYZus{}func}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\\PY{p}{)} \n            \\PY{k}{if} \\PY{n}{len\\PYZus{}here} \\PY{o}{!=} \\PY{l+m+mi}{0}\\PY{p}{:}\n                \\PY{n}{loss\\PYZus{}here} \\PY{o}{/}\\PY{o}{=} \\PY{n}{len\\PYZus{}here}\n                \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{loss\\PYZus{}here}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n            \\PY{k}{else}\\PY{p}{:}       \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n+nb}{float}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n            \n            \\PY{k}{if} \\PY{n}{j} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{loss}  \\PY{o}{=} \\PY{n}{loss\\PYZus{}here} \\PY{o}{*} \\PY{n}{w}\n            \\PY{k}{else}\\PY{p}{:}      \\PY{n}{loss} \\PY{o}{+}\\PY{o}{=} \\PY{n}{loss\\PYZus{}here} \\PY{o}{*} \\PY{n}{w}\n\n            \\PY{k}{if} \\PY{n}{IS\\PYZus{}R} \\PY{o}{==} \\PY{k+kc}{False}\\PY{p}{:} \\PY{n}{probs} \\PY{o}{=} \\PY{n}{F}\\PY{o}{.}\\PY{n}{sigmoid}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{)}\n            \\PY{k}{if} \\PY{n}{train\\PYZus{}type} \\PY{o}{!=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} valid or test, output probs and labels}\n                                      \\PY{c+c1}{\\PYZsh{} if train, no process prob to save time}\n                \\PY{n}{probs} \\PY{o}{=} \\PY{n}{probs}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n                \\PY{n}{label} \\PY{o}{=} \\PY{n}{label}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n                \\PY{k}{if} \\PY{n}{scale\\PYZus{}dict} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:}\n                    \\PY{k}{if} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{.}\\PY{n}{keys}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{min\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n                        \\PY{n}{max\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n                        \\PY{n}{del\\PYZus{}here} \\PY{o}{=} \\PY{n}{max\\PYZus{}here} \\PY{o}{\\PYZhy{}} \\PY{n}{min\\PYZus{}here}\n                        \\PY{n}{label} \\PY{o}{=} \\PY{p}{[}\\PY{n}{l} \\PY{o}{*} \\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{l} \\PY{o+ow}{in} \\PY{n}{label}\\PY{p}{]}\n                        \\PY{n}{probs} \\PY{o}{=} \\PY{p}{[}\\PY{n}{p} \\PY{o}{*} \\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{probs}\\PY{p}{]}\n                    \n                \\PY{k}{if} \\PY{n}{idx} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\n                \\PY{k}{else}\\PY{p}{:}     \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{probs}\\PY{p}{;} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{label}\n        \n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{losses\\PYZus{}list}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:}               \\PY{n}{losses\\PYZus{}list} \\PY{o}{=} \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n}{losses\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{i}\\PY{o}{+}\\PY{n}{j} \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n+nb}{zip}\\PY{p}{(}\\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{p}{)}\\PY{p}{]}\n\n        \\PY{n}{total\\PYZus{}loss} \\PY{o}{+}\\PY{o}{=} \\PY{n}{loss}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\n\n        \\PY{k}{if} \\PY{n}{optimizer} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:}\n            \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{loss}\\PY{o}{.}\\PY{n}{backward}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{p}{)}\n\n    \\PY{n}{total\\PYZus{}loss} \\PY{o}{/}\\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} no need /loader.dataset since has / len\\PYZus{}here }\n    \n    \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} train or valid}\n        \\PY{k}{if} \\PY{n}{ver}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Epoch:}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{, [}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{total\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n    \n    \\PY{k}{elif} \\PY{n}{epoch} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} test}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{[}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{total\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{n}{performance} \\PY{o}{=} \\PY{n}{eval\\PYZus{}dict}\\PY{p}{(}\\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\\PY{p}{,} \n                                \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{n}{model\\PYZus{}type}\\PY{p}{,} \\PY{n}{draw\\PYZus{}fig}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n        \\PY{n}{performance}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n+nb}{float}\\PY{p}{(}\\PY{n}{total\\PYZus{}loss}\\PY{p}{)}\n\n    \\PY{n}{IS\\PYZus{}R} \\PY{o}{=} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\n    \\PY{k}{if}   \\PY{n}{train\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k}{return} \\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R} \\PY{c+c1}{\\PYZsh{} train}\n    \\PY{k}{elif} \\PY{n}{train\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k}{return} \\PY{n}{total\\PYZus{}loss}\\PY{p}{,}  \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label} \\PY{c+c1}{\\PYZsh{} valid}\n    \\PY{k}{else}\\PY{p}{:}                       \\PY{k}{return} \\PY{n}{performance}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label} \\PY{c+c1}{\\PYZsh{} test}\n\n\n\n\n\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}epoch\\PYZus{}VAE}\\PY{p}{(}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{device}\\PY{p}{,} \n                    \\PY{n}{kl\\PYZus{}weight}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{cls\\PYZus{}weight}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\n                    \\PY{n}{epoch}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{optimizer}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \n                    \\PY{n}{MASK}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \n                    \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{:}\n\n    \\PY{k}{if} \\PY{n}{optimizer} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \n        \\PY{n}{model}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{p}{)}          \\PY{c+c1}{\\PYZsh{} Valid or Test}\n        \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{train\\PYZus{}type} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Valid}\\PY{l+s+s1}{\\PYZsq{}}\n        \\PY{k}{else}\\PY{p}{:}             \\PY{n}{train\\PYZus{}type} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Test}\\PY{l+s+s1}{\\PYZsq{}}\n    \\PY{k}{else}\\PY{p}{:}  \\PY{n}{model}\\PY{o}{.}\\PY{n}{train}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{train\\PYZus{}type} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}}\n\n    \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n+nb}{list}\\PY{p}{)}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{n}{IS\\PYZus{}R}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{IS\\PYZus{}R}\\PY{p}{]} \\PY{o}{*} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\n    \n    \\PY{k}{if} \\PY{n}{weight\\PYZus{}loss} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{p}{[}\\PY{l+m+mf}{1.0}\\PY{o}{/}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\\PY{p}{]}\\PY{o}{*}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\n    \\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label} \\PY{o}{=} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{p}{[}\\PY{p}{]}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\n    \\PY{n}{klds}\\PY{p}{,} \\PY{n}{recs}\\PY{p}{,} \\PY{n}{clss} \\PY{o}{=} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{0}\n    \\PY{k}{for} \\PY{n}{idx}\\PY{p}{,} \\PY{n}{batch\\PYZus{}data} \\PY{o+ow}{in} \\PY{n}{tqdm}\\PY{p}{(}\\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{,} \n                            \\PY{n}{total}\\PY{o}{=}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{,} \\PY{n}{desc}\\PY{o}{=}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{2}\\PY{p}{:} \\PY{n}{x}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{batch\\PYZus{}data}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n}{x}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{batch\\PYZus{}data}\\PY{p}{,} \\PY{k+kc}{None}\n        \\PY{n}{kld}\\PY{p}{,} \\PY{n}{rec}\\PY{p}{,} \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n}{pred} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n+nb+bp}{cls} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{tensor}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n        \\PY{k}{else}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} label is not none, and has pred, calculate: }\n            \\PY{n}{labels} \\PY{o}{=} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{mask} \\PY{o}{=} \\PY{n}{labels} \\PY{o}{==} \\PY{n}{MASK}\n            \\PY{n}{batch\\PYZus{}loss\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n            \\PY{k}{for} \\PY{n}{j}\\PY{p}{,} \\PY{p}{(}\\PY{n}{name}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n}{w}\\PY{p}{)} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\n                \\PY{n+nb}{zip}\\PY{p}{(}\\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n                \\PY{n}{loss\\PYZus{}func} \\PY{o}{=} \\PY{n}{get\\PYZus{}loss\\PYZus{}fn}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\n                \\PY{n}{probs} \\PY{o}{=} \\PY{n}{pred}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n                \\PY{n}{label} \\PY{o}{=} \\PY{n}{labels}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n                \\PY{n}{len\\PYZus{}here} \\PY{o}{=} \\PY{n}{label}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n                \\PY{n}{loss\\PYZus{}here} \\PY{o}{=} \\PY{n}{loss\\PYZus{}func}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\\PY{p}{)}\n                \\PY{k}{if} \\PY{n}{len\\PYZus{}here} \\PY{o}{!=} \\PY{l+m+mi}{0}\\PY{p}{:} \n                    \\PY{n}{loss\\PYZus{}here} \\PY{o}{/}\\PY{o}{=} \\PY{n}{len\\PYZus{}here}\n                    \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{loss\\PYZus{}here}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n                \\PY{k}{else}\\PY{p}{:} \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n+nb}{float}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n\n                \\PY{k}{if} \\PY{n}{j} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n+nb+bp}{cls}  \\PY{o}{=} \\PY{n}{loss\\PYZus{}here} \\PY{o}{*} \\PY{n}{w}\n                \\PY{k}{else}\\PY{p}{:}      \\PY{n+nb+bp}{cls} \\PY{o}{+}\\PY{o}{=} \\PY{n}{loss\\PYZus{}here} \\PY{o}{*} \\PY{n}{w}\n\n                \\PY{k}{if} \\PY{n}{IS\\PYZus{}R} \\PY{o}{==} \\PY{k+kc}{False}\\PY{p}{:} \\PY{n}{probs} \\PY{o}{=} \\PY{n}{F}\\PY{o}{.}\\PY{n}{sigmoid}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{)}\n                \\PY{k}{if} \\PY{n}{train\\PYZus{}type} \\PY{o}{!=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \n                    \\PY{n}{probs} \\PY{o}{=} \\PY{n}{probs}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n                    \\PY{n}{label} \\PY{o}{=} \\PY{n}{label}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n                    \\PY{k}{if} \\PY{n}{scale\\PYZus{}dict} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \n                        \\PY{k}{if} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{.}\\PY{n}{keys}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                            \\PY{n}{min\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n                            \\PY{n}{max\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n                            \\PY{n}{del\\PYZus{}here} \\PY{o}{=} \\PY{n}{max\\PYZus{}here} \\PY{o}{\\PYZhy{}} \\PY{n}{min\\PYZus{}here}\n                            \\PY{n}{label} \\PY{o}{=} \\PY{p}{[}\\PY{n}{l} \\PY{o}{*} \\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{l} \\PY{o+ow}{in} \\PY{n}{label}\\PY{p}{]}\n                            \\PY{n}{probs} \\PY{o}{=} \\PY{p}{[}\\PY{n}{p} \\PY{o}{*} \\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{probs}\\PY{p}{]}\n                    \\PY{k}{if} \\PY{n}{idx} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\n                    \\PY{k}{else}\\PY{p}{:}     \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{probs}\\PY{p}{;} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{label} \n            \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{losses\\PYZus{}list}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{losses\\PYZus{}list} \\PY{o}{=} \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\n            \\PY{k}{else}\\PY{p}{:} \\PY{n}{losses\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{i}\\PY{o}{+}\\PY{n}{j} \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n+nb}{zip}\\PY{p}{(}\n                                    \\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{batch\\PYZus{}loss\\PYZus{}list}\\PY{p}{)}\\PY{p}{]}\n            \n        \\PY{n}{loss} \\PY{o}{=} \\PY{n}{kl\\PYZus{}weight} \\PY{o}{*} \\PY{n}{kld} \\PY{o}{+} \\PY{n}{rec} \\PY{o}{+} \\PY{n}{cls\\PYZus{}weight} \\PY{o}{*} \\PY{n+nb+bp}{cls}\n        \\PY{n}{total\\PYZus{}loss} \\PY{o}{+}\\PY{o}{=} \\PY{n}{loss}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\n        \\PY{n}{klds} \\PY{o}{+}\\PY{o}{=} \\PY{n}{kld}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{recs} \\PY{o}{+}\\PY{o}{=} \\PY{n}{rec}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{clss} \\PY{o}{+}\\PY{o}{=} \\PY{n+nb+bp}{cls}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\n\n        \\PY{k}{if} \\PY{n}{optimizer} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \n            \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{loss}\\PY{o}{.}\\PY{n}{backward}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n}{clip\\PYZus{}grad\\PYZus{}norm\\PYZus{}}\\PY{p}{(}\\PY{n}{get\\PYZus{}optim\\PYZus{}params}\\PY{p}{(}\\PY{n}{model}\\PY{p}{)}\\PY{p}{,} \\PY{n}{clip\\PYZus{}grad}\\PY{p}{)}\n            \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{p}{)}\n        \\PY{n}{lr}\\PY{o}{=}\\PY{p}{(}\\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{param\\PYZus{}groups}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{lr}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{k}{if} \\PY{n}{optimizer} \\PY{o+ow}{is} \\PY{o+ow}{not} \\PY{k+kc}{None} \\PY{k}{else} \\PY{k+kc}{None}\\PY{p}{)}\n    \n    \\PY{n}{IS\\PYZus{}R} \\PY{o}{=} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\n    \\PY{n}{total\\PYZus{}loss} \\PY{o}{/}\\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\n    \\PY{n}{klds} \\PY{o}{/}\\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{;} \\PY{n}{recs} \\PY{o}{/}\\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{;} \\PY{n}{clss} \\PY{o}{/}\\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\n    \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Epoch:}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ [}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{total\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ |}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n              \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{KL Div: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{klds}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ | Recon: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{recs}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ | Classify: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{clss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n              \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{| KL w: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{kl\\PYZus{}weight}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ | cls w: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cls\\PYZus{}weight}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)} \n    \\PY{k}{else}\\PY{p}{:}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{[}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{total\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ | Classify: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{clss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{n}{perf} \\PY{o}{=} \\PY{n}{eval\\PYZus{}dict}\\PY{p}{(}\\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \n                         \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{n}{model\\PYZus{}type}\\PY{p}{,} \\PY{n}{draw\\PYZus{}fig}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n        \\PY{n}{perf}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n+nb}{float}\\PY{p}{(}\\PY{n}{clss}\\PY{p}{)}\n    \n    \\PY{k}{if}   \\PY{n}{train\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k}{return} \\PY{p}{[}\\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n}{clss}\\PY{p}{]}\\PY{p}{,} \\PY{n}{losses\\PYZus{}list}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\n    \\PY{k}{elif} \\PY{n}{train\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k}{return} \\PY{p}{[}\\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n}{clss}\\PY{p}{]}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\n    \\PY{k}{elif} \\PY{n}{train\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Test}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}  \\PY{k}{return} \\PY{n}{perf}\\PY{p}{,}       \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\n\n\\PY{k}{def} \\PY{n+nf}{eval\\PYZus{}VAE}\\PY{p}{(}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{MASK}\\PY{o}{=}\\PY{n}{MASK}\\PY{p}{)}\\PY{p}{:}\n    \\PY{n}{model}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{p}{)}\n    \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{names}\\PY{p}{,} \\PY{n+nb}{str}\\PY{p}{)}\\PY{p}{:} \\PY{n}{names} \\PY{o}{=} \\PY{p}{[}\\PY{n}{names}\\PY{p}{]}\n    \\PY{n}{IS\\PYZus{}R} \\PY{o}{=} \\PY{p}{[}\\PY{n}{names\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{k}{for} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{names}\\PY{p}{]}\n    \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{,} \\PY{n}{mu\\PYZus{}dict} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\n    \\PY{k}{for} \\PY{n}{idx}\\PY{p}{,} \\PY{p}{(}\\PY{n}{input\\PYZus{}}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{)} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{:}\n        \\PY{n}{input\\PYZus{}}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{input\\PYZus{}}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{model}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{,} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{model}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\n        \\PY{n}{mu}\\PY{p}{,} \\PY{n}{\\PYZus{}} \\PY{o}{=} \\PY{n}{model}\\PY{o}{.}\\PY{n}{encoder}\\PY{p}{(}\\PY{n}{input\\PYZus{}}\\PY{p}{)}\n        \\PY{n}{preds} \\PY{o}{=} \\PY{n}{model}\\PY{o}{.}\\PY{n}{classifier}\\PY{p}{(}\\PY{n}{mu}\\PY{p}{)}\n        \\PY{n}{mask} \\PY{o}{=} \\PY{n}{labels} \\PY{o}{==} \\PY{n}{MASK}\n        \\PY{k}{del} \\PY{n}{input\\PYZus{}}\n\n        \\PY{k}{for} \\PY{n}{j}\\PY{p}{,} \\PY{p}{(}\\PY{n}{name}\\PY{p}{,} \\PY{n}{is\\PYZus{}r}\\PY{p}{)} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n+nb}{zip}\\PY{p}{(}\\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n            \\PY{n}{probs} \\PY{o}{=} \\PY{n}{preds}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n            \\PY{n}{label} \\PY{o}{=} \\PY{n}{labels}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{[}\\PY{o}{\\PYZti{}}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{p}{]}\n            \\PY{n}{mask\\PYZus{}here} \\PY{o}{=} \\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{n}{j}\\PY{p}{]}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{mask}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{o}{.}\\PY{n}{expand\\PYZus{}as}\\PY{p}{(}\\PY{n}{mu}\\PY{p}{)}\n            \\PY{n}{mu\\PYZus{}} \\PY{o}{=} \\PY{n}{mu} \\PY{o}{*} \\PY{p}{(}\\PY{o}{\\PYZti{}}\\PY{n}{mask\\PYZus{}here}\\PY{p}{)}\n            \\PY{k}{del} \\PY{n}{mask\\PYZus{}here}\n            \\PY{k}{if} \\PY{n}{is\\PYZus{}r} \\PY{o}{==} \\PY{k+kc}{False}\\PY{p}{:} \\PY{n}{probs} \\PY{o}{=} \\PY{n}{F}\\PY{o}{.}\\PY{n}{sigmoid}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{)}\n            \\PY{n}{probs} \\PY{o}{=} \\PY{n}{probs}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n}{label} \\PY{o}{=} \\PY{n}{label}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n}{mu\\PYZus{}}   \\PY{o}{=} \\PY{n}{mu\\PYZus{}}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\n\n            \\PY{k}{if} \\PY{n}{scale\\PYZus{}dict} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:}\n                \\PY{k}{if} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{.}\\PY{n}{keys}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{min\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n                    \\PY{n}{max\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n                    \\PY{n}{del\\PYZus{}here} \\PY{o}{=} \\PY{n}{max\\PYZus{}here} \\PY{o}{\\PYZhy{}} \\PY{n}{min\\PYZus{}here}\n                    \\PY{n}{label} \\PY{o}{=} \\PY{p}{[}\\PY{n}{l}\\PY{o}{*}\\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{l} \\PY{o+ow}{in} \\PY{n}{label}\\PY{p}{]}\n                    \\PY{n}{probs} \\PY{o}{=} \\PY{p}{[}\\PY{n}{p}\\PY{o}{*}\\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{probs}\\PY{p}{]}\n            \\PY{k}{if} \\PY{n}{idx} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:}\n                \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{,} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{,} \\PY{n}{mu\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\\PY{p}{,} \\PY{n}{mu\\PYZus{}}\n            \\PY{k}{else}\\PY{p}{:}\n                \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{probs}\\PY{p}{;} \\PY{n}{y\\PYZus{}label}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{label}\n                \\PY{n}{mu\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{mu\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{,} \\PY{n}{mu\\PYZus{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{)}\n\n    \\PY{k}{return} \\PY{n}{mu\\PYZus{}dict}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{,} \\PY{n}{y\\PYZus{}label} \n\n\\PY{k}{def} \\PY{n+nf}{model\\PYZus{}predict}\\PY{p}{(}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n}{names}\\PY{p}{,} \\PY{n}{device}\\PY{p}{,} \\PY{n}{model\\PYZus{}type}\\PY{p}{,} \n        \\PY{n}{MASK}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{scale\\PYZus{}back}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{:}\n    \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n+nb}{list}\\PY{p}{)}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{n}{IS\\PYZus{}R}\n    \\PY{k}{else}\\PY{p}{:} \\PY{n}{IS\\PYZus{}R\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{IS\\PYZus{}R}\\PY{p}{]} \\PY{o}{*} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{names}\\PY{p}{)}\n    \\PY{n}{model}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{p}{)}\n    \\PY{n}{y\\PYZus{}probs} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\n    \\PY{k}{for} \\PY{n}{idx}\\PY{p}{,} \\PY{n}{batch\\PYZus{}data} \\PY{o+ow}{in} \\PY{n}{tqdm}\\PY{p}{(}\\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{,} \\PY{n}{total}\\PY{o}{=}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{,} \n                                \\PY{n}{desc}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Predicting...}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{1}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{dataloader error}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{;} \\PY{k}{return}\n        \\PY{k}{elif} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{2}\\PY{p}{:} \n            \\PY{n}{fp}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n}{batch\\PYZus{}data}\\PY{p}{;}    \\PY{n}{labels} \\PY{o}{=} \\PY{n}{labels}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{k}{if} \\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n}{\\PYZus{}}\\PY{p}{,} \\PY{n}{\\PYZus{}}\\PY{p}{,} \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{fp}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{)}\n            \\PY{k}{else}\\PY{p}{:} \\PY{n}{fp} \\PY{o}{=} \\PY{n}{fp}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\\PY{p}{;}     \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{fp}\\PY{p}{)}\n        \\PY{k}{elif} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{batch\\PYZus{}data}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{4}\\PY{p}{:} \n            \\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{n}{bg}\\PY{p}{,}\\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{n}{\\PYZus{}}\\PY{o}{=}\\PY{n}{batch\\PYZus{}data}\\PY{p}{;} \\PY{n}{bg} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{c+c1}{\\PYZsh{} bg, labels = bg.to(device), labels.to(device)}\n            \\PY{n}{n\\PYZus{}feats} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{ndata}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{hv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{e\\PYZus{}feats} \\PY{o}{=} \\PY{n}{bg}\\PY{o}{.}\\PY{n}{edata}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{he}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n            \\PY{n}{pred} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{n}{bg}\\PY{p}{,} \\PY{n}{n\\PYZus{}feats}\\PY{p}{,} \\PY{n}{e\\PYZus{}feats}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} print(pred.shape)}\n        \\PY{c+c1}{\\PYZsh{} print(fp.shape)}\n        \\PY{k}{for} \\PY{n}{j}\\PY{p}{,} \\PY{p}{(}\\PY{n}{name}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R}\\PY{p}{)} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n+nb}{zip}\\PY{p}{(}\\PY{n}{names}\\PY{p}{,} \\PY{n}{IS\\PYZus{}R\\PYZus{}list}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n            \\PY{n}{probs} \\PY{o}{=} \\PY{n}{pred}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\n            \\PY{k}{if} \\PY{n}{IS\\PYZus{}R} \\PY{o}{==} \\PY{k+kc}{False}\\PY{p}{:} \\PY{n}{probs} \\PY{o}{=} \\PY{n}{F}\\PY{o}{.}\\PY{n}{sigmoid}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{)}\n            \\PY{n}{probs} \\PY{o}{=} \\PY{n}{probs}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{numpy}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{tolist}\\PY{p}{(}\\PY{p}{)}\n            \\PY{k}{if} \\PY{n}{scale\\PYZus{}dict} \\PY{o}{!=} \\PY{k+kc}{None} \\PY{o+ow}{and} \\PY{n}{scale\\PYZus{}back} \\PY{o}{==} \\PY{k+kc}{True}\\PY{p}{:} \n                \\PY{k}{if} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{.}\\PY{n}{keys}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{min\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n                    \\PY{n}{max\\PYZus{}here} \\PY{o}{=} \\PY{n}{scale\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n                    \\PY{n}{del\\PYZus{}here} \\PY{o}{=} \\PY{n}{max\\PYZus{}here} \\PY{o}{\\PYZhy{}} \\PY{n}{min\\PYZus{}here}\n                    \\PY{n}{probs} \\PY{o}{=} \\PY{p}{[}\\PY{n}{p} \\PY{o}{*} \\PY{n}{del\\PYZus{}here} \\PY{o}{+} \\PY{n}{min\\PYZus{}here} \\PY{k}{for} \\PY{n}{p} \\PY{o+ow}{in} \\PY{n}{probs}\\PY{p}{]}\n            \\PY{k}{if} \\PY{n}{idx} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}  \\PY{o}{=} \\PY{n}{probs}\n            \\PY{k}{else}\\PY{p}{:}        \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{+}\\PY{o}{=} \\PY{n}{probs}\n    \\PY{k}{return} \\PY{n}{y\\PYZus{}probs}\n\n\n\\PY{k}{class} \\PY{n+nc}{PRED}\\PY{p}{:}\n    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{device}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{device}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{else}\\PY{p}{:} \n            \\PY{n}{cuda} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{cuda}\\PY{o}{.}\\PY{n}{is\\PYZus{}available}\\PY{p}{(}\\PY{p}{)}\n            \\PY{k}{if} \\PY{n}{cuda}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{cuda}\\PY{l+s+s1}{\\PYZsq{}}\n            \\PY{k}{else}\\PY{p}{:}    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{cpu}\\PY{l+s+s1}{\\PYZsq{}}\n        \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config} \\PY{o}{=} \\PY{n}{config}\\PY{p}{;} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{prop\\PYZus{}names}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{scale\\PYZus{}dict}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}           \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{scale\\PYZus{}dict}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{weight\\PYZus{}loss}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}          \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{weight\\PYZus{}loss}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model} \\PY{o}{=} \\PY{n}{init\\PYZus{}model}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{config}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{params\\PYZus{}num} \\PY{o}{=} \\PY{n}{count\\PYZus{}parameters}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Model type: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{,} \\PY{n}{end}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ | Model parameters: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{params\\PYZus{}num}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab} \\PY{o}{=} \\PY{k+kc}{None} \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{vocab}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config} \\PY{k}{else} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{vocab}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{vocab\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab\\PYZus{}type} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}           \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab\\PYZus{}type} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{vocab\\PYZus{}type}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \n        \\PY{c+c1}{\\PYZsh{} initialize model paths and config path}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{encoder\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder\\PYZus{}path} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}          \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{encoder\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{decoder\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder\\PYZus{}path} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}          \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{decoder\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{classifier\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{classifier\\PYZus{}path} \\PY{o}{=} \\PY{k+kc}{None}\n        \\PY{k}{else}\\PY{p}{:}          \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{classifier\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{classifier\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{config\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \n            \\PY{n}{c\\PYZus{}p} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{o}{.}\\PY{n}{split}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{.}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]} \\PY{o}{+} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{.yml}\\PY{l+s+s1}{\\PYZsq{}}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config\\PYZus{}path} \\PY{o}{=} \\PY{n}{c\\PYZus{}p}\\PY{p}{;} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{config\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n}{c\\PYZus{}p}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{config\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{figure\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:}\n            \\PY{n}{figure\\PYZus{}path} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{o}{.}\\PY{n}{split}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{.}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{figure\\PYZus{}path} \\PY{o}{=} \\PY{n}{figure\\PYZus{}path}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{figure\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n}{figure\\PYZus{}path}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{figure\\PYZus{}path} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{figure\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eval\\PYZus{}fn} \\PY{o}{=} \\PY{n}{get\\PYZus{}eval\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}fn} \\PY{o}{=} \\PY{n}{get\\PYZus{}train\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{IS\\PYZus{}R}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{c+c1}{\\PYZsh{} could be list, could be true/false}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{optimizer} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{optim}\\PY{o}{.}\\PY{n}{AdamW}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n                        \\PY{n}{lr}\\PY{o}{=}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{lr}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{weight\\PYZus{}decay}\\PY{o}{=}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{wd}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{stopper} \\PY{o}{=} \\PY{n}{EarlyStopping}\\PY{p}{(}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{lower}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{patience}\\PY{o}{=}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{patience}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{verbose\\PYZus{}freq}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq} \\PY{o}{=} \\PY{l+m+mi}{10}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{verbose\\PYZus{}freq}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{verbose\\PYZus{}freq}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{uncertainty\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{config}\\PY{p}{:} \n            \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{1}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw} \\PY{o}{=} \\PY{k+kc}{False} \\PY{c+c1}{\\PYZsh{} single task}\n            \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw} \\PY{o}{=} \\PY{k+kc}{True}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw} \\PY{o}{=} \\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{uncertainty\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}    \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{inf}\\PY{p}{,} \\PY{l+m+mi}{0}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MAX\\PYZus{}EPOCH}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{MAX\\PYZus{}EPOCH} \\PY{o}{=} \\PY{l+m+mi}{1000}\n        \\PY{k}{else}\\PY{p}{:}          \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{MAX\\PYZus{}EPOCH} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MAX\\PYZus{}EPOCH}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{max\\PYZus{}kl\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{max\\PYZus{}kl\\PYZus{}weight} \\PY{o}{=} \\PY{l+m+mf}{0.5}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{max\\PYZus{}kl\\PYZus{}weight} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{max\\PYZus{}kl\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{k}{if} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{cls\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{cls\\PYZus{}weight} \\PY{o}{=} \\PY{l+m+mf}{0.5}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{cls\\PYZus{}weight} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{cls\\PYZus{}weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \n\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{[}\\PY{p}{]}\n        \n        \\PY{c+c1}{\\PYZsh{} will store the results on test set, if test set == None, leave blank}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}} \n\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{data} \\PY{o}{=} \\PY{n+nb}{dict}\\PY{p}{(}\\PY{n}{config}     \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{,}\n                         \\PY{n}{min\\PYZus{}loss}   \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{p}{,}\n                         \\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{p}{,} \n                         \\PY{n}{train\\PYZus{}dict} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \n                         \\PY{n}{valid\\PYZus{}dict} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,}\n                         \\PY{n}{times\\PYZus{}list} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{,}\n                         \\PY{n}{params\\PYZus{}num} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{params\\PYZus{}num}\\PY{p}{,} \n                         \\PY{n}{performance}\\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\\PY{p}{)}\n    \n    \\PY{k}{def} \\PY{n+nf}{save\\PYZus{}train\\PYZus{}status}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:} \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{data} \\PY{o}{=} \\PY{n+nb}{dict}\\PY{p}{(}\n            \\PY{n}{config} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{,}\n            \\PY{n}{min\\PYZus{}loss} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{p}{,}\n            \\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{p}{,} \n            \\PY{n}{train\\PYZus{}dict} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \n            \\PY{n}{valid\\PYZus{}dict} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,}\n            \\PY{n}{times\\PYZus{}list} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{,}\n            \\PY{n}{params\\PYZus{}num} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{params\\PYZus{}num}\\PY{p}{,} \n            \\PY{n}{performance} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\\PY{p}{)}\n\n        \\PY{k}{with} \\PY{n+nb}{open}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config\\PYZus{}path}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{w}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)} \\PY{k}{as} \\PY{n}{fl}\\PY{p}{:}\n            \\PY{n}{yaml}\\PY{o}{.}\\PY{n}{dump}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{fl}\\PY{p}{,} \\PY{n}{default\\PYZus{}flow\\PYZus{}style}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s1}{\\PYZhy{}\\PYZhy{}\\PYZgt{} Train status saved at}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config\\PYZus{}path}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}encoder}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{encoder\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\\PY{c+c1}{\\PYZsh{} this is VAE or RNN\\PYZus{}pretrain}\n        \\PY{k}{if} \\PY{n}{encoder\\PYZus{}path} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{encoder\\PYZus{}path} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder\\PYZus{}path} \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{encoder}\\PY{o}{.}\\PY{n}{load\\PYZus{}state\\PYZus{}dict}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\n               \\PY{n}{encoder\\PYZus{}path}\\PY{p}{,} \\PY{n}{map\\PYZus{}location}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finish load encoder from}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{encoder\\PYZus{}path}\\PY{p}{)}\n    \n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}decoder}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{decoder\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n}{decoder\\PYZus{}path} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{decoder\\PYZus{}path} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder\\PYZus{}path}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{decoder}\\PY{o}{.}\\PY{n}{load\\PYZus{}state\\PYZus{}dict}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\n               \\PY{n}{decoder\\PYZus{}path}\\PY{p}{,} \\PY{n}{map\\PYZus{}location}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finish load decoder from}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{decoder\\PYZus{}path}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}classifier}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{classifier\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n}{classifier\\PYZus{}path} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{classifier\\PYZus{}path}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{classifier\\PYZus{}path}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{classifier}\\PY{o}{.}\\PY{n}{load\\PYZus{}state\\PYZus{}dict}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\\PY{n}{classifier\\PYZus{}path}\\PY{p}{,} \n                                               \\PY{n}{map\\PYZus{}location}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)} \n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finish load classifier from}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{classifier\\PYZus{}path}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}vae\\PYZus{}pretrain}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{encoder\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{classifier\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}encoder}\\PY{p}{(}\\PY{n}{encoder\\PYZus{}path}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}classifier}\\PY{p}{(}\\PY{n}{classifier\\PYZus{}path}\\PY{p}{)}\n    \n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}vae}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{encoder\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{decoder\\PYZus{}path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}encoder}\\PY{p}{(}\\PY{n}{encoder\\PYZus{}path}\\PY{p}{)}\\PY{p}{;} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}decoder}\\PY{p}{(}\\PY{n}{decoder\\PYZus{}path}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}model}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{AttentiveFP}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \n            \\PY{n}{con} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{o}{.}\\PY{n}{copy}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{con}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{dropout}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{l+m+mi}{0}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model} \\PY{o}{=} \\PY{n}{init\\PYZus{}model}\\PY{p}{(}\\PY{o}{*}\\PY{o}{*}\\PY{n}{con}\\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n}{path} \\PY{o}{==} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n}{path} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{load pretrained model from }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{path}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{load\\PYZus{}state\\PYZus{}dict}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\\PY{n}{path}\\PY{p}{,} \\PY{n}{map\\PYZus{}location}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n    \n    \\PY{k}{def} \\PY{n+nf}{load\\PYZus{}status}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{data}\\PY{p}{)}\\PY{p}{:}\n        \\PY{c+c1}{\\PYZsh{} with open(yml\\PYZus{}file\\PYZus{}path, \\PYZsq{}r\\PYZsq{}) as f:}\n        \\PY{c+c1}{\\PYZsh{}     data = yaml.safe\\PYZus{}load(f)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{data} \\PY{o}{=} \\PY{n}{data}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{config}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZus{}path}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \n        \\PY{c+c1}{\\PYZsh{} self.load\\PYZus{}model(self.config[\\PYZsq{}model\\PYZus{}path\\PYZsq{}])}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{min\\PYZus{}loss}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{best\\PYZus{}epoch}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{train\\PYZus{}dict}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid\\PYZus{}dict}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{times\\PYZus{}list}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{params\\PYZus{}num} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{params\\PYZus{}num}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict} \\PY{o}{=} \\PY{n}{data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{performance}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{finish load data status }\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{verbose}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n}{verbose}\\PY{p}{:}\n            \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Train time: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{)}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\n                  \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{+/\\PYZhy{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{np}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{)}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ ms}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{)}\\PY{p}{,} \\PY{n}{np}\\PY{o}{.}\\PY{n}{std}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{print\\PYZus{}config}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:} \n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{*}\\PY{l+m+mi}{68}\\PY{p}{)}\\PY{p}{;} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{*}\\PY{l+m+mi}{30}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{CONFIG}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{*}\\PY{l+m+mi}{30}\\PY{p}{)}\\PY{p}{;} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{*}\\PY{l+m+mi}{68}\\PY{p}{)}\n        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{config}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}             \\PY{n+nb}{print}\\PY{p}{(}\\PY{n}{i}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{j}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{*}\\PY{l+m+mi}{68}\\PY{p}{)}\n\n    \\PY{k}{def} \\PY{n+nf}{eval}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{ver}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n}{ver}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{print\\PYZus{}config}\\PY{p}{(}\\PY{p}{)}\n        \n        \\PY{k}{if} \\PY{n}{path} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}model}\\PY{p}{(}\\PY{n}{path}\\PY{p}{)}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}model}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}vae\\PYZus{}pretrain}\\PY{p}{(}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n}{ver}\\PY{p}{:}\n            \\PY{c+c1}{\\PYZsh{} if self.weight\\PYZus{}loss != None: print(\\PYZsq{}task weight: \\PYZsq{},self.weight\\PYZus{}loss)}\n            \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Model parameters: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{count\\PYZus{}parameters}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)}\\PY{p}{)}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{epoch }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{ \\PYZhy{}\\PYZgt{} min loss }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n            \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                      \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \n        \\PY{n}{performance}\\PY{p}{,} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eval\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,} \\PY{n}{epoch}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{optimizer}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \n            \\PY{n}{MASK}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,} \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,}\n            \\PY{c+c1}{\\PYZsh{} weight\\PYZus{}loss=self.weight\\PYZus{}loss, \\PYZsh{} should not use the weightloss}\n            \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\n        \\PY{k}{return} \\PY{n}{performance}\\PY{p}{,} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\n\n\n    \\PY{k}{def} \\PY{n+nf}{train\\PYZus{}VAE}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n}{val\\PYZus{}loader}\\PY{p}{,} \\PY{n}{test\\PYZus{}loader}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \n                 \\PY{n}{data\\PYZus{}df}\\PY{o}{=}\\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{sample\\PYZus{}num}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{latent\\PYZus{}eval\\PYZus{}freq}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{:}\n\\PY{+w}{        }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n\\PY{l+s+sd}{        Aim: Train Variational AutoEncoder (VAE), evaluate latent space }\n\\PY{l+s+sd}{        params: }\n\\PY{l+s+sd}{            loader:       DataLoader, for train}\n\\PY{l+s+sd}{            val\\PYZus{}loader:   DataLoader, for valid, save model based on its loss}\n\\PY{l+s+sd}{            test\\PYZus{}loader:  DataLoader, for test,  final performance evaluation}\n\\PY{l+s+sd}{            data\\PYZus{}df: pd.DataFrame, if no empty, will plot PCA on latent sapce}\n\\PY{l+s+sd}{            sample\\PYZus{}num:       int, the number of entries sampled from data\\PYZus{}df}\n\\PY{l+s+sd}{            latent\\PYZus{}eval\\PYZus{}freq: int, the frequency of plot PCA and save figures}\n\\PY{l+s+sd}{        Return performance: dict, performance on test loader}\n\\PY{l+s+sd}{                            performance[name]: metrics nums evaluated on name}\n\\PY{l+s+sd}{                            performance[loss]: total loss of VAE for test set }\n\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n        \n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{1}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw} \\PY{o}{=} \\PY{k+kc}{False} \n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:} \n            \\PY{n}{m\\PYZus{}w} \\PY{o}{=} \\PY{n}{MTLoss}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{)}\\PY{p}{,} \\PY{n}{device}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)} \n            \\PY{n}{optimizer} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{optim}\\PY{o}{.}\\PY{n}{SGD}\\PY{p}{(}\\PY{n}{m\\PYZus{}w}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{)}\\PY{p}{;} \\PY{n}{m\\PYZus{}w}\\PY{o}{.}\\PY{n}{train}\\PY{p}{(}\\PY{p}{)}\n\n        \\PY{c+c1}{\\PYZsh{} self.optimizer = torch.optim.AdamW(}\n        \\PY{c+c1}{\\PYZsh{}     get\\PYZus{}optim\\PYZus{}params(self.model), lr=lr\\PYZus{}start)}\n        \\PY{c+c1}{\\PYZsh{} lr\\PYZus{}annealer = CosineAnnealingLRWithRestart(self.optimizer)}\n        \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{start\\PYZus{}epoch} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\n        \\PY{n}{min\\PYZus{}total\\PYZus{}loss} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{inf}\\PY{p}{;} \\PY{n}{train\\PYZus{}total}\\PY{p}{,} \\PY{n}{valid\\PYZus{}total} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{p}{\\PYZob{}}\\PY{p}{\\PYZcb{}} \n        \\PY{k}{for} \\PY{n}{epoch} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{start\\PYZus{}epoch}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{MAX\\PYZus{}EPOCH}\\PY{p}{)}\\PY{p}{:}\n            \n            \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{\\PYZpc{}} \\PY{n}{latent\\PYZus{}eval\\PYZus{}freq} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:}\n                \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{data\\PYZus{}df}\\PY{p}{)} \\PY{o}{\\PYZgt{}} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} plot PCA before training one epoch }\n                    \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{\\PYZpc{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq} \\PY{o}{==} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{n}{plot\\PYZus{}show} \\PY{o}{=} \\PY{k+kc}{True}\n                    \\PY{k}{else}\\PY{p}{:} \\PY{n}{plot\\PYZus{}show} \\PY{o}{=} \\PY{k+kc}{False}\n                    \\PY{n}{tmp\\PYZus{}} \\PY{o}{=} \\PY{n}{data\\PYZus{}df}\\PY{o}{.}\\PY{n}{sample}\\PY{p}{(}\\PY{n}{n}\\PY{o}{=}\\PY{n}{sample\\PYZus{}num}\\PY{p}{)}\\PY{o}{.}\\PY{n}{reset\\PYZus{}index}\\PY{p}{(}\\PY{n}{drop}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n                    \\PY{n}{tmp\\PYZus{}} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{encoder}\\PY{o}{.}\\PY{n}{cal\\PYZus{}mu}\\PY{p}{(}\\PY{n}{tmp\\PYZus{}}\\PY{p}{)}\n                    \\PY{n}{header\\PYZus{}here} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{encoder}\\PY{o}{.}\\PY{n}{header}\n                    \\PY{k}{for} \\PY{n}{n} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{:} \n                        \\PY{c+c1}{\\PYZsh{} there might be MASK values in tmp, delete entire row}\n                        \\PY{n}{tmp} \\PY{o}{=} \\PY{n}{tmp\\PYZus{}}\\PY{p}{[}\\PY{n}{tmp\\PYZus{}}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]}\\PY{o}{!=} \\PY{n}{MASK}\\PY{p}{]}\n                        \\PY{n}{plot\\PYZus{}dim\\PYZus{}reduced}\\PY{p}{(}\\PY{n}{tmp}\\PY{p}{[}\\PY{n}{header\\PYZus{}here}\\PY{p}{]}\\PY{p}{,}\\PY{n}{tmp}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]}\\PY{p}{,}\\PY{n}{names\\PYZus{}dict}\\PY{p}{[}\\PY{n}{n}\\PY{p}{]}\\PY{p}{,}\n                        \\PY{n}{dim\\PYZus{}reduct}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PCA}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{title} \\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PCA on }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{n}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ in latent space}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                        \\PY{n}{savepath}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{figure\\PYZus{}path}\\PY{p}{,} \n                        \\PY{n}{savename}\\PY{o}{=}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PCA\\PYZus{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{n}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZus{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{.png}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{plot\\PYZus{}show}\\PY{o}{=}\\PY{n}{plot\\PYZus{}show}\\PY{p}{)}\n\n            \\PY{n}{inc} \\PY{o}{=} \\PY{p}{(}\\PY{n}{epoch} \\PY{o}{\\PYZhy{}} \\PY{n}{start\\PYZus{}epoch}\\PY{p}{)} \\PY{o}{/} \\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{MAX\\PYZus{}EPOCH} \\PY{o}{\\PYZhy{}} \\PY{n}{start\\PYZus{}epoch}\\PY{p}{)}\n            \\PY{n}{kl\\PYZus{}weight} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{max\\PYZus{}kl\\PYZus{}weight} \\PY{o}{*} \\PY{n}{inc}\n            \\PY{c+c1}{\\PYZsh{} cls\\PYZus{}weight = self.cls\\PYZus{}weight}\n            \\PY{n}{cls\\PYZus{}weight} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{cls\\PYZus{}weight} \\PY{o}{*} \\PY{n}{inc}\n            \\PY{n}{t} \\PY{o}{=} \\PY{n}{time}\\PY{o}{.}\\PY{n}{time}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n}{score}\\PY{p}{,} \\PY{n}{l}\\PY{p}{,} \\PY{n}{r} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,}\n                                        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,} \\PY{n}{kl\\PYZus{}weight}\\PY{p}{,} \n                                        \\PY{n}{cls\\PYZus{}weight}\\PY{p}{,} \\PY{n}{epoch}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{optimizer}\\PY{p}{,} \n                                        \\PY{n}{scale\\PYZus{}dict}  \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,}\n                                        \\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{,}\n                                        \\PY{n}{model\\PYZus{}type}  \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\n            \\PY{n}{train\\PYZus{}time} \\PY{o}{=} \\PY{p}{(}\\PY{n}{time}\\PY{o}{.}\\PY{n}{time}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n}{t}\\PY{p}{)} \\PY{o}{*} \\PY{l+m+mi}{1000} \\PY{o}{/} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{o}{.}\\PY{n}{dataset}\\PY{p}{)}\n            \n            \\PY{n}{val\\PYZus{}s}\\PY{p}{,} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{label} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}fn}\\PY{p}{(}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,} \\PY{n}{val\\PYZus{}loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,} \n                \\PY{n}{kl\\PYZus{}weight}\\PY{p}{,} \\PY{n}{cls\\PYZus{}weight}\\PY{p}{,} \\PY{n}{epoch}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,}\n                \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{,} \\PY{n}{model\\PYZus{}type}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{)}\n            \n            \n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{train\\PYZus{}time}\\PY{p}{)}\n            \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:}\n                \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\n                \\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{n}{m\\PYZus{}w}\\PY{p}{(}\\PY{n}{l}\\PY{p}{,} \\PY{n}{r}\\PY{p}{)}\n                \\PY{n}{total\\PYZus{}loss}\\PY{o}{.}\\PY{n}{backward}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{p}{)}\n            \n\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{score}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{;} \\PY{n}{train\\PYZus{}total}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{score}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{;} \\PY{n}{valid\\PYZus{}total}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\n            \\PY{k}{if} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]} \\PY{o}{\\PYZlt{}} \\PY{n}{min\\PYZus{}total\\PYZus{}loss}\\PY{p}{:}\n                \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{} SAVE MODEL: loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{min\\PYZus{}total\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ \\PYZhy{}\\PYZgt{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                      \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{end}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ | }\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n                \\PY{n}{min\\PYZus{}total\\PYZus{}loss} \\PY{o}{=} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{;}  \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n}{epoch}\n                \\PY{n}{torch}\\PY{o}{.}\\PY{n}{save}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{state\\PYZus{}dict}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n\n            \\PY{k}{if} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]} \\PY{o}{\\PYZlt{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{p}{:} \n                \\PY{c+c1}{\\PYZsh{} use cls loss as save indicator of enc, dec cls model}\n                \\PY{c+c1}{\\PYZsh{} seperate save to simplify later load pretrain models}\n                \\PY{c+c1}{\\PYZsh{} load model for MLP, just need to load encoder for FP}\n                \\PY{c+c1}{\\PYZsh{} load model for RNN\\PYZus{}pretrain, no need to load decoder}\n                \\PY{c+c1}{\\PYZsh{} load model for VAE on different tasks, no classifier}\n                \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsh{}\\PYZsh{} SAVE Enc, Dec, Cls: classify loss:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                      \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ \\PYZhy{}\\PYZgt{} }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                      \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{| runtime: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}time}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ ms}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss} \\PY{o}{=} \\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\n                \\PY{n}{torch}\\PY{o}{.}\\PY{n}{save}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{encoder}\\PY{o}{.}\\PY{n}{state\\PYZus{}dict}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder\\PYZus{}path}\\PY{p}{)}\n                \\PY{n}{torch}\\PY{o}{.}\\PY{n}{save}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{decoder}\\PY{o}{.}\\PY{n}{state\\PYZus{}dict}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder\\PYZus{}path}\\PY{p}{)}\n                \\PY{n}{torch}\\PY{o}{.}\\PY{n}{save}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{classifier}\\PY{o}{.}\\PY{n}{state\\PYZus{}dict}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \n                           \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{classifier\\PYZus{}path}\\PY{p}{)}\n            \n            \n\n            \\PY{n}{early\\PYZus{}stop} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{stopper}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{n}{val\\PYZus{}s}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} cls loss}\n            \n            \n            \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{\\PYZpc{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq} \\PY{o}{==} \\PY{l+m+mi}{0} \\PY{o+ow}{and} \\PY{n}{epoch} \\PY{o}{!=} \\PY{l+m+mi}{0}\\PY{p}{:}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{p}{)}\n                \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:}                 \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{different task weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \n                            \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}:.3f\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{i}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Classify loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n                \n                \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n}{train\\PYZus{}total}\\PY{p}{,} \\PY{n}{valid\\PYZus{}total}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Total loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n                \n                \\PY{n}{eval\\PYZus{}dict}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{,} \\PY{n}{label}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,}  \\PY{n}{IS\\PYZus{}R}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\n            \n            \\PY{k}{if} \\PY{n}{early\\PYZus{}stop}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{early stop}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{;} \\PY{k}{break}\n\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finished training}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{data\\PYZus{}df}\\PY{p}{)} \\PY{o}{\\PYZgt{}} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} evaluated PCA on data\\PYZus{}df, create gif}\n            \\PY{k}{for} \\PY{n}{n} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{:} \n                \\PY{n}{images} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n                \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{epoch}\\PY{o}{+}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{file\\PYZus{}name} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{figure\\PYZus{}path} \\PY{o}{+} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{/PCA\\PYZus{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{n}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZus{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{i}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{.png}\\PY{l+s+s1}{\\PYZsq{}}\n                    \\PY{c+c1}{\\PYZsh{} print(file\\PYZus{}name)}\n                    \\PY{k}{for} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{:} \n                        \\PY{k}{try}\\PY{p}{:} \\PY{n}{images}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{imageio}\\PY{o}{.}\\PY{n}{imread}\\PY{p}{(}\\PY{n}{file\\PYZus{}name}\\PY{p}{)}\\PY{p}{)}\n                        \\PY{k}{except}\\PY{p}{:} \\PY{k}{pass}\n                \\PY{n}{gif\\PYZus{}path} \\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{figure\\PYZus{}path}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZus{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{n}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{.gif}\\PY{l+s+s1}{\\PYZsq{}}\n                \\PY{n}{imageio}\\PY{o}{.}\\PY{n}{mimsave}\\PY{p}{(}\\PY{n}{gif\\PYZus{}path}\\PY{p}{,} \\PY{n}{images}\\PY{p}{,} \\PY{n}{duration}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n                \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{save gif at: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{gif\\PYZus{}path}\\PY{p}{)}\n                \\PY{c+c1}{\\PYZsh{} from IPython.display import Image}\n                \\PY{n}{display}\\PY{p}{(}\\PY{n}{IPython}\\PY{o}{.}\\PY{n}{display}\\PY{o}{.}\\PY{n}{Image}\\PY{p}{(}\\PY{n}{data}\\PY{o}{=}\\PY{n+nb}{open}\\PY{p}{(}\\PY{n}{gif\\PYZus{}path}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{rb}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{read}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n                        \\PY{n+nb}{format}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{png}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{)}\n\n        \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{save\\PYZus{}train\\PYZus{}status}\\PY{p}{(}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} status yml is saved iff train finished}\n        \\PY{c+c1}{\\PYZsh{} print(\\PYZsq{}task weight\\PYZsq{}, }\n        \\PY{c+c1}{\\PYZsh{}                 [\\PYZsq{}\\PYZob{}:.3f\\PYZcb{}\\PYZsq{}.format(i) for i in self.weight\\PYZus{}loss])}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Model parameters: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{count\\PYZus{}parameters}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{best epoch: }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{, min loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n}{train\\PYZus{}cls}\\PY{p}{,} \\PY{n}{valid\\PYZus{}cls}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Classify loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \n        \\PY{k}{if} \\PY{n}{test\\PYZus{}loader} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} evaluate test set}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\\PY{p}{,}\\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{n}{\\PYZus{}} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{n}{test\\PYZus{}loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{save\\PYZus{}train\\PYZus{}status}\\PY{p}{(}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} update train status with test performance}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finished evaluate test performance, outputs performance dict}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\n\n    \\PY{k}{def} \\PY{n+nf}{predict}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{smile\\PYZus{}list}\\PY{p}{:}\\PY{n+nb}{list}\\PY{p}{,} \\PY{n}{return\\PYZus{}probs}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,} \\PY{n}{scale\\PYZus{}back}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{:}\n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}vae\\PYZus{}pretrain}\\PY{p}{(}\\PY{p}{)}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{load\\PYZus{}model}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n        \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{smile\\PYZus{}list}\\PY{p}{,} \\PY{n+nb}{str}\\PY{p}{)}\\PY{p}{:} \\PY{n}{smile\\PYZus{}list} \\PY{o}{=} \\PY{p}{[}\\PY{n}{smile\\PYZus{}list}\\PY{p}{]}\n        \\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{df}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Drug}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n}{smile\\PYZus{}list} \n        \n        \\PY{k}{for} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{:}\n            \\PY{n}{df}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{p}{[}\\PY{n}{MASK}\\PY{p}{]} \\PY{o}{*} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{smile\\PYZus{}list}\\PY{p}{)}\n        \n        \\PY{n}{prm} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{batch\\PYZus{}size}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+m+mi}{64}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{shuffle}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k+kc}{False}\\PY{p}{,} \n               \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{drop\\PYZus{}last}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{k+kc}{False}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{num\\PYZus{}workers}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+m+mi}{0}\\PY{p}{\\PYZcb{}}\n        \\PY{n}{loader} \\PY{o}{=} \\PY{n}{get\\PYZus{}loader}\\PY{p}{(}\\PY{n}{df}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,} \\PY{n}{prm}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{,}\n                            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab\\PYZus{}type}\\PY{p}{)}\n        \n        \\PY{n}{y\\PYZus{}probs} \\PY{o}{=} \\PY{n}{model\\PYZus{}predict}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,} \\PY{n}{loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{p}{,} \\PY{n}{MASK}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,} \\PY{n}{scale\\PYZus{}back}\\PY{p}{)}\n        \\PY{k}{for} \\PY{n}{name} \\PY{o+ow}{in} \\PY{n}{y\\PYZus{}probs}\\PY{o}{.}\\PY{n}{keys}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n            \\PY{n}{is\\PYZus{}r} \\PY{o}{=} \\PY{n}{names\\PYZus{}dict}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\n            \\PY{k}{if} \\PY{n}{is\\PYZus{}r} \\PY{o}{==} \\PY{k+kc}{False} \\PY{o+ow}{and} \\PY{n}{return\\PYZus{}probs}\\PY{o}{==}\\PY{k+kc}{False}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} cls, prob \\PYZhy{}\\PYZgt{} pred}\n                \\PY{n}{df}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{get\\PYZus{}preds}\\PY{p}{(}\\PY{l+m+mf}{0.5}\\PY{p}{,} \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{p}{)}\n            \\PY{k}{else}\\PY{p}{:} \\PY{n}{df}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]} \\PY{o}{=} \\PY{n}{y\\PYZus{}probs}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\n        \\PY{k}{return} \\PY{n}{df}\n\n    \\PY{k}{def} \\PY{n+nf}{train}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{data\\PYZus{}loader}\\PY{p}{,} \\PY{n}{val\\PYZus{}loader}\\PY{p}{,} \\PY{n}{test\\PYZus{}loader}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,}\n                 \\PY{n}{data\\PYZus{}df}\\PY{o}{=}\\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{sample\\PYZus{}num}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{latent\\PYZus{}eval\\PYZus{}freq}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{:} \n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch} \\PY{o}{!=} \\PY{l+m+mi}{0}\\PY{p}{:}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{load\\PYZus{}state\\PYZus{}dict}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{,} \\PY{n}{map\\PYZus{}location}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n        \\PY{k}{else}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Start training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{...}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} if \\PYZsq{}MAX\\PYZus{}EPOCH\\PYZsq{} not in self.config: MAX\\PYZus{}EPOCH = 1000}\n        \\PY{c+c1}{\\PYZsh{} else:          MAX\\PYZus{}EPOCH = self.config[\\PYZsq{}MAX\\PYZus{}EPOCH\\PYZsq{}]}\n        \\PY{c+c1}{\\PYZsh{} single task, no need uncertainty weight}\n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{VAE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \n            \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}VAE}\\PY{p}{(}\\PY{n}{data\\PYZus{}loader}\\PY{p}{,} \\PY{n}{val\\PYZus{}loader}\\PY{p}{,} \\PY{n}{test\\PYZus{}loader}\\PY{p}{,}\n                                  \\PY{n}{data\\PYZus{}df}\\PY{p}{,} \\PY{n}{sample\\PYZus{}num}\\PY{p}{,} \\PY{n}{latent\\PYZus{}eval\\PYZus{}freq}\\PY{p}{)}\n\n        \\PY{k}{if} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{)} \\PY{o}{==} \\PY{l+m+mi}{1}\\PY{p}{:} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw} \\PY{o}{=} \\PY{k+kc}{False} \n        \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:} \n            \\PY{n}{m\\PYZus{}w} \\PY{o}{=} \\PY{n}{MTLoss}\\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{)}\\PY{p}{,} \\PY{n}{device}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{)} \n            \\PY{n}{optimizer} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{optim}\\PY{o}{.}\\PY{n}{SGD}\\PY{p}{(}\\PY{n}{m\\PYZus{}w}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{)}\\PY{p}{;} \\PY{n}{m\\PYZus{}w}\\PY{o}{.}\\PY{n}{train}\\PY{p}{(}\\PY{p}{)}\n    \n        \n        \\PY{k}{for} \\PY{n}{epoch} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{MAX\\PYZus{}EPOCH}\\PY{p}{)}\\PY{p}{:}\n            \\PY{n}{t} \\PY{o}{=} \\PY{n}{time}\\PY{o}{.}\\PY{n}{time}\\PY{p}{(}\\PY{p}{)}\n            \\PY{n}{score}\\PY{p}{,} \\PY{n}{l}\\PY{p}{,} \\PY{n}{r}  \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,} \\PY{n}{data\\PYZus{}loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,}\n                                  \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,} \\PY{n}{epoch}\\PY{p}{,}\n                                  \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{optimizer}\\PY{p}{,} \\PY{n}{scale\\PYZus{}dict}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,}\n                                  \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{)}\n            \\PY{n}{train\\PYZus{}time} \\PY{o}{=} \\PY{p}{(}\\PY{n}{time}\\PY{o}{.}\\PY{n}{time}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n}{t}\\PY{p}{)} \\PY{o}{*} \\PY{l+m+mi}{1000} \\PY{o}{/} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{data\\PYZus{}loader}\\PY{o}{.}\\PY{n}{dataset}\\PY{p}{)}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{times\\PYZus{}list}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{train\\PYZus{}time}\\PY{p}{)}\n\n            \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} uncertainty weight training}\n                \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\n                \\PY{n}{total\\PYZus{}loss}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss} \\PY{o}{=} \\PY{n}{m\\PYZus{}w}\\PY{p}{(}\\PY{n}{l}\\PY{p}{,} \\PY{n}{r}\\PY{p}{)}\n                \\PY{n}{total\\PYZus{}loss}\\PY{o}{.}\\PY{n}{backward}\\PY{p}{(}\\PY{p}{)}\\PY{p}{;} \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{p}{)}\n            \\PY{c+c1}{\\PYZsh{} do not use weight loss for val?  }\n            \\PY{n}{val\\PYZus{}score}\\PY{p}{,} \\PY{n}{probs}\\PY{p}{,} \\PY{n}{labels} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}fn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{,}  \\PY{n}{val\\PYZus{}loader}\\PY{p}{,}\n                                       \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{,}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{device}\\PY{p}{,}\n                                       \\PY{n}{epoch}\\PY{p}{,}   \\PY{n}{scale\\PYZus{}dict} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{scale\\PYZus{}dict}\\PY{p}{,}\n                                       \\PY{n}{weight\\PYZus{}loss}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{)} \n            \n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{score}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{[}\\PY{n}{epoch}\\PY{p}{]} \\PY{o}{=} \\PY{n}{val\\PYZus{}score}\n            \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Epoch:}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ [Train] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{score}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ |}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                  \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{[Valid] Loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{val\\PYZus{}score}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{end}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+se}{\\PYZbs{}t}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n            \\PY{n}{early\\PYZus{}stop} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{stopper}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{n}{val\\PYZus{}score}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)}\n            \n            \\PY{k}{if} \\PY{n}{val\\PYZus{}score} \\PY{o}{\\PYZlt{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} loss drop, save model}\n                \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{SAVE MODEL: loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ \\PYZhy{}\\PYZgt{} }\\PY{l+s+s1}{\\PYZsq{}}\n                      \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{val\\PYZus{}score}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ | runtime: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{train\\PYZus{}time}\\PY{l+s+si}{:}\\PY{l+s+s1}{.3f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{ ms}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss} \\PY{o}{=} \\PY{n}{val\\PYZus{}score}\\PY{p}{;}  \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch} \\PY{o}{=} \\PY{n}{epoch}\n                \\PY{n}{torch}\\PY{o}{.}\\PY{n}{save}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{o}{.}\\PY{n}{state\\PYZus{}dict}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n\n            \\PY{k}{if} \\PY{n}{epoch} \\PY{o}{\\PYZpc{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{verbose\\PYZus{}freq} \\PY{o}{==} \\PY{l+m+mi}{0} \\PY{o+ow}{and} \\PY{n}{epoch} \\PY{o}{!=} \\PY{l+m+mi}{0}\\PY{p}{:}\n                \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{p}{)}\n                \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{uw}\\PY{p}{:}                 \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{different task weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \n                           \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}:.3f\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{i}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                    \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n                \\PY{n}{eval\\PYZus{}dict}\\PY{p}{(}\\PY{n}{probs}\\PY{p}{,} \\PY{n}{labels}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{prop\\PYZus{}names}\\PY{p}{,}  \\PY{n}{IS\\PYZus{}R}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{IS\\PYZus{}R}\\PY{p}{)}\n                \n            \\PY{k}{if} \\PY{n}{early\\PYZus{}stop}\\PY{p}{:} \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{early stop}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{;} \\PY{k}{break}\n\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finished training}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{save\\PYZus{}train\\PYZus{}status}\\PY{p}{(}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} status yml file is saved iff train finished}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{task weight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \n                        \\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}:.3f\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{i}\\PY{p}{)} \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weight\\PYZus{}loss}\\PY{p}{]}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Model parameters: }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{count\\PYZus{}parameters}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model}\\PY{p}{)}\\PY{p}{)}\n        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{get\\PYZus{}runtime}\\PY{p}{(}\\PY{p}{)}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{best epoch: }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{best\\PYZus{}epoch}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{, min loss: }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{min\\PYZus{}loss}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{n}{plot\\PYZus{}loss}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{train\\PYZus{}dict}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{valid\\PYZus{}dict}\\PY{p}{,} \\PY{n}{name}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{valid}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n                  \\PY{n}{title\\PYZus{}name}\\PY{o}{=} \\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{loss during training }\\PY{l+s+si}{\\PYZob{}}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}type}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \n        \\PY{k}{if} \\PY{n}{test\\PYZus{}loader} \\PY{o}{!=} \\PY{k+kc}{None}\\PY{p}{:} \\PY{c+c1}{\\PYZsh{} evaluate test set}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\\PY{p}{,}\\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{n}{\\PYZus{}} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{n}{test\\PYZus{}loader}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{model\\PYZus{}path}\\PY{p}{)}\n            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{save\\PYZus{}train\\PYZus{}status}\\PY{p}{(}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} update status yml with test performance}\n        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Finished evaluate test performance, outputs performance dict}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{performance\\PYZus{}dict}\n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_=train_mt(names_M5, 'chemBERTa', 'M5/uw', 3, retrain=False, uw=True, batch_size=128, ver_freq=5)\n",
        "_=train_mt(names_A3, 'chemBERTa', 'A3/uw', 3, retrain=False, uw=True, batch_size=128, ver_freq=5)\n",
        "_=train_mt(names_T3, 'chemBERTa', 'T3/uw', 3, retrain=False, uw=True, batch_size=128, ver_freq=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG1BV9u8MLL0",
        "outputId": "b674cf87-af27-444b-81c9-1cbf891089b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run # 0 for chemBERTa MT\t | save dir:  M5/uw/chemBERTa_MT_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa MT\t | save dir:  M5/uw/chemBERTa_MT_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa MT\t | save dir:  M5/uw/chemBERTa_MT_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** CYP2C19_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.803$\\pm$0.023  &0.803$\\pm$0.025  &0.774$\\pm$0.018  &0.806$\\pm$0.045  &0.801$\\pm$0.015  &0.789$\\pm$0.029  &0.878$\\pm$0.016  &0.606$\\pm$0.048  &0.851$\\pm$0.013  \n",
            " idx 1: &0.823            &0.823            &0.797            &0.824            &0.822            &0.810            &0.890            &0.644            &0.857            \n",
            "\n",
            "******************** CYP2D6_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.854$\\pm$0.014  &0.711$\\pm$0.010  &0.658$\\pm$0.086  &0.485$\\pm$0.047  &0.938$\\pm$0.028  &0.552$\\pm$0.006  &0.841$\\pm$0.009  &0.479$\\pm$0.026  &0.616$\\pm$0.029  \n",
            " idx 1: &0.836            &0.725            &0.559            &0.549            &0.901            &0.554            &0.828            &0.454            &0.584            \n",
            "\n",
            "******************** CYP3A4_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.754$\\pm$0.003  &0.746$\\pm$0.008  &0.705$\\pm$0.011  &0.696$\\pm$0.037  &0.795$\\pm$0.021  &0.700$\\pm$0.014  &0.835$\\pm$0.008  &0.493$\\pm$0.011  &0.764$\\pm$0.011  \n",
            " idx 1: &0.750            &0.734            &0.718            &0.647            &0.822            &0.681            &0.825            &0.478            &0.749            \n",
            "\n",
            "******************** CYP1A2_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.830$\\pm$0.021  &0.833$\\pm$0.019  &0.792$\\pm$0.037  &0.874$\\pm$0.015  &0.792$\\pm$0.051  &0.830$\\pm$0.015  &0.908$\\pm$0.010  &0.666$\\pm$0.036  &0.892$\\pm$0.014  \n",
            " idx 1: &0.846            &0.846            &0.826            &0.854            &0.839            &0.839            &0.913            &0.692            &0.899            \n",
            "\n",
            "******************** CYP2C9_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.797$\\pm$0.034  &0.787$\\pm$0.025  &0.686$\\pm$0.059  &0.757$\\pm$0.012  &0.818$\\pm$0.052  &0.718$\\pm$0.032  &0.863$\\pm$0.015  &0.564$\\pm$0.057  &0.739$\\pm$0.019  \n",
            " idx 1: &0.819            &0.807            &0.717            &0.769            &0.844            &0.742            &0.878            &0.604            &0.754            \n",
            "\n",
            "******************** CYP2C19_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.823   &0.890   &0.857   \n",
            "******************** CYP2D6_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.836   &0.828   &0.584   \n",
            "******************** CYP3A4_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.750   &0.825   &0.749   \n",
            "******************** CYP1A2_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.846   &0.913   &0.899   \n",
            "******************** CYP2C9_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.819   &0.878   &0.754   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa MT\t | save dir:  A3/uw/chemBERTa_MT_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa MT\t | save dir:  A3/uw/chemBERTa_MT_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa MT\t | save dir:  A3/uw/chemBERTa_MT_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** PAMPA_NCATS ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.840$\\pm$0.009  &0.605$\\pm$0.076  &0.877$\\pm$0.023  &0.946$\\pm$0.043  &0.265$\\pm$0.194  &0.909$\\pm$0.008  &0.713$\\pm$0.007  &nan$\\pm$nan  &0.895$\\pm$0.011  \n",
            " idx 0: &0.845            &0.500            &0.845            &1.000            &0.000            &0.916            &0.703            &nan            &0.879            \n",
            "\n",
            "******************** Lipophilicity_AstraZeneca ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.567$\\pm$0.045  &0.580$\\pm$0.102  &0.758$\\pm$0.068  &0.608$\\pm$0.069  &0.786$\\pm$0.046  &0.771$\\pm$0.037  \n",
            " idx 0: &0.579            &0.593            &0.770            &0.599            &0.793            &0.773            \n",
            "\n",
            "******************** Solubility_AqSolDB ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.884$\\pm$0.135  &1.863$\\pm$0.852  &1.332$\\pm$0.297  &0.657$\\pm$0.157  &0.821$\\pm$0.081  &0.822$\\pm$0.065  \n",
            " idx 0: &0.811            &1.314            &1.146            &0.758            &0.874            &0.864            \n",
            "\n",
            "******************** PAMPA_NCATS ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.845   &0.703   &0.879   \n",
            "******************** Lipophilicity_AstraZeneca ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.579   &0.770   &0.599   \n",
            "******************** Solubility_AqSolDB ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.811   &1.146   &0.758   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa MT\t | save dir:  T3/uw/chemBERTa_MT_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa MT\t | save dir:  T3/uw/chemBERTa_MT_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa MT\t | save dir:  T3/uw/chemBERTa_MT_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** hERG_Karim ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.797$\\pm$0.014  &0.797$\\pm$0.014  &0.779$\\pm$0.038  &0.834$\\pm$0.035  &0.759$\\pm$0.060  &0.804$\\pm$0.006  &0.875$\\pm$0.010  &0.597$\\pm$0.025  &0.872$\\pm$0.018  \n",
            " idx 1: &0.816            &0.816            &0.833            &0.790            &0.842            &0.811            &0.882            &0.633            &0.885            \n",
            "\n",
            "******************** AMES ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.795$\\pm$0.022  &0.800$\\pm$0.016  &0.863$\\pm$0.029  &0.748$\\pm$0.080  &0.851$\\pm$0.048  &0.797$\\pm$0.036  &0.857$\\pm$0.010  &0.602$\\pm$0.026  &0.880$\\pm$0.006  \n",
            " idx 1: &0.808            &0.811            &0.852            &0.787            &0.834            &0.818            &0.866            &0.618            &0.874            \n",
            "\n",
            "******************** LD50_Zhu ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.472$\\pm$0.012  &0.419$\\pm$0.026  &0.647$\\pm$0.020  &0.531$\\pm$0.029  &0.752$\\pm$0.015  &0.720$\\pm$0.015  \n",
            " idx 1: &0.487            &0.424            &0.651            &0.525            &0.746            &0.703            \n",
            "\n",
            "******************** hERG_Karim ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.816   &0.882   &0.885   \n",
            "******************** AMES ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.808   &0.866   &0.874   \n",
            "******************** LD50_Zhu ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.487   &0.651   &0.525   \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names_all_test = [\n",
        " 'AMES',\n",
        " 'CYP2C9_Substrate_CarbonMangels',\n",
        " 'CYP2D6_Substrate_CarbonMangels',\n",
        " 'CYP3A4_Substrate_CarbonMangels',\n",
        " 'DILI',\n",
        " 'Skin Reaction',\n",
        " 'Carcinogens_Lagunin',\n",
        " 'ClinTox']"
      ],
      "metadata": {
        "id": "QTeavmQF_tws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_bad = []\n",
        "for name in names_all[:-2]:\n",
        "    try:\n",
        "        train_mt(name, 'chemBERTa', f'ST/{name}', 3, retrain=False, uw=False)\n",
        "    except:\n",
        "        names_bad.append(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GdNhdbs_svB",
        "outputId": "75c17499-c786-4455-8c07-9d471bb33094"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Caco2_Wang/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Caco2_Wang/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Caco2_Wang/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** Caco2_Wang ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.371$\\pm$0.010  &0.228$\\pm$0.014  &0.477$\\pm$0.014  &0.641$\\pm$0.021  &0.809$\\pm$0.007  &0.748$\\pm$0.007  \n",
            " idx 0: &0.361            &0.216            &0.465            &0.660            &0.816            &0.758            \n",
            "\n",
            "******************** Caco2_Wang ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.361   &0.465   &0.660   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Lipophilicity_AstraZeneca/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Lipophilicity_AstraZeneca/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Lipophilicity_AstraZeneca/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** Lipophilicity_AstraZeneca ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.546$\\pm$0.014  &0.509$\\pm$0.024  &0.713$\\pm$0.017  &0.656$\\pm$0.016  &0.813$\\pm$0.009  &0.790$\\pm$0.013  \n",
            " idx 2: &0.526            &0.476            &0.690            &0.678            &0.825            &0.807            \n",
            "\n",
            "******************** Lipophilicity_AstraZeneca ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.526   &0.690   &0.678   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/HydrationFreeEnergy_FreeSolv/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/HydrationFreeEnergy_FreeSolv/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/HydrationFreeEnergy_FreeSolv/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** HydrationFreeEnergy_FreeSolv ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&1.208$\\pm$0.043  &2.340$\\pm$0.106  &1.529$\\pm$0.035  &0.857$\\pm$0.006  &0.935$\\pm$0.004  &0.915$\\pm$0.006  \n",
            " idx 2: &1.147            &2.191            &1.480            &0.866            &0.936            &0.917            \n",
            "\n",
            "******************** HydrationFreeEnergy_FreeSolv ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &1.147   &1.480   &0.866   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Solubility_AqSolDB/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Solubility_AqSolDB/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Solubility_AqSolDB/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** Solubility_AqSolDB ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.771$\\pm$0.015  &1.177$\\pm$0.015  &1.085$\\pm$0.007  &0.783$\\pm$0.003  &0.887$\\pm$0.003  &0.878$\\pm$0.003  \n",
            " idx 0: &0.755            &1.156            &1.075            &0.787            &0.891            &0.881            \n",
            "\n",
            "******************** Solubility_AqSolDB ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.755   &1.075   &0.787   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/LD50_Zhu/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/LD50_Zhu/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/LD50_Zhu/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** LD50_Zhu ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&0.469$\\pm$0.012  &0.404$\\pm$0.019  &0.635$\\pm$0.015  &0.548$\\pm$0.021  &0.752$\\pm$0.015  &0.705$\\pm$0.014  \n",
            " idx 0: &0.455            &0.383            &0.619            &0.571            &0.772            &0.725            \n",
            "\n",
            "******************** LD50_Zhu ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &0.455   &0.619   &0.571   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Kp/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Kp/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Kp/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** Kp ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&6.267$\\pm$0.650  &158.404$\\pm$9.724  &12.580$\\pm$0.386  &0.161$\\pm$0.051  &0.447$\\pm$0.040  &0.309$\\pm$0.046  \n",
            " idx 0: &5.653            &146.728            &12.113            &0.223            &0.501            &0.251            \n",
            "\n",
            "******************** Kp ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &5.653   &12.113   &0.223   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Half_Life_Obach/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Half_Life_Obach/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Half_Life_Obach/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** Half_Life_Obach ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&29.347$\\pm$0.741  &12908.436$\\pm$1155.370  &113.499$\\pm$5.130  &0.100$\\pm$0.081  &0.435$\\pm$0.132  &0.326$\\pm$0.040  \n",
            " idx 1: &28.381            &11381.773            &106.685            &0.207            &0.596            &0.271            \n",
            "\n",
            "******************** Half_Life_Obach ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &28.381   &106.685   &0.207   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Clearance_Hepatocyte_AZ/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Clearance_Hepatocyte_AZ/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Clearance_Hepatocyte_AZ/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** Clearance_Hepatocyte_AZ ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&34.490$\\pm$2.387  &2311.557$\\pm$111.528  &48.064$\\pm$1.169  &0.074$\\pm$0.045  &0.380$\\pm$0.023  &0.427$\\pm$0.003  \n",
            " idx 1: &37.841            &2155.245            &46.425            &0.137            &0.396            &0.427            \n",
            "\n",
            "******************** Clearance_Hepatocyte_AZ ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &37.841   &46.425   &0.137   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Clearance_Microsome_AZ/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Clearance_Microsome_AZ/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Clearance_Microsome_AZ/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** Clearance_Microsome_AZ ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&27.001$\\pm$0.094  &1676.198$\\pm$89.057  &40.927$\\pm$1.079  &0.114$\\pm$0.047  &0.397$\\pm$0.021  &0.544$\\pm$0.028  \n",
            " idx 2: &27.121            &1594.464            &39.931            &0.157            &0.423            &0.516            \n",
            "\n",
            "******************** Clearance_Microsome_AZ ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &27.121   &39.931   &0.157   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/PPBR_AZ/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/PPBR_AZ/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/PPBR_AZ/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** PPBR_AZ ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&8.153$\\pm$0.288  &180.924$\\pm$5.979  &13.449$\\pm$0.223  &0.253$\\pm$0.025  &0.545$\\pm$0.009  &0.550$\\pm$0.040  \n",
            " idx 0: &7.929            &173.154            &13.159            &0.285            &0.556            &0.495            \n",
            "\n",
            "******************** PPBR_AZ ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &7.929   &13.159   &0.285   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/VDss_Lombardo/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/VDss_Lombardo/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/VDss_Lombardo/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** VDss_Lombardo ******************** \n",
            "\t|       mae      |       mse      |       rmse      |       r2      |       pcc      |       spearman      \n",
            "\t&5.691$\\pm$3.589  &83.554$\\pm$65.495  &8.493$\\pm$3.380  &-0.790$\\pm$1.403  &0.372$\\pm$0.266  &0.374$\\pm$0.270  \n",
            " idx 1: &2.982            &36.966            &6.080            &0.208            &0.517            &0.636            \n",
            "\n",
            "******************** VDss_Lombardo ******************** \n",
            "\t|  mae  |  rmse  |  r2  \n",
            "single: &2.982   &6.080   &0.208   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP2C19_Veith/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP2C19_Veith/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP2C19_Veith/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** CYP2C19_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.812$\\pm$0.002  &0.813$\\pm$0.002  &0.783$\\pm$0.010  &0.819$\\pm$0.015  &0.807$\\pm$0.014  &0.800$\\pm$0.003  &0.883$\\pm$0.003  &0.625$\\pm$0.003  &0.846$\\pm$0.010  \n",
            " idx 1: &0.811            &0.811            &0.786            &0.808            &0.813            &0.797            &0.887            &0.620            &0.857            \n",
            "\n",
            "******************** CYP2C19_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.811   &0.887   &0.857   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP2D6_Veith/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP2D6_Veith/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP2D6_Veith/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** CYP2D6_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.862$\\pm$0.003  &0.710$\\pm$0.034  &0.701$\\pm$0.044  &0.468$\\pm$0.086  &0.952$\\pm$0.017  &0.553$\\pm$0.052  &0.833$\\pm$0.003  &0.494$\\pm$0.030  &0.642$\\pm$0.003  \n",
            " idx 1: &0.865            &0.724            &0.689            &0.500            &0.949            &0.580            &0.835            &0.511            &0.645            \n",
            "\n",
            "******************** CYP2D6_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.865   &0.835   &0.645   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP3A4_Veith/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP3A4_Veith/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP3A4_Veith/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** CYP3A4_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.794$\\pm$0.003  &0.783$\\pm$0.006  &0.768$\\pm$0.009  &0.718$\\pm$0.026  &0.847$\\pm$0.014  &0.742$\\pm$0.010  &0.878$\\pm$0.002  &0.572$\\pm$0.008  &0.833$\\pm$0.005  \n",
            " idx 0: &0.794            &0.784            &0.766            &0.722            &0.845            &0.743            &0.881            &0.573            &0.841            \n",
            "\n",
            "******************** CYP3A4_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.794   &0.881   &0.841   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP1A2_Veith/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP1A2_Veith/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP1A2_Veith/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** CYP1A2_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.850$\\pm$0.002  &0.851$\\pm$0.002  &0.829$\\pm$0.010  &0.861$\\pm$0.011  &0.841$\\pm$0.013  &0.844$\\pm$0.001  &0.922$\\pm$0.001  &0.701$\\pm$0.003  &0.913$\\pm$0.002  \n",
            " idx 0: &0.853            &0.853            &0.843            &0.846            &0.859            &0.845            &0.923            &0.705            &0.915            \n",
            "\n",
            "******************** CYP1A2_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.853   &0.923   &0.915   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP2C9_Veith/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP2C9_Veith/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP2C9_Veith/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** CYP2C9_Veith ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.821$\\pm$0.002  &0.797$\\pm$0.012  &0.743$\\pm$0.027  &0.724$\\pm$0.051  &0.870$\\pm$0.028  &0.731$\\pm$0.012  &0.886$\\pm$0.003  &0.599$\\pm$0.009  &0.782$\\pm$0.004  \n",
            " idx 1: &0.819            &0.813            &0.708            &0.795            &0.832            &0.749            &0.888            &0.611            &0.786            \n",
            "\n",
            "******************** CYP2C9_Veith ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.819   &0.888   &0.786   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/BBB_Martins/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/BBB_Martins/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/BBB_Martins/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** BBB_Martins ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.850$\\pm$0.010  &0.759$\\pm$0.014  &0.868$\\pm$0.008  &0.943$\\pm$0.015  &0.576$\\pm$0.033  &0.903$\\pm$0.007  &0.860$\\pm$0.016  &0.578$\\pm$0.029  &0.930$\\pm$0.013  \n",
            " idx 0: &0.857            &0.754            &0.861            &0.964            &0.544            &0.910            &0.852            &0.595            &0.928            \n",
            "\n",
            "******************** BBB_Martins ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.857   &0.852   &0.928   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Bioavailability_Ma/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Bioavailability_Ma/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Bioavailability_Ma/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** Bioavailability_Ma ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.724$\\pm$0.019  &0.583$\\pm$0.060  &0.745$\\pm$0.030  &0.930$\\pm$0.052  &0.237$\\pm$0.168  &0.826$\\pm$0.009  &0.662$\\pm$0.034  &nan$\\pm$nan  &0.794$\\pm$0.040  \n",
            " idx 0: &0.750            &0.640            &0.774            &0.911            &0.368            &0.837            &0.652            &0.339            &0.776            \n",
            "\n",
            "******************** Bioavailability_Ma ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.750   &0.652   &0.776   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Pgp_Broccatelli/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Pgp_Broccatelli/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Pgp_Broccatelli/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** Pgp_Broccatelli ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.851$\\pm$0.007  &0.851$\\pm$0.007  &0.856$\\pm$0.048  &0.854$\\pm$0.046  &0.848$\\pm$0.060  &0.852$\\pm$0.002  &0.917$\\pm$0.016  &0.706$\\pm$0.017  &0.939$\\pm$0.008  \n",
            " idx 1: &0.844            &0.844            &0.820            &0.886            &0.802            &0.852            &0.932            &0.691            &0.948            \n",
            "\n",
            "******************** Pgp_Broccatelli ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.844   &0.932   &0.948   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/HIA_Hou/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/HIA_Hou/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/HIA_Hou/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** HIA_Hou ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.948$\\pm$0.007  &0.870$\\pm$0.039  &0.954$\\pm$0.015  &0.986$\\pm$0.013  &0.754$\\pm$0.089  &0.970$\\pm$0.004  &0.965$\\pm$0.034  &0.805$\\pm$0.028  &0.988$\\pm$0.014  \n",
            " idx 1: &0.948            &0.906            &0.969            &0.969            &0.842            &0.969            &0.991            &0.811            &0.998            \n",
            "\n",
            "******************** HIA_Hou ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.948   &0.991   &0.998   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/PAMPA_NCATS/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/PAMPA_NCATS/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/PAMPA_NCATS/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** PAMPA_NCATS ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.847$\\pm$0.006  &0.596$\\pm$0.077  &0.874$\\pm$0.023  &0.959$\\pm$0.030  &0.233$\\pm$0.182  &0.914$\\pm$0.003  &0.716$\\pm$0.011  &nan$\\pm$nan  &0.922$\\pm$0.010  \n",
            " idx 1: &0.855            &0.687            &0.901            &0.930            &0.444            &0.916            &0.720            &0.406            &0.909            \n",
            "\n",
            "******************** PAMPA_NCATS ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.855   &0.720   &0.909   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/hERG_Karim/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/hERG_Karim/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/hERG_Karim/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** hERG_Karim ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.799$\\pm$0.010  &0.799$\\pm$0.010  &0.808$\\pm$0.023  &0.787$\\pm$0.047  &0.811$\\pm$0.037  &0.796$\\pm$0.017  &0.884$\\pm$0.008  &0.600$\\pm$0.019  &0.889$\\pm$0.007  \n",
            " idx 2: &0.813            &0.813            &0.808            &0.821            &0.805            &0.815            &0.895            &0.627            &0.899            \n",
            "\n",
            "******************** hERG_Karim ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.813   &0.895   &0.899   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/AMES/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/AMES/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/AMES/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** AMES ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.806$\\pm$0.004  &0.801$\\pm$0.005  &0.804$\\pm$0.010  &0.854$\\pm$0.010  &0.747$\\pm$0.018  &0.828$\\pm$0.003  &0.877$\\pm$0.003  &0.607$\\pm$0.008  &0.891$\\pm$0.006  \n",
            " idx 0: &0.807            &0.804            &0.814            &0.840            &0.767            &0.827            &0.877            &0.609            &0.887            \n",
            "\n",
            "******************** AMES ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.807   &0.877   &0.887   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP2C9_Substrate_CarbonMangels/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP2C9_Substrate_CarbonMangels/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP2C9_Substrate_CarbonMangels/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** CYP2C9_Substrate_CarbonMangels ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.746$\\pm$0.074  &0.537$\\pm$0.052  &nan$\\pm$nan  &0.185$\\pm$0.262  &0.888$\\pm$0.159  &nan$\\pm$nan  &0.617$\\pm$0.012  &nan$\\pm$nan  &0.273$\\pm$0.023  \n",
            " idx 1: &0.799            &0.500            &nan            &0.000            &1.000            &nan            &0.627            &nan            &0.289            \n",
            "\n",
            "******************** CYP2C9_Substrate_CarbonMangels ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.799   &0.627   &0.289   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP2D6_Substrate_CarbonMangels/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP2D6_Substrate_CarbonMangels/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP2D6_Substrate_CarbonMangels/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 0 has the lowest loss\n",
            "******************** CYP2D6_Substrate_CarbonMangels ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.659$\\pm$0.044  &0.658$\\pm$0.012  &0.376$\\pm$0.038  &0.656$\\pm$0.055  &0.660$\\pm$0.074  &0.474$\\pm$0.015  &0.693$\\pm$0.008  &0.275$\\pm$0.030  &0.436$\\pm$0.050  \n",
            " idx 0: &0.722            &0.673            &0.429            &0.581            &0.765            &0.493            &0.701            &0.314            &0.459            \n",
            "\n",
            "******************** CYP2D6_Substrate_CarbonMangels ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.722   &0.701   &0.459   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/CYP3A4_Substrate_CarbonMangels/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/CYP3A4_Substrate_CarbonMangels/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/CYP3A4_Substrate_CarbonMangels/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** CYP3A4_Substrate_CarbonMangels ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.592$\\pm$0.013  &0.592$\\pm$0.013  &0.586$\\pm$0.004  &0.627$\\pm$0.068  &0.557$\\pm$0.043  &0.604$\\pm$0.034  &0.637$\\pm$0.017  &0.186$\\pm$0.027  &0.611$\\pm$0.016  \n",
            " idx 2: &0.597            &0.597            &0.589            &0.642            &0.552            &0.614            &0.648            &0.195            &0.618            \n",
            "\n",
            "******************** CYP3A4_Substrate_CarbonMangels ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.597   &0.648   &0.618   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/DILI/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/DILI/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/DILI/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** DILI ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.793$\\pm$0.013  &0.792$\\pm$0.013  &0.767$\\pm$0.010  &0.847$\\pm$0.020  &0.738$\\pm$0.010  &0.805$\\pm$0.013  &0.879$\\pm$0.004  &0.589$\\pm$0.027  &0.883$\\pm$0.010  \n",
            " idx 1: &0.789            &0.789            &0.769            &0.833            &0.745            &0.800            &0.874            &0.581            &0.870            \n",
            "\n",
            "******************** DILI ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.789   &0.874   &0.870   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Skin Reaction/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Skin Reaction/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Skin Reaction/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** Skin Reaction ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.687$\\pm$0.058  &0.620$\\pm$0.085  &0.680$\\pm$0.054  &0.939$\\pm$0.050  &0.302$\\pm$0.217  &0.786$\\pm$0.023  &0.789$\\pm$0.011  &nan$\\pm$nan  &0.836$\\pm$0.015  \n",
            " idx 1: &0.728            &0.689            &0.729            &0.878            &0.500            &0.796            &0.804            &0.415            &0.855            \n",
            "\n",
            "******************** Skin Reaction ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.728   &0.804   &0.855   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/Carcinogens_Lagunin/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/Carcinogens_Lagunin/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/Carcinogens_Lagunin/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 2 has the lowest loss\n",
            "******************** Carcinogens_Lagunin ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.821$\\pm$0.051  &0.604$\\pm$0.146  &nan$\\pm$nan  &0.222$\\pm$0.314  &0.985$\\pm$0.021  &nan$\\pm$nan  &0.867$\\pm$0.009  &nan$\\pm$nan  &0.787$\\pm$0.034  \n",
            " idx 2: &0.893            &0.811            &0.800            &0.667            &0.955            &0.727            &0.879            &0.666            &0.819            \n",
            "\n",
            "******************** Carcinogens_Lagunin ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.893   &0.879   &0.819   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Run # 0 for chemBERTa ST\t | save dir:  ST/ClinTox/chemBERTa_ST_0 | \t--> pre data loaded\n",
            "\n",
            "Run # 1 for chemBERTa ST\t | save dir:  ST/ClinTox/chemBERTa_ST_1 | \t--> pre data loaded\n",
            "\n",
            "Run # 2 for chemBERTa ST\t | save dir:  ST/ClinTox/chemBERTa_ST_2 | \t--> pre data loaded\n",
            "repeated num # 3 idx 1 has the lowest loss\n",
            "******************** ClinTox ******************** \n",
            "\t|       acc      |       w_acc      |       prec      |       recall      |       sp      |       f1      |       auc      |       mcc      |       ap      \n",
            "\t&0.937$\\pm$0.003  &0.687$\\pm$0.010  &0.702$\\pm$0.045  &0.389$\\pm$0.020  &0.985$\\pm$0.003  &0.500$\\pm$0.021  &0.919$\\pm$0.038  &0.493$\\pm$0.025  &0.580$\\pm$0.045  \n",
            " idx 1: &0.932            &0.678            &0.643            &0.375            &0.982            &0.474            &0.865            &0.459            &0.517            \n",
            "\n",
            "******************** ClinTox ******************** \n",
            "\t|  acc  |  auc  |  ap  \n",
            "single: &0.932   &0.865   &0.517   \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}